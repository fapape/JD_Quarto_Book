[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JDemetra+ documentation",
    "section": "",
    "text": "What is JDemetra+ ?\nJDemetra+ is an open-source software for seasonal adjustment and time series analysis, developed in the framework of Eurostat’s “Centre of Excellence on Statistical Methods and Tools” by the National Bank of Belgium with the support of the Bundesbank and Insee. It has been officially recommended by Eurostat to the European Statistical System members since 2015. It is unique in its combination of very fast Java routines, a graphical user interface and an ecosystem of R packages. The graphical interface offers a structured and visual feedback, suitable for refined analysis and training. R tools allow the user to mix the capabilities of JDemetra+ with the versatility of the R world, be it for mathematical functions or data wrangling.\nA pdf version of this documentation is available here"
  },
  {
    "objectID": "index.html#curently-available-versions",
    "href": "index.html#curently-available-versions",
    "title": "JDemetra+ documentation",
    "section": "Curently available versions",
    "text": "Curently available versions\nThe highest version currently recommended for production purposes is 2.2.4.\nVersion 3.x family provides, among other things, extended features for seasonal adjustment and trend estimation, including high frequency data. The latest version 3.2 was released on November 23rd 2023."
  },
  {
    "objectID": "index.html#useful-links",
    "href": "index.html#useful-links",
    "title": "JDemetra+ documentation",
    "section": "Useful links",
    "text": "Useful links\nTo install the software and get started, you can browse and watch tutorials for JDemetra+. On this YouTube channel you will also find many JDemetra+ related webinars.\nTo keep up with all JDemetra+ related news head to the JDemetra+ Universe Blog\nTo learn more about the JDemetra+ development project you can visit Eurostat CROS Portal.\nThis website is under construction, in the meantime you can fill a large number of the gaps by referring to the previous version of the on-line documentation, coordinated by Sylwia Grudkowska-Kubik (National Bank of Poland).\nEurostat’s recommendations on the statistical processes described in this documentation are outlined in:\n\nEurostat’s Guidelines on seasonal adjustment (2015)\nEurostat’s Guidelines on temporal disaggregation, benchmarking and reconcilation (2018)\n\nKey methodological explanations and state-of-the-art description and references can be found in:\n\nHandbook on seasonal adjustment (2018)\nHandbook on rapid estimates (2017)"
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "JDemetra+ documentation",
    "section": "How to contribute",
    "text": "How to contribute\nIf you want to help us improve this book, you can fork this repository on GitHub and create pull requests with your contributions."
  },
  {
    "objectID": "G-how-to-use-this-book.html#structure",
    "href": "G-how-to-use-this-book.html#structure",
    "title": "How to use this book",
    "section": "Structure",
    "text": "Structure\nThis book is divided in three parts, allowing the user to access the resources from different perspectives.\n\nAlgorithms\nTools\nMethods"
  },
  {
    "objectID": "G-how-to-use-this-book.html#quick-start",
    "href": "G-how-to-use-this-book.html#quick-start",
    "title": "How to use this book",
    "section": "Quick Start",
    "text": "Quick Start\n(up coming content here)"
  },
  {
    "objectID": "G-how-to-use-this-book.html#features-map",
    "href": "G-how-to-use-this-book.html#features-map",
    "title": "How to use this book",
    "section": "Features MAP",
    "text": "Features MAP\nUp coming content: here an overview of all the existing tools will be provided, highlighted what specific features can (or cannot) be accessed with each of them.\n\nWhat is new in version 3.x\nSeasonal adjustment of high frequency data is the main functionality upgrade brought by version 3 but there are many others. They will be extensively pointed out in this chapter\n\n\nR ecosytem vs GUI in v2\nThe vast majority of functions have identical options and output when used via R or GUI, but there are some exceptions. Data structure and visualization can also differ. This will be described in the sections below.\n\nIn version 2.2.4\nup coming content\n\n\nIn version 3.x\nup coming content"
  },
  {
    "objectID": "G-how-to-use-this-book.html#frequently-asked-questions",
    "href": "G-how-to-use-this-book.html#frequently-asked-questions",
    "title": "How to use this book",
    "section": "Frequently asked questions",
    "text": "Frequently asked questions\nup coming content"
  },
  {
    "objectID": "G-how-to-use-this-book.html#troubleshooting",
    "href": "G-how-to-use-this-book.html#troubleshooting",
    "title": "How to use this book",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nup coming content\n\nSoftware Installation\n\n\nReporting bugs"
  },
  {
    "objectID": "G-news-v3-vs-v2.html#in-this-chapter",
    "href": "G-news-v3-vs-v2.html#in-this-chapter",
    "title": "New Features in v 3.x family",
    "section": "In this chapter",
    "text": "In this chapter\nUp coming content.\nThis chapter will provide a contextualized view of new features of v 3.x as well as modification of display or content for existing features. We will report on their degree of maturity and testing."
  },
  {
    "objectID": "P_Algorithms.html",
    "href": "P_Algorithms.html",
    "title": "Algorithms",
    "section": "",
    "text": "This part provides practical guidance for using all the algorithms featured in JDemetra+, be it with the Graphical User Interface or R packages\nFurther methodological insights on each algorithm can be found in the Methods part of this book, whereas detailed description of all the available tools allowing to access the algorithms can be found in the Tools part.\nIn this part:\nModelling and Auxiliary Variables\nReg-Arima modelling Outlier detection and external regressors Calendar correction\nSeasonal Adjustment (SA)\n\nSeasonal Adjustment overview\nSA: pre-treatment\nSA: X11 decomposition\nSA: Seats-decomposition\nSA: STL decomposition\nSA of High-Frequency Data\nSA with Basic Stuctural Models (BSM)\n\nOther Algorithms\n\nBenchmarking and temporal disaggregation\nTrend-Cycle estimation\nRevision analysis\nNowcasting"
  },
  {
    "objectID": "A-RegArima-Tramo-Modelling-Overview.html#in-this-chapter",
    "href": "A-RegArima-Tramo-Modelling-Overview.html#in-this-chapter",
    "title": "RegArima (Tramo) Modelling",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter focuses on practical implementation of modelling of a time series (with arima residuals) .\nThe sections below will describe modelling features which can be used stand alone or as pre-treatment (first step of seasonal adjustment).\nIn-depth methodological explanations of the algorithms are covered in separated chapters, in the Methods part."
  },
  {
    "objectID": "A-RegArima-Tramo-Modelling-Overview.html#modelling-algorithms",
    "href": "A-RegArima-Tramo-Modelling-Overview.html#modelling-algorithms",
    "title": "RegArima (Tramo) Modelling",
    "section": "Modelling Algorithms",
    "text": "Modelling Algorithms\n\n\n\n\n\n\n\n\n\nAlgorithm\nAccess in GUI\nAccess in R (v2)\nAccess in R (v3)\n\n\n\n\nReg-Arima\n✔️\nRJDemetra\n\n\n\nTramo\n✔️\nRJDemetra\nrjd3tramoseats\n\n\nExtended Airline\n✔️ (v3 only)\n✔\nrjd3highfreq\n\n\nSTS\n✖\n✔\nrjd3sts\n\n\n\nSteps to use Reg-Arima and Tramo in a pre-treatment context are described here. Options and outputs are the same as when modelling is done as pre-treatment or stand alone. Specification differ slightly and the possibility of saving parameters and generating output in the GUI is also different.\nExtended Airline Model allows to handle infra monthly series in a restricted reg-Arima framework.\nStrucural time series (STS) allow another kind of modelling using state space framework."
  },
  {
    "objectID": "A-RegArima-Tramo-Modelling-Overview.html#practical-reg-arima-modelling",
    "href": "A-RegArima-Tramo-Modelling-Overview.html#practical-reg-arima-modelling",
    "title": "RegArima (Tramo) Modelling",
    "section": "Practical Reg-Arima modelling",
    "text": "Practical Reg-Arima modelling\nFor the user not needing seasonal adjustment, the sections below highlight the functions or steps allowing to perform reg-Arima (or Tramo) as a stand alone goal, outside of a seasonal adjustment process.\n\nIn R\nUp coming content\n\n\nGUI\nUp coming content"
  },
  {
    "objectID": "A-sa-overview.html#in-this-chapter",
    "href": "A-sa-overview.html#in-this-chapter",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter is a first of a series focusing on the practical step by step use of JDemetra+ Seasonal Adjustment (SA) algorithms, restricted to monthly and quarterly series. For infra-monthly data see the following chapter.\nIn the section below an overview of the seasonal adjustment process is provided. The most widely used SA algorithms have two steps: a pre-treatment to remove (temporarily) deterministic effects and decompositions allowing to estimate the seasonal factors to be removed from the serie.\nThe following chapters get into the specifics of each algorithm.\n\nSA: pre-treatment\nSA: X11 decomposition\nSA: Seats-decomposition\nSA: STL decomposition\nSA of High-Frequency Data\nSA with Basic Stuctural Models (BSM)\n\nThe use of graphical user interface and R packages is described simultaneously whenever relevant.\nIn-depth methodological explanations of the algorithms are covered in separated chapters, in the Methods part.\nMore information on the steps and best practices of a seasonal adjustment process can be found in the Eurostat guidelines on seasonal adjustment\nFor an overview on the algorithms and methodological issues, please refer to the Handbook on Seasonal Adjustment"
  },
  {
    "objectID": "A-sa-overview.html#sa-process-description",
    "href": "A-sa-overview.html#sa-process-description",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "SA process description",
    "text": "SA process description\nUpcoming content"
  },
  {
    "objectID": "A-sa-overview.html#seasonal-adjustment-algorithms",
    "href": "A-sa-overview.html#seasonal-adjustment-algorithms",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "Seasonal Adjustment Algorithms",
    "text": "Seasonal Adjustment Algorithms\n\n\n\n\n\n\n\n\n\nAlgorithm\nAccess in GUI\nAccess in R (v2)\nAccess in R v3\n\n\n\n\nX-13 Arima\n✔️\nRJDemetra\nrjd3x13\n\n\nReg-Arima only\n✔️\nRJDemetra\nrjd3x13\n\n\nX11 decomposition only\n✔️\nRJDemetra\nrjd3x13\n\n\nTRAMO-SEATS\n✔️\nRJDemetra\nrjd3tramoseats\n\n\nTramo only\n✔️\nRJDemetra\nrjd3tramoseats\n\n\nSTL\n✖\n✖\nrjd3stl\n\n\nSTS\n✖\n✖\nrjd3sts\n\n\n\nX13-ARIMA and TRAMO-SEATS are two-step algorithms with a pre-treatment phase (Reg-Arima or Tramo) and a decomposition phase (X11 and Seats). STL is a local regression (Loess) based decomposition, without pre-treatment. In a Structural Time Series approach pre-treatment and decomposition are done simultaneously in a State Space Framework."
  },
  {
    "objectID": "A-sa-overview.html#admissible-data-frequencies",
    "href": "A-sa-overview.html#admissible-data-frequencies",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "Admissible data frequencies",
    "text": "Admissible data frequencies\nUp coming content"
  },
  {
    "objectID": "A-sa-overview.html#decomposition-in-unobserved-components",
    "href": "A-sa-overview.html#decomposition-in-unobserved-components",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "Decomposition in unobserved components",
    "text": "Decomposition in unobserved components\nTo seasonally adjust a series, seasonal factors \\(S_{t}\\) will be estimated and removed from the original raw series: \\(Y_{sa}=Y_{t}/S_{t}\\) or \\(Y_{sa}=Y_{t}-S_{t}\\). To do so the series is first decomposed into unobservable components. Two decomposition models:\n\nThe additive model: \\(X_{t} = T_{t} + S_{t} + I_{t}\\);\nThe multiplicative model: \\(X_{t} = T_{t} \\times S_{t} \\times I_{t}\\).\n\nThe main components, each representing the impact of certain types of phenomena on the time series (\\(X_{t}\\)), are:\n\nThe trend (\\(T_{t}\\)) that captures long-term and medium-term behaviour;\nThe seasonal component (\\(S_{t}\\)) representing intra-year fluctuations, monthly or quarterly, that are repeated more or less regularly year after year;\nThe irregular component (\\(I_{t}\\)) combining all the other more or less erratic fluctuations not covered by the previous components.\n\nIn general, the trend consists of 2 sub-components:\n\nThe long-term evolution of the series;\nThe cycle, that represents the smooth, almost periodic movement around the long-term evolution of the series. It reveals a succession of phases of growth and recession. Trend and cycle are not separated in SA algorithms."
  },
  {
    "objectID": "A-sa-overview.html#detecting-seasonal-patterns",
    "href": "A-sa-overview.html#detecting-seasonal-patterns",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "Detecting seasonal patterns",
    "text": "Detecting seasonal patterns\nA large number of seasonality tests are available in JDemetra+. They can be accessed in the graphical user interface or via R.\n\nIn R\nIn rjd3toolkit package:\n\nCanova-Hansen (seasonality.canovahansen())\nX-12 combined test (seasonality.combined())\nF-test on seasonal dummies (seasonality.f())\nFriedman Seasonality Test (seasonality.friedman())\nKruskall-Wallis Seasonality Test (seasonality.kruskalwallis())\nPeriodogram Seasonality Test (seasonality.periodogram())\nQS Seasonality Test (seasonality.qs())\n\n\n\nIn GUI\nHow to generate test in GUI is described here."
  },
  {
    "objectID": "A-sa-overview.html#direct-indirect-seasonal-adjustment",
    "href": "A-sa-overview.html#direct-indirect-seasonal-adjustment",
    "title": "Seasonal Adjustment (SA) Overview",
    "section": "Direct-Indirect seasonal adjustment",
    "text": "Direct-Indirect seasonal adjustment\nUp coming content\n\nGUI\n\n\nR"
  },
  {
    "objectID": "A-sa-pre-treatment.html#in-this-chapter",
    "href": "A-sa-pre-treatment.html#in-this-chapter",
    "title": "SA: Pre-Treatment",
    "section": "In this chapter",
    "text": "In this chapter\nThe following sections cover pre-treatment with Reg-ARIMA (or Tramo) algorithms. Tramo and the Reg-Arima part of X13-ARIMA rely on very similar principles. Thus Tramo will be mentioned only to highlight differences with the Reg-Arima part of X13-ARIMA.\nReg-Arima modelling part can be of a seasonal adjustment process or run on its own. Below we focus on performing reg-arima modelling as pre-treatment in a SA processing.\nMore in-depth methodological explanations of the algorithms can be found in this part of the documentation."
  },
  {
    "objectID": "A-sa-pre-treatment.html#pre-treatment-principles",
    "href": "A-sa-pre-treatment.html#pre-treatment-principles",
    "title": "SA: Pre-Treatment",
    "section": "Pre-treatment principles",
    "text": "Pre-treatment principles\nThe goal of this step is to remove deterministic effects (calendar and outliers) in order to improve the decomposition.\n\\[\nY_t = \\sum{\\alpha}_i O_{it} + \\sum\\beta_j C_{jt} + \\sum {\\gamma}_i U_{it} + Y_{lin,t}\n\\]\n\n\\(O_{it}\\) are the \\(i\\) final outliers (AO, LS, TC)\n\\(C_{it}\\) are the calendar regressors (automatic or user-defined) (link to calendar chap)\n\\(U_{it}\\) are all the other user-defined regressors (link to outliers and regressors chap)\n\\(Y_{lin,t} \\sim ARIMA(p,d,q)(P,D,Q)\\)"
  },
  {
    "objectID": "A-sa-pre-treatment.html#sa-pre-t-realloc",
    "href": "A-sa-pre-treatment.html#sa-pre-t-realloc",
    "title": "SA: Pre-Treatment",
    "section": "Reallocation of pre-treatment effects",
    "text": "Reallocation of pre-treatment effects\nUp coming content.\n\nDefault Specifications\nDefault specifications are set for the whole SA procedure, pre-treatment and decomposition. They are slightly different for X13-ARIMA and TRAMO-SEATS and can be modified with user defined parameters.\n\nStarting point for X13-ARIMA\n\n\n\n\n\n\n\n\n\n\nSpec identifier\nLog/level detection\nOutliers detection\nCalendar effects\nARIMA\n\n\n\n\nRSA0\nNA\nNA\nNA\nAirline(+mean)\n\n\nRSA1\nautomatic\nAO/LS/TC\nNA\nAirline(+mean)\n\n\nRSA2c\nautomatic\nAO/LS/TC\n2 TD vars+Easter\nAirline(+mean)\n\n\nRSA3\nautomatic\nAO/LS/TC\nNA\nautomatic\n\n\nRSA4c\nautomatic\nAO/LS/TC\n2 TD vars+Easter\nautomatic\n\n\nRSA5\nautomatic\nAO/LS/TC\n7 TD vars+Easter\nautomatic\n\n\nX-11\nNA\nNA\nNA\nNA\n\n\n\nexplanations:\n\nNA: non applied, for example in RSA3 there is no calendar effect correction\nautomatic: test is performed\n\noutliers detection: AO/LS/TC type of outliers automatically detected under a critical T-Stat value (default value=4)\ncalendar:\n\n2 regressors: weekdays vs week-ends + LY\n7 regressors: each week day vs Sundays + LY\nalways tested\neaster tested (default length = 6 days in Tramo, 8 days in X13-ARIMA)\n\n\n\nStarting point for Tramo-Seats\n\n\n\n\n\n\n\n\n\n\nSpec identifier\nLog/level detection\nOutliers detection\nCalendar effects\nARIMA\n\n\n\n\nRSA0\nNA\nNA\nNA\nAirline(+mean)\n\n\nRSA1\nautomatic\nAO/LS/TC\nNA\nAirline(+mean)\n\n\nRSA2\nautomatic\nAO/LS/TC\n2 TD vars+Easter\nAirline(+mean)\n\n\nRSA3\nautomatic\nAO/LS/TC\nNA\nautomatic\n\n\nRSA5\nautomatic\nAO/LS/TC\n6 TD vars+Easter\nautomatic\n\n\nRSAfull\nautomatic\nAO/LS/TC\nautomatic\nautomatic\n\n\n\n\n\n\nUser-defined specifications\nPrinciple of user setting parameters: can be done from one of the default specifications or any specification in a “Save as” mode very similar in GUI and R, see below.\nThe user may add new seasonal adjustment specifications to the Workspace window. To do it, go to the Seasonal adjustment section, right click on the tramoseats or x13 item in the specifications node and select New from the local menu.\n\n\n\nCreating a new specification in the Seasonal adjustment section\n\n\nNext, double click on the newly created specification, change the settings accordingly and confirm with the OK button.\n\n\n\nChanging settings of seasonal adjustment specification\n\n\n\n\nSpans\n\nEstimation span\nSpecifies the span (data interval) of the time series to be used in the seasonal adjustment process. The user can restrict the span\nCommon settings\n\n\n\n\n\n\n\n\nOption\nDescription (expected format)\n\n\n\n\n\nAll\ndefault\n\n\n\nFrom\nfirst observation included (yyyy-mm-dd)\n\n\n\nTo\nlast observation included (yyyy-mm-dd)\n\n\n\nBetween\ninterval [from ; to] included (yyyy-mm-dd to yyyy-mm-dd)\n\n\n\nFirst\nnumber of obs from the beginning of the series included (dynamic) (integer)\n\n\n\nLast\nnumber of obs from the end of the series (dynamic)(integer)\n\n\n\nExcluding\nexcluding N first obs and P last obs from the computation,dynamic) (integer)\n\n\n\nPreliminary check\ncheck to exclude highly problematic series e.g. the series with a number of identical observations and/or missing values above pre-specified threshold values. (True/False)\n\n\n\n\nSetting series span in GUI\nUse the specification window for a given series and expand the nodes.\n\n\n\nSetting series span in R\n\n\nx13 in version 2\n\nlibrary(\"RJDemetra\")\n# estimation interval: option with static dates\nuser_spec_1 &lt;- x13_spec(\n    spec = c(\n        \"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\",\n        \"RSA3\", \"RSA4c\", \"X11\"\n    ),\n    preliminary.check = TRUE,\n    estimate.from = \"2012-06-01\",\n    estimate.to = \"2019-12-01\"\n)\n\n# estimation interval: option with dynamic numbers of observations\n\n#\n# spec can be applied on different series and therefore exclude different dates\nuser_spec_2 &lt;- x13_spec(\n    spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"),\n    estimate.first = 12\n)\n\n# eestimation on the last 120 obs\nuser_spec_3 &lt;- x13_spec(\n    spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"),\n    estimate.last = 120\n)\n\n# excluding first 24 and last 36 observations\nuser_spec_4 &lt;- x13_spec(\n    spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"),\n    estimate.exclFirst = 24,\n    estimate.exclLast = 36\n)\n\n# Retrieve settings\n\nFor comprehensive details about x13_spec function see RJDemetra R help pages.\nTRAMO-SEATS in version 2\n\n# excluding first 24 and last 36 observations\nuser_spec_1 &lt;- tramoseats_spec(\n    spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),\n    estimate.exclFirst = 24,\n    estimate.exclLast = 36\n)\n\nFor comprehensive details about tramoseats_spec function see RJDemetra R help pages.\n\n\nSetting model span\nThe user can also specify the span (data interval) of the time series to be used for the estimation of the Reg-ARIMA model coefficients. It allows to impede a chosen part of the data from influencing the regression estimates. Setting works the same way as setting series (estimation) span described above.\nAdditional (vs series span setting) parameters are described below:\n\n\n\n\n\n\n\nTolerance\nConvergence tolerance for the non-linear estimation.\nThe absolute changes in the log-likelihood are compared to Tolerance to check the convergence of the estimation iterations.\nThe default setting is 0.0000001.\n\n\nTramo specific parameters\n\n\n\nExact ML\nWhen this option is marked, an exact maximum likelihood estimation is performed.\nAlternatively, the Unconditional Least Squares method is used.\nHowever, in the current version of JDemetra+ it is not recommended to change this parameter’s value\n\n\nUnit Root Limit\nLimit for the autoregressive roots. If the inverse of a real root of the autoregressive polynomial of the\nARIMA model is higher than this limit, the root is set equal to 1. The default parameter value is 0.96.\n\n\n\nSetting model span in GUI:\nUse the specification window\n\n\n\nSetting in R\n\n\nTramo example in version 2\n\n# excluding first 24 and last 36 observations\nuser_spec_1 &lt;- tramoseats_spec(\n    spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),\n    estimate.tol = 0.0000001,\n    estimate.eml = FALSE,\n    estimate.urfinal = 0.98\n)\n\n\n\n\nDecomposition Scheme\n\nParameters\nTransformation test: a test is performed to choose between an additive decomposition (no transformation) (link to reg A chap to detail this)\nSettings\nFunction\ntransform {function=}\nTransformation of data. 2 The user can choose between:\nNone – no transformation of the data;\nLog – takes logs of the data;\nAuto – the program tests for the log-level specification. This option is recommended for automatic modelling of many series.\nThe default setting is Auto.\nReg-Arima specific settings\nAIC difference\ntransform {aicdiff=}\nDefines the difference in AICC needed to accept no transformation over a log transformation when the automatic transformation\nselection option is invoked. The option is disabled when Function is not set to Auto. The default AIC difference value is -2.\nAdjust\ntransform {adjust=}\nOptions for proportional adjustment for the leap year effect. The option is available when Function is set to Log. Adjust can be set to:\nLeapYear – performs a leap year adjustment of monthly or quarterly data;\nLengthofPeriod – performs a length-of-month adjustment on monthly data or length-of-quarter adjustment on quarterly data;\nNone – does not include a correction for the length of the period.\nThe default setting is None\nTramo specific settings\nFct\nTransformation; fct\nControls the bias in the log/level pre-test (the function is active when Function is set to Auto); Fct &gt; 1 favours levels, Fct &lt; 1 favors logs. The default setting is 0.95.\nSet in GUI\n\n\n\nModel span setting\n\n\nSet and in R\nX13\n\n# excluding first 24 and last 36 observations\nuser_spec &lt;- x13_spec(\n    spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"),\n    transform.function = \"Log\", # choose from: c(NA, \"Auto\", \"None\", \"Log\"),\n    transform.adjust = \"LeapYear\", # c(NA, \"None\", \"LeapYear\", \"LengthOfPeriod\"),\n    transform.aicdiff = -3\n)\n# Retrieve settings: to complete*\n\nTRAMO-SEATS settings\n\n# transfo\nuser_spec_1 &lt;- tramoseats_spec(\n    spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),\n    transform.function = \"Auto\", # c(NA, \"Auto\", \"None\", \"Log\"),\n    transform.fct = 0.5\n)\n# Retrieve settings: to complete\n\n\n\n\nCalendar correction\nSome calendar correction options included in the starting specifications for X13-ARIMA or TRAMO-SEATS, they can be fine-tuned by modifying specifications. The following section lists all the available options, illustrates how to set them in GUI or R and shows have to retrieve used parameters, regressors as well as results.\nJDemetra+ offers two default options for calendar correction working days regressors and trading days regressors, with Leap-year effect if needed. Those options don’t take into account national calendars (link) and their specific holidays. There are two ways to change this:\n\nuser-defined regressors (link)\ncustomized calendars (link)\n\nOverview: what you can do\nNeed 1: correct for working days, trading days (+ easter) not taking national calendars\nNeed 2: taking national calendar into account Solutions\n\nadd a work of means of allocating regressors to the calendar component\n\n\nAvailable Options\n\nTrading Days\n“Trading Days” has two meanings: general calendar correction process (here without easter effect) and one of the options of this correction (see below)\n-    \"None\": no correction for trading days and working days effects\n\n-    \"Default\": JDemetra + built regressors (xorking days or trading days)\n\n-    \"Holidays\": same as above but taking into accoutn a national calendar,                  available on ly in GUI, R interface requires direct use of pre-built                   regressors \n\n-     \"UserDefined\": user-defined trading days regressors (see below)\n\n-    (if NONE) indicating the day of the month when inventories and other stock are reported (to denote the last day of the month, set the variable to 31). \n\n\nLeap Year effect\nAutoadjust\nIf enabled, the program corrects automatically for the leap year effect.. When is the option available Modifications of this variable are taken into account only when transform.function is set to “Auto”.\nLeapyear\nto specify whether or not to include the leap-year effect in the model: - “LeapYear”: leap year effect; - “LengthOfPeriod”: length of period, - “None” = no effect included.\nThe leap-year effect can be pre-specified in the model only if the input series hasn’t been pre-adjusted (transform.adjust set to “None”) and if the automatic correction for the leap-year effect isn’t selected (tradingdays.autoadjust set to FALSE).\n\n\n\nTest\nTest: defines the pre-tests for the significance of the trading day regression variables based on the AICC statistics: “Add” = the trading day variables are not included in the initial regression model but can be added to the Reg-ARIMA model after the test; “Remove” = the trading day variables belong to the initial regression model but can be removed from the RegARIMA model after the test; “None” = the trading day variables are not pre-tested and are included in the model.\n\nEaster\nEaster.enabled a logical. If TRUE, the program considers the Easter effect in the model.\neaster.Julian a logical. If TRUE, the program uses the Julian Easter (expressed in Gregorian calendar).\neaster.duration a numeric indicating the duration of the Easter effect (length in days, between 1 and 20).\neaster.test defines the pre-tests for the significance of the Easter effect based on the t-statistic (the Easter effect is considered as significant if the t-statistic is greater than 1.96): “Add” = the Easter effect variable is not included in the initial regression model but can be added to the Reg-ARIMA model after the test; “Remove” = the Easter effect variable belongs to the initial regression model but can be removed from the RegARIMA model after the test; “None” = the Easter effect variable is not pre-tested and is included in the model.\nA user-defined regressor can also be used, see chapter on calendar correction\n(to be added: additional options in Tramo)\n\n\n\nSetting Calendar correction in GUI\n\nUsing default options (without national calendars)\nIn GUI Use the specification window\nCalendar effects\n\n\n\nSTEP 1: Selection from JDemetra+ Default…or User_defined\n\n\n\n\n\nSTEP2: Calendar effects minus Easter are labeled trading days \n\n\n\n\nHolidays option\nusing a customized calendar just show how to fetch it building process in calendar chapter\n\n\n\nThe list of calendars displayed under Holidays option corresponds to the calendars defined in the Workspace window\n\n\nMissing: stock td option, length-of-period\nUser-defined regressors: adding see below\nLink to Import data Once data imported: here explain how to link variables\n\n\nEaster\n\n\n\neaster Options\n\n\n\n\n\nSetting Calendar correction in R\nIn version 2\n\n# Parameter choice NA=...\ntradingdays.option &lt;- c(NA, \"TradingDays\", \"WorkingDays\", \"UserDefined\", \"None\")\ntradingdays.autoadjust &lt;- NA\ntradingdays.leapyear &lt;- c(NA, \"LeapYear\", \"LengthOfPeriod\", \"None\")\ntradingdays.stocktd &lt;- NA_integer_\ntradingdays.test &lt;- c(NA, \"Remove\", \"Add\", \"None\")\neaster.enabled &lt;- NA\neaster.julian &lt;- NA\neaster.duration &lt;- NA_integer_\neaster.test &lt;- c(NA, \"Add\", \"Remove\", \"None\")\n# example\n\nIn version 3 (Under construction)\n\n\nUser defined regressors\nIf User Defined options is used for trading days, regressors have to be provided by the user.\nBuilding Regressors The underlying methodology and implementation in JDemetra+ to build these regression variables are provided here\n\nAdding Regressors in GUI\nStep 1: import data set containing the regressors, general procedure explained here\nStep 2: Link the regressors to the workspace, procedure detailed here\nStep 3: Modify specifications Modifications are done the same way in a global specification (whole SAP) or series by series.\n\nselect trading days User-defined option and select variables\n\nIn the specification window, click right from “userVariables” on “Unused” to open the variable selection window\n\nMove right the chosen regressors\n\n\nset TEST option (expl)\n\n\n\n\nAdding Regressors in R\n“UserDefined” = user-defined trading days regressors (regressors must be defined by the usrdef.var argument with usrdef.varType set to “Calendar” and usrdef.varEnabled = TRUE).\n\n# example\nspec_4 &lt;- x13_spec(\n    spec = spec_1,\n    tradingdays.option = \"UserDefined\",\n    tradingdays.test = \"None\",\n    usrdef.varEnabled = TRUE,\n    usrdef.varType = \"Calendar\",\n    usrdef.var = reg3\n) # set of regressors in TS format\n\n\n\n\nRetrieving Results\nThe following section details how to retrieve results (parameters, regressors, regression coefficients and tests) when using GUI or R interface.\n\nParameters\nParameters are regressors used in fine. If non test options, parameters are known If test options are selected by the algorithm.\nIn GUI\nAutomatically chosen or user-defined calendar options (as well as other pre-adjustment options) are displayed at the top of the MAIN Results NODE displayed by clicking on a given series name in the SAProcessing panel.\n\nIn R\n(to be added)\nversion 2: RJDemetra\nversion 3: rjd3x13 or rjd3tramoseats\n\n\nRegressors\nIn GUI All regressors in the pre-adjustment phase (calendar, outliers, external) are displayed in the pre-processing-regressors node.\n\nIn R\n(to be added)\nVersion 2\nversion 3\n\n\nRegression results\nRegressions results\nIn GUI\nThe results of the whole Reg-Arima regression (link to last section) including calendar effects (below) are displayed in the pre-processing panel.\n\nIn R\n\n\nTest for residual trading-days effects\nResidual calendar effects are tested with A F-Test 7 regressors and no national calendar, on sa final series and on irregular component (link to calendar chapter for test details)\nIn GUI\nF-Test results are displayed at the bottom of Main Results NODE in the SAProcessing panel\n\n\n\nF-Test results in GUI\n\n\nIn R\n\n\n\nCustomizing Calendars\nThe following describes how to take a national calendar into account.\nSolution 1: if working with GUI build a new calendar in GUI (here\n(to be added: GUI: how to use it or customize HTML file structure explanation)\nset this option in GUI\n(to be added: image: spec window calendar / holidays / choice of calendars)\nset this option in R (to be added) version 2:\nversion 3:\nsolution 2: import external regressors, which can be built with rjd3toolkit (link) which can then be used in via are or imported via GUI\nset this option in GUI how to import variables into JD+ / set utility (in interface chapter) classical user defined\nset this option in R version 2:\nversion 3\nOnce the calendar regressors are set, the Reg-ARIMA (tramo) model will be estimated globally with all the other regression variables and taking into account Arima model specificities as well. That is why diagnostics are all jointly displayed at the end of the process. (link)\n(to be added: worked example: french calendar in R)\n\n\n\nOutliers\nThe sections below focus on\n\noutlier detection parameters (type and critical value)\npre-specifying outliers in a seasonal adjustement (reg-arima modelling) process\n\nAdditional information can be found in this chapter.\n\nOptions for automatic detection\n*Is enabled** outliers; iatip\n  Enables/disables the automatic detection of outliers in the span determined by the **Detection span** option. By default, the checkbox is marked, which implies that the automatic identification of outliers is enabled.\n\nUse default critical value outliers; va\nThe critical value is automatically determined by the number of observations in the interval specified by the Detection span option. When Use default critical value is disabled, the procedure uses the critical value inputted in the Critical value item (see below). Otherwise, the default value is used (the first case corresponds to “critical = xxx”; the second corresponds to a specification without the critical argument). It should be noted that it is not possible to define a separate critical value for each outlier type. By default, the checkbox is marked, which implies that the automatic determination of the critical value is enabled.\n\nCritical value outliers; va\nThe critical value used in the outlier detection procedure. The option is active once Use default critical value is disabled. By default, it is set to 3.5.\nDetection span $$ type outliers; int1, int2*\nA span of the time series to be searched for outliers. The possible values of the parameter are:\n\nAll – full time series span is considered in the modelling;\nFrom – date of the first time series observation included in the pre-processing model;\nTo – date of the last time series observation included in the pre-processing model;\nBetween – date of the first and the last time series observations included in the pre-processing model;\nLast – number of observations from the end of the time series included in the pre-processing model;\nFirst – number of observations from the beginning of the time series included in the pre-processing model;\nExcluding – number of observations excluded from the beginning (specified in the first field) and/or end of the time series (specified in the last field) of the pre-processing model.\n\nWith the options Last, First, Excluding the span can be computed dynamically on the series. The default setting is All.\nAdditive outliers; aio*\nAutomatic identification of additive outliers. By default, this option is enabled.\n\nLevel shift outliers; aio*\nAutomatic identification of level shifts. By default, this option is enabled.\nTransitory change outliers; aio*\nAutomatic identification of transitory changes. By default, this option is enabled.\nSeasonal outlier outliers; aio*\nAutomatic identification of seasonal outliers. By default, this option is disabled. Tramo specific\nEML estimation outliers; imvx\nThe estimation method used in the automatic model identification procedure. By default, the fast method of Hannan-Rissanen is used for parameter estimation in the intermediate steps of the automatic detection and correction of outliers. When the checkbox is marked the exact maximum likelihood estimation method is used.\nTC rateoutliers; deltatc\nThe rate of decay for the transitory change outlier. It takes values between 0 and 1. The default value is 0.7.\n\n\n\nOptions for pre-specified outliers\nUser-defined outliers are used when prior knowledge suggests that certain effects exist at known time points[^14]. Four pre-defined outlier types, which are simple forms of intervention variables, are implemented: * Additive Outlier (AO); * Level shift (LS); * Temporary change[^15] (TC); * Seasonal outliers (SO).\n\n\nSetting in GUI\n\n\n\nAutomatic detection of outliers in GUI\n\n\n\n\n\nOutliers types in GUI\n\n\nPre-specified :\n\nClick on …\nClick on +\nFill the outlier’s information\nClick on Ok\n\n\n\n\nPre-specified outliers in GUI\n\n\nTo change the view to set the outliers, got to Tools –&gt; Options\n\n\n\nOptions in GUI\n\n\nThen to Demetra –&gt; Pre-specified Outliers –&gt; Calendar-like Grid –&gt; Ok\n\n\n\nChange view to calendar\n\n\nThen you have the calendar view (when selecting the pre-specified outliers) :\n\n\n\n**Calendar view in GUI\n\n\n\n\nSetting in R\n(to be added)\n\n\nRetrieving results\n\nParameters\nIn GUI\nIn main results NODE (same info at top of pre-processing NODE)\n\n\n\nMain results in GUI\n\n\n\n\nRegressors\nIn GUI\n\n\n\nRegressors in GUI\n\n\nIn R\n(to be added)\n\n\nRegression details\nIn GUI\n\n\n\nRegression details in GUI\n\n\nIn R\n(to be added)\n\n\n\n\nUser-defined regressors\n(to be added)\n\nrationale\nparameters: assign to a component\n\nPre-treatment regression with additional outliers\n\\[\nY_t = \\sum \\hat{\\alpha}_i O_{it} + \\sum\\hat\\beta_j C_{jt} + \\sum\\hat\\gamma_k Reg_{kt} + y_{lin_t}\n\\]\n\nAllocation to components\n\\(reg= reg_{i}+reg_{t}+reg_{s}+...\\) The user-defined regression variable associated to a specific component should not contain effects that have to be associated with another component. Therefore, the following rules should be observed: * The variable assigned to the trend or to the seasonally adjusted series should not contain a seasonal pattern; * The variable assigned to the seasonal should not contain a trend (or level); * The variable assigned to the irregular should contain neither a seasonal pattern nor a trend (or level). - no external regressors can be assigned to calendar component. It has to be be done via user defined calendar regressors specific part (link)\nRamps and intervention variables are Specific cases of external regressors\n\n\nSetting in GUI\nUser-defined variables\nStep 1: import data set containing the regressors, general procedure explained here\nStep 2: Link the regressors to the workspace, procedure detailed here\nStep 3: Modify specifications via window\nModifications are done the same way in a global specification (whole SAP) or series by series.\n\n\n\nCreation of user-defined variables in GUI\n\n\n\n\nSetting in R\n(to be added)\n\n\nSpecial case 1: Ramp effects\nA ramp effect means a linear increase or decrease in the level of the series over a specified time interval \\(t_{0}\\) to \\(\\ t_{1}\\). All dates of the ramps must occur within the time series span. (tested: not true). Ramps can overlap other ramps, additive outliers and level shifts.\n\nCreation in GUI\n\n\n\nCreation of ramp variable in GUI\n\n\n\n\nAllocation to components\nallocation when intervention or ramps ? in test allocated to trend ? (reg)\nimpossible (?) to create several intervention variables\n\n\n\nSpecial case 2: Intervention variables\nIntervention variables are modeled as any possible sequence of ones and zeros, on which some operators may be applied. They are built as combinations of the following basic structures:\n\nDummy variables [^17];\nAny possible sequence of ones and zeros;\n\\(\\frac{1}{(1 - \\delta B)}\\),\n\\((0 &lt; \\delta \\leq 1)\\)\n\\(\\frac{1}{(1 - \\delta_{s}B^{s })}\\),\n\\((0 &lt; \\delta_{s} \\leq 1)\\);\n\\(\\frac{1}{(1 - B)(1 - B^{s})}\\);\n\nwhere \\(B\\) is backshift operator (i.e. \\(B^{k}X_{t} = X_{t - k}\\)) and \\(s\\) is frequency of the time series (\\(s = 12\\) for a monthly time series, \\(s = 4\\) for a quarterly time series).\nThese basic structures enable the generation of not only AO, LS, TC, SO and RP outliers but also sophisticated intervention variables that are well-adjusted to the particular case.\n\nCreation in GUI\n\n\n\nStep 1\n\n\n\n\n\nStep 2\n\n\n\n\n\nStep 3\n\n\n\n\nCreation in R\n(to be added)\n\n\nAllocation to components\nallocation (to be added)\nfixed coefficient options\n\nFixed regression coefficients regression variables; –\nFor the pre-specified regression variables this option specifies the parameter estimates that will be held fixed at the values provided by the user. To fix a coefficient the user should undertake the following actions:\n\nChoose the transformation (log or none).\nDefine some regression variables in the Regressors specification.\nPush on the fixed regression coefficients editor button in the User-defined variables row.\nSelect the regression variable from the list for which the coefficient will be fixed.\nSave the new setting with the Done button.\n\n\nOverview: differences GUI set up vs R set up\n\n\n\nRetrieving Results\nFor all types of external regressors: user-defined, ramps or intervention variables.\n\nRegressors\nIn GUI\nTo retrieve regressors that were actually used, expand pre-processing NODE and click on Regressors pane.\n\n\n\nRegressors in GUI\n\n\nIn R\n(to be added )\n\n\nRegression details\nIn GUI\nRegression details are in the pre-processing pane.\n\n\n\nRegression details\n\n\nIN R\n\n\n\n\nArima Model\nKey specifications on Arima modelling are embedded in default specifications: airline (default model) or full automatic research.(links)\nTwo kinds of interventions are available to the user\n\nmodify automatic detection parameters\nset a user defined Arima model\n\nIn both cases forecast horizon can also be set (link)\n\nOptions for modifying automatic detection\nautomdl.enabled If TRUE, the automatic modelling of the ARIMA model is enabled. (If FALSE, the parameters of the ARIMA model can be specified, see below)\nControl variables for the automatic modelling of the ARIMA model (when automdl.enabled is set to TRUE):\nautomdl.acceptdefault a logical. If TRUE, the default model (ARIMA(0,1,1)(0,1,1)) may be chosen in the first step of the automatic model identification. If the Ljung-Box Q statistics for the residuals is acceptable, the default model is accepted and no further attempt will be made to identify another model.\nautomdl.cancel the cancellation limit (numeric). If the difference in moduli of an AR and an MA roots (when estimating ARIMA(1,0,1)(1,0,1) models in the second step of the automatic identification of the differencing orders) is smaller than the cancellation limit, the two roots are assumed equal and cancel out.\nautomdl.ub1 the first unit root limit (numeric). It is the threshold value for the initial unit root test in the automatic differencing procedure. When one of the roots in the estimation of the ARIMA(2,0,0)(1,0,0) plus mean model, performed in the first step of the automatic model identification procedure, is larger than the first unit root limit in modulus, it is set equal to unity.\nautomdl.ub2 the second unit root limit (numeric). When one of the roots in the estimation of the ARIMA(1,0,1)(1,0,1) plus mean model, which is performed in the second step of the automatic model identification procedure, is larger than second unit root limit in modulus, it is checked if there is a common factor in the corresponding AR and MA polynomials of the ARMA model that can be cancelled (see automdl.cancel). If there is no cancellation, the AR root is set equal to unity (i.e. the differencing order changes).\nautomdl.mixed a logical. This variable controls whether ARIMA models with non-seasonal AR and MA terms or seasonal AR and MA terms will be considered in the automatic model identification procedure. If FALSE, a model with AR and MA terms in both the seasonal and non-seasonal parts of the model can be acceptable, provided there are no AR or MA terms in either the seasonal or non-seasonal terms.\nautomdl.balanced a logical. If TRUE, the automatic model identification procedure will have a preference for balanced models (i.e. models for which the order of the combined AR and differencing operator is equal to the order of the combined MA operator).\nautomdl.armalimit the ARMA limit (numeric). It is the threshold value for t-statistics of ARMA coefficients and constant term used for the final test of model parsimony. If the highest order ARMA coefficient has a t-value smaller than this value in magnitude, the order of the model is reduced. If the constant term t-value is smaller than the ARMA limit in magnitude, it is removed from the set of regressors.\nautomdl.reducecv numeric, ReduceCV. The percentage by which the outlier’s critical value will be reduced when an identified model is found to have a Ljung-Box statistic with an unacceptable confidence coefficient. The parameter should be between 0 and 1, and will only be active when automatic outlier identification is enabled. The reduced critical value will be set to (1-ReduceCV)*CV, where CV is the original critical value.\nautomdl.ljungboxlimit the Ljung Box limit (numeric). Acceptance criterion for the confidence intervals of the Ljung-Box Q statistic. If the LjungBox Q statistics for the residuals of a final model is greater than the Ljung Box limit, then the model is rejected, the outlier critical value is reduced and model and outlier identification (if specified) is redone with a reduced value.\nautomdl.ubfinal numeric, final unit root limit. The threshold value for the final unit root test. If the magnitude of an AR root for the final model is smaller than the final unit root limit, then a unit root is assumed, the order of the AR polynomial is reduced by one and the appropriate order of the differencing (non-seasonal, seasonal) is increased. The parameter value should be greater than one.\n(for both options) fcst.horizon the forecasting horizon (numeric). The forecast length generated by the Reg-Arima model in periods (positive values) or years (negative values). By default, the program generates a two-year forecast (fcst.horizon set to -2). Defaults different in GUI and R.\n\nv2v3\n\n\n\n\n\nSetting in GUI in v2\n\n\n\n\n\n\n\nSetting in GUI in v3\n\n\n\n\n\nForecast horizon when using TRAMO-SEATS Is set in the decomposition part of the specification in GUI.\n\n\n\nForecast horizon when using TRAMO-SEATS\n\n\n\n\n\nForecast horizon when using X13-ARIMA\n\n\nSetting in R (first template, then worked example) X13-ARIMA template in version 2\n\nspec_2 &lt;- x13_spec(\n    spec = spec_1,\n    automdl.enabled = NA,\n    automdl.acceptdefault = NA,\n    automdl.cancel = NA_integer_,\n    automdl.ub1 = NA_integer_,\n    automdl.ub2 = NA_integer_,\n    automdl.mixed = NA,\n    automdl.balanced = NA,\n    automdl.armalimit = NA_integer_,\n    automdl.reducecv = NA_integer_,\n    automdl.ljungboxlimit = NA_integer_,\n    automdl.ubfinal = NA_integer_\n)\n\nadd worked example in version 2\nin version 3\nadd worked example in version 3\n\n\nOptions for setting a user-defined Arima model\nControl variables for the non-automatic modelling of the ARIMA model (when automdl.enabled is set to FALSE):\narima.mu logical. If TRUE, the mean is considered as part of the ARIMA model.\narima.p numeric. The order of the non-seasonal autoregressive (AR) polynomial.\narima.d numeric. The regular differencing order.\narima.q numeric. The order of the non-seasonal moving average (MA) polynomial.\narima.bp numeric. The order of the seasonal autoregressive (AR) polynomial.\narima.bd numeric. The seasonal differencing order.\narima.bq numeric. The order of the seasonal moving average (MA) polynomial.\nControl variables for the user-defined ARMA coefficients. Coefficients can be defined for the regular and seasonal autoregressive (AR) polynomials and moving average (MA) polynomials. The model considers the coefficients only if the procedure for their estimation (arima.coefType) is provided, and the number of provided coefficients matches the sum of (regular and seasonal) AR and MA orders (p,q,bp,bq).\narima.coefEnabled logical. If TRUE, the program uses the user-defined ARMA coefficients.\narima.coef a vector providing the coefficients for the regular and seasonal AR and MA polynomials. The vector length must be equal to the sum of the regular and seasonal AR and MA orders. The coefficients shall be provided in the following order: regular AR (Phi; p elements), regular MA (Theta; q elements), seasonal AR (BPhi; bp elements) and seasonal MA (BTheta; bq elements). E.g.: arima.coef=c(0.6,0.7) with arima.p=1, arima.q=0,arima.bp=1 and arima.bq=0.\narima.coefType a vector defining the ARMA coefficients estimation procedure. Possible procedures are: “Undefined” = no use of any user-defined input (i.e. coefficients are estimated), “Fixed” = the coefficients are fixed at the value provided by the user, “Initial” = the value defined by the user is used as the initial condition. For orders for which the coefficients shall not be defined, the arima.coef can be set to NA or 0, or the arima.coefType can be set to “Undefined”. E.g.: arima.coef = c(-0.8,-0.6,NA), arima.coefType = c(“Fixed”,“Fixed”,“Undefined”).\nSetting in GUI\n\n\n\nManual ARIMA modeling\n\n\n\n\n\nFixing coefficients\n\n\nSetting in R\nX13-ARIMA template in version 2\n\nspec_2 &lt;- x13_spec(\n    spec = spec_1,\n    automdl.enabled = FALSE,\n    arima.mu = NA,\n    arima.p = NA_integer_,\n    arima.d = NA_integer_,\n    arima.q = NA_integer_,\n    arima.bp = NA_integer_,\n    arima.bd = NA_integer_,\n    arima.bq = NA_integer_,\n    arima.coefEnabled = NA,\n    arima.coef = NA,\n    arima.coefType = NA,\n    fcst.horizon = NA_integer_\n)\n\nin version 3\n\n\n\nReg-Arima model Results and Diagnostics\nType of results (including Tramo addenda)\n\nall regressors used (shown above)\nregression details: explanatory variables (above)\nArima model specific results\nadditional diagnostics on residuals\nlikelihood\nseasonality tests on residuals\n\n\nDisplay in GUI\nReg-Arima model detail with other regression results in pre-processing pane. with number of observations.. parameters\n\n\n\nFinal model\n\n\nMore details in Pre-processing/Arima Node\n\n\n\nArima details\n\n\nIn residual Node\n\n\n\nResiduals\n\n\n\n\n\nDistribution\n\n\n\n\n\nLikelihood\n\n\n\nSeasonality tests on residuals in the Diagnostics NODE\n\n\n\nResiduals"
  },
  {
    "objectID": "A-sa-X11-decomposition.html#in-this-chapter",
    "href": "A-sa-X11-decomposition.html#in-this-chapter",
    "title": "SA: X11 Decomposition",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter focuses on practical implementation of an X11 decomposition using the graphical user interface GUI and R using R packages in version 2.x and 3.x. More explanations on X11 algorithm can be found here.\nIn recent years X11 has been tailored in JDemetra+ to handle high-frequency (infra-monthly) data, which is described here with more methodological details here.\nThe sections below will describe\n\nspecifications needed to run X11\ngenerated output\nseries\ndiagnostics\nfinal parameters\nuser-defined parameters"
  },
  {
    "objectID": "A-sa-X11-decomposition.html#context-of-use",
    "href": "A-sa-X11-decomposition.html#context-of-use",
    "title": "SA: X11 Decomposition",
    "section": "Context of use",
    "text": "Context of use\nX11 algorithm is generally the second (decomposition) step in a seasonal adjustment processing with X-13-Arima, once a pre-treatment phase has been performed. In this case X11 will decompose the linearized series using iteratively different moving averages. The effects of pre-treatment will be reallocated at the end the the relevant components. X11 can also be used without pre-treatment, choosing and will decompose the raw series."
  },
  {
    "objectID": "A-sa-X11-decomposition.html#a-sa-X11-tools-X11",
    "href": "A-sa-X11-decomposition.html#a-sa-X11-tools-X11",
    "title": "SA: X11 Decomposition",
    "section": "Tools for X11 decomposition",
    "text": "Tools for X11 decomposition\n\n\n\n\n\n\n\n\n\nAlgorithm\nAccess in GUI (v2 and v3)\nAccess in R (v2)\nAccess in R (v3)\n\n\n\n\nX-13 Arima\n✔️\nRJDemetra\nrjd3x13\n\n\nX11 decomposition only\n✔️\nRJDemetra\nrjd3x13\n\n\n\nAvailable frequencies in version 2 and version 3\n\n\n\nVersion\nGUI and R\n\n\n\n\nv 2.x\n\\(p=12, 4, 2\\)\n\n\nv 3.x\n\\(p=12, 6, 4, 3, 2\\)"
  },
  {
    "objectID": "A-sa-X11-decomposition.html#a-sa-X11-default-specs",
    "href": "A-sa-X11-decomposition.html#a-sa-X11-default-specs",
    "title": "SA: X11 Decomposition",
    "section": "Default specifications",
    "text": "Default specifications\nThe default specifications for X11 must be chosen at the start of the SA processing, one of the options available there is to run a X11 decomposition without pre-treatment.\nThey are detailed in the chapter on pre-treatment."
  },
  {
    "objectID": "A-sa-X11-decomposition.html#quick-launch",
    "href": "A-sa-X11-decomposition.html#quick-launch",
    "title": "SA: X11 Decomposition",
    "section": "Quick Launch",
    "text": "Quick Launch\n\nFrom GUI\nWith a workspace open, an SAProcessing created and an open data provider: (link to GUI general process)\n\nchoose a default specification\ndrop your data and press green arrow\n\n\n\nIn R\n\nIn version 2 using RJDemetra\n\nlibrary(\"RJDemetra\")\n# the input series has to be a Time Series (TS) object\n# specification RSA5c including pre-treatment\nmodel_sa_v2 &lt;- x13(raw_series, spec = \"RSA5c\")\n# specification X11 without pre-treatment\nmodel_sa_v2 &lt;- x13(raw_series, spec = \"X11\")\n\nFull documentation of ‘RJDemetra::x13’ function can be found here\nThe model_sa_v2 R object (list of lists) contains all parameters and results. Its structure is detailed here. It can be printed giving access to selected parameters, series and diagnostics.\n\nprint(model_sa_v2)\n\n\n\nIn version 3 using rjd3x13\n\nlibrary(\"rjd3toolkit\")\nlibrary(\"rjd3x13\")\n# the input series has to be a Time Series (TS) object\nmodel_sa_v3 &lt;- rjd3x13::x13(y_raw, spec = \"RSA5\")\n\nFull documentation of ‘rjd3x13::x13’ function can be found here and of ‘rjd3x13::X11’ here.\nThe model_sa_v3 R object (list of lists) contains all parameters and results. Its structure is detailed here.\nIt can be printed giving access to selected parameters, series and diagnostics.\n\nprint(model_sa_v3)"
  },
  {
    "objectID": "A-sa-X11-decomposition.html#a-sa-X11-out-series",
    "href": "A-sa-X11-decomposition.html#a-sa-X11-out-series",
    "title": "SA: X11 Decomposition",
    "section": "Retrieve series",
    "text": "Retrieve series\n\nDisplay in GUI\nFinal components from the SA Processing are displayed in Main results. They contain the re-allocated pre-adjustment effects of outliers (link) or external regressors (link). The final seasonal components contains the calendar effects, if any.\n\n\n\nFinal components in GUI\n\n\n(forecasts are added at the end of the series, values in italic)\nDetailed results from decomposition are displayed in Decomposition (X11) node.\n\n\n\nDetailed results\n\n\nThe final D Tables contain the re-allocated pre-adjustment effects.\n(to be checked: v2 vs v3 on pre-treatment effects in D tables)\nOutput series can be exported out of GUI by two means:\n\ngenerating output files directly with interactive menus\nrunning the cruncher to generate those files as described here\n\n\n\nRetrieve in R\nIn version 2\n\nmodel_sa &lt;- x13(raw_series, spec = \"RSA3\") # user's spec choice\n# final components\nmodel_sa$final$series\n# final forecasts y_f sa_f s_f t_f i_f\nmodel_sa$final$forecasts\n\nDetailed X11 tables have to be pre-specified from the user-defined output list.\n\n# display the list of available objects (series, diagnostics, parameters)\nuser_defined_variables(\"X13-ARIMA\")\n# add selected object to estimation\nsa_x13_v2 &lt;- RJDemetra::x13(myseries, myspec,\n    userdefined = c(\"decomposition.c20\", \"decomposition.d1\")\n)\n# retrieve in the user-defined sub-list\nsa_x13_v2$user_defined\n\nto be modified In version 3\n\n# final components\nmodel_sa$final$series\n# final forecasts y_f sa_f s_f t_f i_f\nmodel_sa$final$forecasts\n# from user defined output"
  },
  {
    "objectID": "A-sa-X11-decomposition.html#a-sa-X11-diags",
    "href": "A-sa-X11-decomposition.html#a-sa-X11-diags",
    "title": "SA: X11 Decomposition",
    "section": "Diagnostics",
    "text": "Diagnostics\nX11 produces the following type diagnostics or quality measures\n\nSI-ratios\n\nDisplay in GUI\nNODE Main Results &gt; SI-Ratios\n\n\n\nS-I Ratio\n\n\nFor each period (month, quarter) the final value of the seasonal factors (without calendar factors, Table D10) is plotted (blue line). The dots represent \\(S+I\\) or \\(S*I\\) in the multiplicative case, where I= Table D8. The red straight line is the average of the factors over the decomposition (estimation) span.\nIn GUI all values cannot be retrieved.\n\n\nRetrieve in R\nAll the values and the same plot as described above can be generated in R, the span can be customized.\n(to be checked the average of the seasonal factors is not recalculated if span modified )\nIn version 2\n\n# data frame with values\nmodel_sa_v2$decomposition$si_ratio\n\n# customizable plot\nplot(mysa2$decomposition)\n\nplot(model_sa, type = \"cal-seas-irr\", first_date = c(2015, 1))\n\nIn version 3\n\n# data frame with values\nmodel_sa_v2$decomposition$si_ratio\n\n# customizable plot\nplot(mysa2$decomposition)\n\nplot(model_sa, type = \"cal-seas-irr\", first_date = c(2015, 1))\n\n\n\n\nM-statistics\nX11 algorithm provides quality measures of the decomposition called “M statistics” (detailed here\n\n11 statistics (M1 to M11)\n2 summary indicators (Q et Q-M2)\nby design \\(0&lt;M_x&lt;3\\) and acceptance region is \\(M_x \\leq 1\\)\n\n\nDisplay in GUI\nTo display results in GUI, expand NODE\nDecomposition(X11) &gt; Quality Measures &gt; Summary\nResults displayed in red indicate that the test failed.\n\n\n\nText\n\n\n\n\nRetrieve in R\nIn version 2\n\n# this code snippet is not self-sufficient\nmodel_sa$decomposition$mstats\n\nIn version 3\n\n# this code snippet is not self-sufficient\nmodel_sa$decomposition$mstats\n\n\n\nDetailed Quality measures\nIn GUI all the diagnostics below can be displayed expanding the NODE\nDecomposition(X11) &gt; Quality Measures &gt; Details\nThey are detailed in the X11 method chapter\nIn R (to be added): not directly available ?!\n\n\n\nRetrieve final filters\nThe following parameters are automatically chosen by the software as a result of the estimation process. They have no default value but can be set by the user.\n\nFinal trend filter: length of Henderson filter applied for final trend estimation (in the second part of the D step).\nFinal seasonal filer: length of final seasonal filter for seasonal component estimation (in the second part of the D step).\n\n\nDisplay in GUI\nNode Decomposition(X11) &gt; Final Filters\n\n\n\nText\n\n\n\n\nRetrieve in R\nIn version 2\n\nlibrary(\"RJDemetra\")\nmodel_sa_v2 &lt;- x13(raw_seriesa, spec = \"RSA5c\")\nmodel_sa$decomposition$s_filter\nmodel_sa$decomposition$t_filter\n\nIn version 3\n\nlibrary(\"rjd3toolkit\")\nlibrary(\"rjd3x13\")\nmodel_sa_v3 &lt;- rjd3x13::x13(y_raw, spec = \"RSA5\")\nmodel_sa_v3$result$decomposition$final_seasonal\nmodel_sa_v3$result$decomposition$final_henderson\n\n\n\n\nUser-defined parameters\nThe following parameters have default values, which will not be changed in the estimation process. They can be set by the user in a given range of admissible values.\n\nGeneral settings\n\nMode\n\nUndefined: automatically chosen between Multiplicative and Additive Options available only if no pre-processing:\nAdditive: \\(Y=T+S+I\\), \\(SA =Y-S=T+I\\)\nMultiplicative \\(Y=T*S*I\\), \\(SA =Y/S=T*I\\)\nLogAdditive \\(Log(Y) = T + S + I\\), \\(SA=exp(T+I)=Y/exp(S)\\)\nPseudoAdditive \\(Y=T*(S+I-1)\\), \\(SA=T*I\\)\n\n\nIf X11 decomposition comes after a pre-processing, mode is set to undefined and will correspond to decomposition choice (link) made in the pre-treatment: multiplicative if series log- transformed, additive otherwise.\n\nSeasonal component\n\nOption available only if no pre-processing: - yes (default), decomposition into \\(S\\), \\(T\\), \\(I\\) - no, decomposition into \\(S\\), \\(T\\), \\(I\\)\n\nForecasts horizon\n\nLength of the forecasts generated by the Reg-Arima model - in months (positive values) - years (negative values) - if set to is set to 0, the X11 procedure does not use any model-based forecasts but the original X11 type forecasts for one year. - default value: -1, thus one year from the Arima model\n\nBackcasts horizon\n\nLength of the backcasts generated by the Reg-Arima model - in months (positive values) - years (negative values) - default value: 0\n\nIrregular correction\n\nLSigma\n\nsets lower sigma (standard deviation) limit used to down-weight the extreme irregular values in the internal seasonal adjustment iterations\nvalues in \\([0,Usigma]\\)\ndefault value is 1.5\n\nUSigma\n\nsets upper sigma (standard deviation)\nvalues in \\([Lsigma,+\\infty]\\)\ndefault value is 2.5\n\nCalendarsigma\n\nAllows to set different LSigma and USigma for each period - None (default) - All: standard errors used for the extreme values detection and adjustment computed separately for each calendar month/quarter - Signif: groups determined by Cochran test (check) - Sigmavec: set two customized groups of periods\n\nExcludeforecasts\n\nticked: forecasts and backcasts from the Reg-Arima model not used in Irregular Correction\nunticked (default): forecasts and backcasts used\n\n\n\n\nSeasonality extraction filters choice\n\nSeasonal filter\n\nSpecifies which filters will be used to estimate the seasonal factors for the entire series.\n\ndefault value: MSR Moving seasonality ratio, automatic choice of final seasonal filter, initial filters are \\(3\\times 3\\)\nchoices: \\(3\\times 1\\), \\(3\\times 3\\), \\(3\\times 5\\), \\(3\\times 9\\), \\(3\\times 15\\) or Stable\n“Stable”: constant factor for each calendar period (simple moving average of a all \\(S+I\\) values for each period)\n\nUser choices will be applied to final phase D step.\nThe seasonal filters can be selected for the entire series, or for a particular month or quarter.\n\nDetails on seasonal filters\n\nSets different seasonal filters by period in order to account for seasonal heteroskedasticity\n\ndefault value: empty, same filter for all periods\n\n\n\nTrend estimation filters\n\nAutomatic Henderson filter or user-defined\n\ndefault: length 13\nunticked: user-defined length choice\n\nHenderson filter length choice\n\nvalues: odd number in \\([3,101]\\)\ndefault value: 13\n\n\nCheck: will user choice be applied to all steps or only to final phase D step\n\n\n\nParameter setting in GUI\nAll the parameters above can be set with in the specification box\n\n\n\nText\n\n\nSetting details on seasonal filters\n\n\n\nSeasonnal filters\n\n\nPreviously set values are displayed for each type of period, here they are all to default MSR choice.\nClick on the right top button (show on image)\nAnother window appears in the top-left corner allowing to chose the filter period by period.\n\n\n\nText\n\n\n\n\nParameter setting in R packages\nIn version 2 using RJDemetra\n\ncurrent_sa_model &lt;- x13(raw_series, spec = current_spec)\n# Creating a modified specification, customizing all available X11 parameters\nmodified_spec &lt;- x13_spec(current_sa_model,\n    X11.mode=NA,\n    X11.seasonalComp = NA,\n    X11.fcasts = -2,\n    X11.bcasts = -1,\n    X11.lsigma = 1.2,\n    X11.usigma = 2.8,\n    X11.calendarSigma = NA,\n    X11.sigmaVector = NA,\n    X11.excludeFcasts = NA,\n    # filters\n    X11.trendAuto = NA,\n    X11.trendma = 23,\n    X11.seasonalma = \"S3X9\"\n)\n\n# New SA estimation: apply modified_spec\nmodified_sa_model &lt;- x13(raw_series, modified_spec)\n\nIn version 3 using rjd3x13\n\n# Creating a modified specification, customizing all available X11 parameters\nlibrary(\"RJDemetra\")\nmodel_sa_v2 &lt;- x13(raw_series, spec = \"RSA5c\")\n# Creating a modified specification from the current estimation model\n# Customizing all available X11 parameters\nmodified_spec &lt;- x13_spec(model_sa_v2,\n    X11.fcasts = -2,\n    X11.bcasts = -1,\n    X11.lsigma = 1.2,\n    X11.usigma = 2.8,\n    X11.calendarSigma = NA,\n    X11.sigmaVector = NA,\n    X11.excludeFcasts = NA,\n    # filters\n    X11.trendAuto = NA,\n    X11.trendma = 23,\n    X11.seasonalma = \"S3X9\"\n)\n\n# New SA estimation: apply modified_spec\n\nmodified_sa_model &lt;- x13(raw_series, modified_spec)\n\n\n# For options available only in X11 mode\nmodified_spec &lt;- x13_spec(model_sa_v2,\n    # X11.mode=\"?\",\n    # X11.seasonalComp = \"?\",\n    X11.fcasts = -2\n)\n\n\n\nRetrieving Parameters\nHow to see what parameters have actually been used.\nIn GUI: just open the specification box and navigate the options.\nIn R, print your model or navigate its elements."
  },
  {
    "objectID": "A-sa-seats-decomposition.html#in-this-chapter",
    "href": "A-sa-seats-decomposition.html#in-this-chapter",
    "title": "SA: SEATS Decomposition",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter focuses on practical implementation of a SEATS decomposition using the graphical user interface GUI and R using R packages in version 2.x and 3.x. More explanations on SEATS algorithm can be found here.\nIn recent years SEATS has been tailored in JDemetra+ to handle high-frequency (infra-monthly) data, which is described here with more methodological details here.\nThe sections below will describe\n\nspecifications needed to run SEATS\ngenerated output\nseries\ndiagnostics\nfinal parameters\nuser-defined parameters"
  },
  {
    "objectID": "A-sa-seats-decomposition.html#context",
    "href": "A-sa-seats-decomposition.html#context",
    "title": "SA: SEATS Decomposition",
    "section": "Context",
    "text": "Context\nSEATS is the second (decomposition) step in a seasonal adjustment processing with Tramo-Seats, once a pre-treatment with Tramo has been performed. SEATS is an Arima Model Based (AMB) algorithm and will decompose the linearized series using the arima model fit in Tramo."
  },
  {
    "objectID": "A-sa-seats-decomposition.html#tools-for-seats-decomposition",
    "href": "A-sa-seats-decomposition.html#tools-for-seats-decomposition",
    "title": "SA: SEATS Decomposition",
    "section": "Tools for Seats decomposition",
    "text": "Tools for Seats decomposition\n\n\n\nAlgorithm\nAccess in GUI\nAccess in R (v2)\nAccess in R v3\n\n\n\n\nTramo-Seats\n✔️\nRJDemetra\nrjd3tramoseats\n\n\nTramo only\n✔️\nRJDemetra\nrjd3tramoseats\n\n\n\nAvailable frequencies in version 2 and version 3\n\n\n\nVersion\nGUI and R\n\n\n\n\nv 2.x\n\\(p=12, 6, 4, 2\\)\n\n\nv 3.x\n\\(p=12, 6, 4, 3, 2\\)"
  },
  {
    "objectID": "A-sa-seats-decomposition.html#seats-decomposition",
    "href": "A-sa-seats-decomposition.html#seats-decomposition",
    "title": "SA: SEATS Decomposition",
    "section": "SEATS Decomposition",
    "text": "SEATS Decomposition\nSEATS algorithm will decompose the linearized series, in level or in logarithm, using the Arima model fitted by Tramo in the pre-treatment phase."
  },
  {
    "objectID": "A-sa-seats-decomposition.html#quick-launch",
    "href": "A-sa-seats-decomposition.html#quick-launch",
    "title": "SA: SEATS Decomposition",
    "section": "Quick Launch",
    "text": "Quick Launch\n\nDefault specifications\nThe default specifications for SEATS must be chosen at the starting of the SA processing. Starting point for TRAMO-SEATS, detailed here\n\n\nUsing GUI\nWith a workspace open, an SAProcessing created and open data provider:\n\nchoose a default specification (link)\ndrop your data and press green arrow (link)\n\n\n\nIn R\n\nIn version 2 using RJDemetra\n\nlibrary(\"RJDemetra\")\n# the input series has to be a Time Series (TS) object\n# specification RSAfull including pre-treatment\nmodel_sa_v2 &lt;- tramoseats(raw_series, spec = \"RSAfull\")\n\nFull documentation of ‘RJDemetra::tramoseats’ function can be found here\nThe model_sa_v2 R object (list of lists) contains all parameters and results. Its structure is detailed here. It can be printed giving access to selected parameters, series and diagnostics.\n\nprint(model_sa_v2)\n\n\n\nIn version 3 using rjd3tramoseats\n\nlibrary(\"rjd3tramoseats\")\nmodel_sa_v3 &lt;- tramoseats(raw_series, spec = \"RSAfull\")\n# the input series has to be a Time Series (TS) object\n\nFull documentation of ‘rjd3tramoseats::tramoseats’ function can be found here.\nThe model_sa_v3 R object (list of lists) contains all parameters and results. Its structure is detailed here.\nIt can be printed giving access to selected parameters, series and diagnostics.\n\nprint(model_sa_v3)"
  },
  {
    "objectID": "A-sa-seats-decomposition.html#a-sa-SEATS-out-series",
    "href": "A-sa-seats-decomposition.html#a-sa-SEATS-out-series",
    "title": "SA: SEATS Decomposition",
    "section": "Retrieve Series",
    "text": "Retrieve Series\nThis section outlines how to retrieve the different kinds of output series from GUI or in R.\n\nfinal components (including reallocation of pre-adjustment effects)\ncomponents in level\ncomponents in level or log\n\n\nStochastic series\nDecomposition of the linearized series or of its logarithm (in case of a multiplicative model)\ny_lin is split into components: t_lin, s_lin, i_lin\nsuffixes: - _f stands for forecast - _e stands for - _ef stands for\n\nDisplay in GUI\nNODE Decomposition&gt;Stochastic series - Table with series and its standard error image\n\nPlot of Trend with confidence interval image\nPlot of Seasonal component with confidence interval image\n\n\n\nRetrieve from GUI\nGenerating output from GUI (link) or from Cruncher (link), stochastic series, their standard errors, forecasts and forecasts errors can be accessed with the following names\n\n\n\nSeries Name\nMeaning\n\n\n\n\ndecomposition.y_lin\n\n\n\ndecomposition.y_lin_f\n\n\n\ndecomposition.y_lin_ef\n\n\n\ndecomposition.t_lin\n\n\n\ndecomposition.t_lin_f\n\n\n\ndecomposition.t_lin_e\n\n\n\ndecomposition.t_lin_f\n\n\n\ndecomposition.sa_lin\n\n\n\ndecomposition.sa_lin_f\n\n\n\ndecomposition.sa_lin_e\n\n\n\ndecomposition.sa_lin_ef\n\n\n\ndecomposition.s_lin\n\n\n\ndecomposition.s_lin_f\n\n\n\ndecomposition.s_lin_e\n\n\n\ndecomposition.s_lin_ef\n\n\n\ndecomposition.i_lin\n\n\n\ndecomposition.i_lin_f\n\n\n\ndecomposition.i_lin_e\n\n\n\ndecomposition.i_lin_ef\n\n\n\n\n\n\nRetrieve in R\nIn version 2\n\nlibrary(\"RJDemetra\")\n# list of additional output objects\nuser_defined_variables(\"TRAMO-SEATS\")\n# specify additional objects in estimation\nm &lt;- tramoseats(\n    series = y,\n    spec = \"RSAfull\",\n    userdefined = c(\n        \"decomposition.y_lin\", \"ycal\",\n        \"variancedecomposition.seasonality\"\n    )\n)\n# retrieve objects\nm$user_defined$decomposition.y_lin\nm$user_defined$ycal\nm$user_defined$variancedecomposition.seasonality\n\nIn version 3\n\nlibrary(\"rjd3tramoseats\")\n# list of additional output objects\nuserdefined_variables_tramoseats(\"tramoseats\")\n# specify additional objects in estimation\nm &lt;- tramoseats(\n    ts = y,\n    spec = \"RSAfull\",\n    userdefined = c(\n        \"decomposition.y_lin\", \"ycal\",\n        \"variancedecomposition.seasonality\"\n    )\n)\n# retrieve objects\nm$user_defined$decomposition.y_lin\nm$user_defined$ycal\nm$user_defined$variancedecomposition.seasonality\n\n\n\n\nComponents (Level)\nDecomposition of the linearized series, back to level in case of a multiplicative model.\ny_lin is split into components: t_lin, s_lin, i_lin\nsuffixes: - _f stands for forecast - _e stands for - _ef stands for\n\nDisplayed in GUI\nNODE Decomposition&gt;Components - Table with series and its standard error image\n\n\nRetrieve from GUI\nGenerating output from GUI (link) or from Cruncher (link), component series, their standard errors, forecasts and forecasts errors can be accessed with the following names\n\n\n\nSeries Name\nMeaning\n\n\n\n\ndecomposition.y_cmp\n\n\n\ndecomposition.y_cmp_f\n\n\n\ndecomposition.y_cmp_ef\n\n\n\ndecomposition.t_cmp\n\n\n\ndecomposition.t_cmp_f\n\n\n\ndecomposition.t_cmp_e\n\n\n\ndecomposition.t_cmp_f\n\n\n\ndecomposition.sa_cmp\n\n\n\ndecomposition.sa_cmp_f\n\n\n\ndecomposition.sa_cmp_e\n\n\n\ndecomposition.sa_cmp_ef\n\n\n\ndecomposition.s_cmp\n\n\n\ndecomposition.s_cmp_f\n\n\n\ndecomposition.s_cmp_e\n\n\n\ndecomposition.s_cmp_ef\n\n\n\ndecomposition.i_cmp\n\n\n\ndecomposition.i_cmp_f\n\n\n\ndecomposition.i_cmp_e\n\n\n\ndecomposition.i_cmp_ef\n\n\n\n\n\n\nRetrieve in R\nSame procedure as for stochastic series.\n\n\nBias correction\nto be added\n\n\n\nFinal series\n\n\n\n\n\n\n\n\n\nSeries\nFinal SEATS components\nFinal Results\nReallocation of pre-adjustment effects\n\n\n\n\nRaw series (forecasts)\n\ny (y_f)\n\n\n\nLinearized series\n\n\nnone\n\n\nFinal seasonal component\n\ns (s_f)\n\n\n\nFinal trend\n\nt (t_f)\n\n\n\nFinal irregular\n\ni (i_f)\n\n\n\nCalendar component\n\n\n\n\n\nSeasonal without calendar\n\n\n\n\n\n\n(to be added: reallocation of outliers effects)\n\nDisplay in GUI\nFinal results are displayed for each series in the NODE MAIN&gt;Table\n\n\n\nText\n\n\nForecasts are glued at the end it italic\n\n\nRetrieve from GUI\nGenerating output from GUI (link) or from Cruncher (link), component series, their standard errors, forecasts and forecasts errors can be accessed with the following names\n\n\n\nSeries Name\nMeaning\n\n\n\n\ny\n\n\n\ny_f\n\n\n\nt\n\n\n\nt_f\n\n\n\nsa\n\n\n\nsa_f\n\n\n\ns\n\n\n\ns_f\n\n\n\ni\n\n\n\ni_f\n\n\n\n\n\n\nRetrieve in R\nIn version 2\n\nlibrary(\"RJDemetra\")\nsa_model &lt;- RJDemetra::tramoseats(y, \"RSAfull\")\nsa_model$final$series\nsa_model$final$forecasts\n# for additional results call user-defined output as explained above\n\nIn version 3\n\nlibrary(\"rjd3tramoseats\")\nsa_model &lt;- tramoseats(y, spec = \"RSAfull\")\n# final series can be accessed here\nsa$result$final$sa\n# for additional results call user-defined output as explained above"
  },
  {
    "objectID": "A-sa-seats-decomposition.html#a-sa-SEATS-diags",
    "href": "A-sa-seats-decomposition.html#a-sa-SEATS-diags",
    "title": "SA: SEATS Decomposition",
    "section": "Retrieve Diagnostics",
    "text": "Retrieve Diagnostics\n\nWK analysis\n\ncomponents final estimators\n\nError analysis autocorrelation of the errors (sa, trend) revisions of the errors\nGrowth rates\nModel based tests\nSignificant seasonality\nStationary variance decomposition"
  },
  {
    "objectID": "A-sa-seats-decomposition.html#a-sa-SEATS-final-p",
    "href": "A-sa-seats-decomposition.html#a-sa-SEATS-final-p",
    "title": "SA: SEATS Decomposition",
    "section": "Retrieve Final Parameters",
    "text": "Retrieve Final Parameters\nRelevant if parameters not set manually, or any parameters automatically selected by the software without having a fixed default value. (The rest of the parameters is set in the specification) To manually set those parameters and see all the fixed default values see Specifications / parameters section\n\nArima Models for components\n\nDisplay in GUI\nClick on the Decomposition NODE\n\n\n\nDecomposition Node\n\n\n\n\nRetrieve from GUI\n(add names for output and cruncher)\n\n\nDisplay in R\n(display or retrieve)\nversion 2\nversion 3\n\n\n\nOther final parameters\nFinal parameters which can be fine-tuned be the user are described in User-defined specifications section below"
  },
  {
    "objectID": "A-sa-seats-decomposition.html#a-sa-SEATS-user-def",
    "href": "A-sa-seats-decomposition.html#a-sa-SEATS-user-def",
    "title": "SA: SEATS Decomposition",
    "section": "Setting user-defined parameters",
    "text": "Setting user-defined parameters\nThe section below explains how the user can fine-tune some seats parameters, which are put in context in the corresponding method chapter.the default value is indicated in ().\n\nPrediction length\n\nForecast span used in the decomposition default: one year (-1) (years are set in negative values, positive values indicate number of periods)\n\nApproximation Mode\n\nModification type for inadmissible models None (default) Legacy Noisy\n\nMA unit root boundary\n\nModulus threshold for resetteing MA “near-unit” roots [0,1] default (0.95)\n\nTrend Boundary Modulus threshold for assigning positive real AR Roots [0,1] default (0.5)\nSeasonal Tolerance Degree threshold for assigning complex AR roots [0,10] default (2)\nSeasonal Boundary (unique) Modulus threshold for assigning negative real AR roots [0,1] default (0.8)\nSeasonal Boundary (unique) Same modulus threshold unique seasonal AR roots [0,1] default (0.8)\nMethod\n\nAlgorithm used for estimation of unobserved components\nBurman (default)\nKalmanSmoother\nMcEllroyMatrix\n\nSeting parameters in GUI\nIn specification window corresponding to a given series:\n\n\n\nText\n\n\n\n\nSet in R\nversion 2 (RJDemetra)\n\ntramoseats_spec(\n    spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),\n    fcst.horizon = NA_integer_,\n    seats.predictionLength = NA_integer_,\n    seats.approx = c(NA, \"None\", \"Legacy\", \"Noisy\"),\n    seats.trendBoundary = NA_integer_,\n    seats.seasdBoundary = NA_integer_,\n    seats.seasdBoundary1 = NA_integer_,\n    seats.seasTol = NA_integer_,\n    seats.maBoundary = NA_integer_,\n    seats.method = c(NA, \"Burman\", \"KalmanSmoother\", \"McElroyMatrix\")\n)\n\nin version 3 with {rjd3tramoseats} (to be added)"
  },
  {
    "objectID": "A-sa-stl-decomposition.html#in-this-chapter",
    "href": "A-sa-stl-decomposition.html#in-this-chapter",
    "title": "SA with STL",
    "section": "In this Chapter",
    "text": "In this Chapter\nWe will cover how to use classic STL JDemetra+. M-STL functions for tackling multiple periodicities (with rounded frequencies) in infra-monthly data will be described in the high-frequency data related chapter.\nMore methodological details will be provided here"
  },
  {
    "objectID": "A-sa-stl-decomposition.html#tools-for-access",
    "href": "A-sa-stl-decomposition.html#tools-for-access",
    "title": "SA with STL",
    "section": "Tools for access",
    "text": "Tools for access\nIn JDemetra+ STL is only available through rjd3stl package."
  },
  {
    "objectID": "A-sa-bsm.html#in-this-chapter",
    "href": "A-sa-bsm.html#in-this-chapter",
    "title": "SA with Basic Structural Models",
    "section": "In this Chapter",
    "text": "In this Chapter\nWe will cover how to perform seasonal adjustment using BSM in JDemetra+. How to tackling multiple periodicities (with rounded frequencies) in infra-monthly data will be described in the high-frequency data related chapter.\nMore methodological details will be provided here"
  },
  {
    "objectID": "A-sa-bsm.html#tools-for-access",
    "href": "A-sa-bsm.html#tools-for-access",
    "title": "SA with Basic Structural Models",
    "section": "Tools for access",
    "text": "Tools for access\nIn JDemetra+ Basic Structural Models are only available through rjd3sts package."
  },
  {
    "objectID": "A-sa-hf.html#in-this-chapter",
    "href": "A-sa-hf.html#in-this-chapter",
    "title": "SA of high-frequency data",
    "section": "In this chapter",
    "text": "In this chapter\nThe sections below provide guidance on seasonal adjustment of infra-monthly, or high-frequency (HF), time-series data with JDemetra+ tailored algorithms.\nCurrently available topics:\n\ndescription of HF data specificities\nR functions for pre-treatment, extended X-11 and extended Seats\n\nUp coming content:\n\ngraphical user interface 3.0 functionalities for HF data\nSTL functions\nState space framework"
  },
  {
    "objectID": "A-sa-hf.html#data-specificities",
    "href": "A-sa-hf.html#data-specificities",
    "title": "SA of high-frequency data",
    "section": "Data specificities",
    "text": "Data specificities\nHF data often display multiple seasonal patterns with potentially non-integer periodicities which cannot be modeled with classical SA algorithms. JD+ provides tailored versions of these algorithms.\n\nPeriodicities (number of observations per cycle)\n\n\nData\nDay\nWeek\nMonth\nQuarter\nYear\n\n\n\n\nquarterly\n\n\n\n\n4\n\n\nmonthly\n\n\n\n3\n12\n\n\nweekly\n\n\n4.3481\n13.0443\n52.1775\n\n\ndaily\n\n7\n30.4368\n91.3106\n365.2425\n\n\nhourly\n24\n168\n730.485\n2191.4550\n8765.82"
  },
  {
    "objectID": "A-sa-hf.html#tailored-algorithms-in-jdemetra",
    "href": "A-sa-hf.html#tailored-algorithms-in-jdemetra",
    "title": "SA of high-frequency data",
    "section": "Tailored algorithms in JDemetra+",
    "text": "Tailored algorithms in JDemetra+\n\n\n\n\n\n\n\n\n\nCol1\nAlgorithm\nGUI v 3.0\nR package\n\n\n\n\nPre-treatment\nExtended Airline Model\n✔️\nrjd3highfreq\n\n\nDecomposition\nExtended SEATS Extended Airline Model\n✔️\nrjd3highfreq\n\n\n\nExtended X-11\n✔️\nrjd3x11plus\n\n\n\nExtended STL\n✖\nrjd3stl\n\n\nOne-Step\nSSF Framework\n✖\nrjd3sts"
  },
  {
    "objectID": "A-sa-hf.html#unobserved-components",
    "href": "A-sa-hf.html#unobserved-components",
    "title": "SA of high-frequency data",
    "section": "Unobserved Components",
    "text": "Unobserved Components\n\nRaw series decomposition\n\n\n\nDecomposition diagram\n\n\n\n\nMultiple seasonal patterns\nHF data often contain multiple seasonal patterns. For example, daily economic time series often display strong infra-weekly and infra-yearly seasonality. An infra-monthly seasonal pattern may also be present, but its strength is usually less pronounced in practice. In theory, the full decomposition of the seasonal component in daily data is given by:\n\\[\nS_{t}= S_{t,7} \\circ S_{t,30.44} \\circ S_{t,365.25}\n\\]\nThe decomposition is done iteratively periodicity by periodicity starting with the smallest one (highest frequency) as:\n\nhighest frequencies usually display the biggest and most stable variations\ncycles of highest frequencies can mix up with lower ones"
  },
  {
    "objectID": "A-sa-hf.html#identifying-seasonal-patterns",
    "href": "A-sa-hf.html#identifying-seasonal-patterns",
    "title": "SA of high-frequency data",
    "section": "Identifying seasonal patterns",
    "text": "Identifying seasonal patterns\nJDemetra+ provides the Canova-Hansen test in the rjd3toolkit package."
  },
  {
    "objectID": "A-sa-hf.html#pre-adjustment",
    "href": "A-sa-hf.html#pre-adjustment",
    "title": "SA of high-frequency data",
    "section": "Pre-adjustment",
    "text": "Pre-adjustment\nIn classical X13-ARIMA and TRAMO-SEATS, a pre-adjustment step is performed to remove deterministic effects, such as outliers and calendar effects, with a Reg-Arima model. In the extended version for HF data, it is also the case with an extended Airline model.\nA general Reg-ARIMA model is written as follows:\n\\[\n\\left(Y_t - \\sum {\\alpha_i}X_{it}\\right) \\sim ARIMA(p,d,q)(P,D,Q)\n\\]\nThese models contain seasonal backshift operators \\(B^{s}(y_t)=y_{t-s}\\). Here \\(s\\) can be non-integer. JDemetra+ will rely on a modified version of a frequently used Arima model: the “Airline” model:\n\\[\n(1-B)(1-B^{s})y_t=(1-\\theta_1 B)(1-\\theta_2 B^{s}) \\epsilon_t \\text{~~~~} \\epsilon_t \\sim \\text{NID}(0,\\sigma^2_{\\epsilon})  \n\\]\nFor HF data, the potentially non-integer periodicity \\(s\\) will be written: \\(s=s' + \\alpha\\), with \\(\\alpha \\in [0,1)\\) (for example \\(52.18 = 52 +0.18\\) is the yearly periodicity for weekly data)\nTaylor series development around \\(1\\) of \\(f(x)=x^\\alpha\\)\n\\[\n\\begin{array}{lll}\nx^\\alpha &=& 1 + \\alpha (x-1) + \\frac{\\alpha (\\alpha+1)}{2!} (x-1)^2 + \\frac{\\alpha (\\alpha+1) (\\alpha+2)}{3!} (x-1)^3 +\\cdots \\\\\n            B^\\alpha &\\cong& (1 - \\alpha)+ \\alpha B     \n\\end{array}\n\\]\nApproximation of \\(B^{s+\\alpha}\\) in an extended Airline model\n\\[\n\\begin{array}{lll}\nB^{s+\\alpha} &\\cong& (1 - \\alpha)B^s+ \\alpha B^{s+1}                \n\\end{array}\n\\]\nExample for a daily series displaying infra-weekly (\\(p_{1}=7\\)) and infra-yearly (\\(p_{2}=365.25\\)) seasonality:\n\\[\n(1-B)(1-B^{7})(1-B^{365.25)}(Y_t - \\sum {\\alpha_i}X_{it})=(1-\\theta_1 B)(1-\\theta_2 B^{7})(1-\\theta_3 B^{365.25}) \\epsilon_t\n\\]\n\\[\n\\epsilon_t \\overset{iid}{\\sim} \\text{N}(0,\\sigma^2_{\\epsilon})\n\\]\nwith\n\\[\n1 - B^{365.25} = 1 - (0.75B^{365} + 0.25B^{366})\n\\]\n\nCalendar correction\nCalendar regressors can be defined with the rjd3toolkit package and added to pre-treatment function as a matrix.\n\n# Create a calendar with rjd3toolkit\n# Define a national calendar\nfrenchCalendar &lt;- national_calendar(days = list(\n    fixed_day(7, 14), # Bastille Day\n    fixed_day(5, 8, validity = list(start = \"1982-05-08\")), # Victory Day\n    special_day(\"NEWYEAR\"),\n    special_day(\"CHRISTMAS\"),\n    special_day(\"MAYDAY\"),\n    special_day(\"EASTERMONDAY\"),\n    special_day(\"ASCENSION\"),\n    special_day(\"WHITMONDAY\"),\n    special_day(\"ASSUMPTION\"),\n    special_day(\"ALLSAINTSDAY\"),\n    special_day(\"ARMISTICE\")\n))\n# Generrate calendar regressors\nq &lt;- holidays(\n    calendar = frenchCalendar, \n    start = \"1968-01-01\",\n    length = length(df_daily$births), \n    type = \"All\",\n    nonworking = 7L\n)\n\n# Argument type = All : taking all holidays into account\n# Argument type = Skip : taking into account only the holidays falling on a week day\n\n\n\nOutliers and intervention variables\nOutliers detection is available in the pre-treatment function. Detected outliers are AO, LS and WO. Critical value can be computed by the algorithm or user-defined.\n\n\nLinearization\nExample using rjd3highfreq::fractionalAirlineEstimation function:\n\npre_adjustment &lt;- rjd3highfreq::fractionalAirlineEstimation(y_raw,\n    x = q, # q = daily calendar regressors\n    periods = c(7, 365.25),\n    ndiff = 2, ar = FALSE, mean = FALSE,\n    outliers = c(\"ao\", \"ls\", \"wo\"),\n    criticalValue = 0, # computed in the algorithm\n    precision = 1e-9, approximateHessian = TRUE\n)\n\n“pre_adjustment” R object is a list of lists in which the user can retrieve input series, parameters and output series. For more details see chapter on R packages and rjd3highfreq help pages R, where all parameters are listed."
  },
  {
    "objectID": "A-sa-hf.html#decomposition",
    "href": "A-sa-hf.html#decomposition",
    "title": "SA of high-frequency data",
    "section": "Decomposition",
    "text": "Decomposition\n\nExtended X-11\nX-11 is the decomposition module of X-13-Arima, the linearized series from the pre-adjustment step is split into seasonal (\\(S\\)), trend (\\(T\\)) and irregular (\\(I\\)) components. In case of multiple periodicities the decomposition is done periodicity by periodicity starting with the smallest one. Global structure of the iterations is the same as in “classical” X-11 but modifications were introduced for tackling non-integer periodicities. They rely on the Taylor approximation for the seasonal backshift operator:\n\\[\n\\begin{array}{lll}\nB^{s+\\alpha} &\\cong& (1 - \\alpha)B^s+ \\alpha B^{s+1}                \n\\end{array}\n\\]\n\nModification of the first trend filter for removing seasonality\nThe first trend estimation is thanks to a generalization of the centred and symmetrical moving averages with an order equal to the periodicity \\(p\\).\n\nfilter length \\(l\\): smallest odd integer greater than \\(p\\)\nexamples: \\(p=7 \\rightarrow l=7\\), \\(p=12 \\rightarrow l=13\\), \\(p=365.25 \\rightarrow l=367\\), \\(p=52.18 \\rightarrow l=53\\)\ncentral coefficients \\(1/p\\) (1/12,1/7, 1/365.25)\nend-point coefficients \\(\\mathbb{I} \\{\\text{$E(p)$ even}\\} +(p-E(p)) /2p\\)\nexample for \\(p=12\\): (\\(1/12\\) and \\(1/24\\)) (we fall back on \\(M_{2\\times12}\\) of the monthly case\nexample for \\(p=365.25\\): (\\(1/365.25\\) and \\(0.25/(2*365.25)\\))\n\n\n\nModification of seasonality extraction filters\nComputation is done on a given period\nExample \\(M_{3\\times3}\\)\n\\[\nM_{3\\times3}X = \\frac{1}{9}(X_{t-2p})+\\frac{2}{9}(X_{t-p})+\\frac{3}{9}(X_{t})+\\frac{2}{9}(X_{t+p})+\\frac{1}{9}(X_{t+2p})\n\\]\nif \\(p\\) integer: no changes needed\nif \\(p\\) non-integer: Taylor approximation of the backshift operator\n\n\nModification of final trend estimation filter\nAs seasonality has been removed in the first step, there is no non-integer periodicity issue in the final trend estimation, but extended X-11 offers additional features vs classic X-11, in which final trend is estimated with Henderson filters and Musgrave asymmetrical surrogates. In extended X-11, a generalization of this method with local polynomial approximation is available.\n\n\nExample of decomposition\nHere the raw series is daily and displays two periodicities \\(p=7\\) and \\(p=365.25\\)\n\n# extraction of day-of-the-week pattern (dow)\nx11.dow &lt;- rjd3x11plus::x11plus(y_linearized,\n    period = 7, # DOW pattern\n    mul = TRUE,\n    trend.horizon = 9, # 1/2 Filter length : not too long vs p\n    trend.degree = 3, # Polynomial degree\n    trend.kernel = \"Henderson\", # Kernel function\n    trend.asymmetric = \"CutAndNormalize\", # Truncation method\n    seas.s0 = \"S3X9\", seas.s1 = \"S3X9\", # Seasonal filters\n    extreme.lsig = 1.5, extreme.usig = 2.5\n) # Sigma-limits\n\n# extraction of day-of-the-week pattern (doy)\nx11.doy &lt;- rjd3x11plus::x11plus(x11.dow$decomposition$sa, # previous sa\n    period = 365.2425, # DOY pattern\n    mul = TRUE,\n    trend.horizon = 371, # 1/2 final filter length\n    trend.degree = 3,\n    trend.kernel = \"Henderson\",\n    trend.asymmetric = \"CutAndNormalize\",\n    seas.s0 = \"S3X15\", seas.s1 = \"S3X5\",\n    extreme.lsig = 1.5, extreme.usig = 2.5\n)\n\n\n\n\nArima Model Based (AMB) Decomposition (Extended Seats)\nExample\n\n# extracting DOY pattern\namb.doy &lt;- rjd3highfreq::fractionalAirlineDecomposition(\n    amb.dow$decomposition$sa, # DOW-adjusted linearised data\n    period = 365.2425, # DOY pattern\n    sn = FALSE, # Signal (SA)-noise decomposition\n    stde = FALSE, # Calculate standard deviations\n    nbcasts = 0, nfcasts = 0\n) # Numbers of back- and forecasts\n\n\n\nSummary of the process\nFor the time being, seasonal adjustment processing in rjd3highfreq cannot be encompassed by one function like for lower frequency, e.g rjd3x13::x13(y_raw)\nThe user has to run the steps one by one, here is an example with \\(p=7\\) and \\(p=365.25\\)\n\ncomputation of the linearized series \\(Y_{lin}=ExtendedAirline(Y)\\)\ncomputation of the calendar corrected series \\(Y_{cal}\\)\ncomputation of \\(S_{7}\\) by decomposition of the linearized series\ncomputation of \\(S_{365.25}\\) by decomposition of the seasonally adjusted series with \\(p=7\\)\nfinally adjusted series \\(sa_{final} = Y_{cal}/S_{7}/S_{365.25}\\) (if multiplicative model)\n\n\n\nSTL decomposition\nNot currently available. Under construction."
  },
  {
    "objectID": "A-sa-hf.html#state-space-framework",
    "href": "A-sa-hf.html#state-space-framework",
    "title": "SA of high-frequency data",
    "section": "State Space framework",
    "text": "State Space framework\nNot currently available. Under construction."
  },
  {
    "objectID": "A-sa-hf.html#quality-assessment",
    "href": "A-sa-hf.html#quality-assessment",
    "title": "SA of high-frequency data",
    "section": "Quality assessment",
    "text": "Quality assessment\n\nResidual seasonality\nJDemetra+ provides the Canova-Hansen test in rjd3toolkit package which allows to check for any remaining seasonal periodicity in the final SA data."
  },
  {
    "objectID": "A-outlier-detection.html#in-this-chapter",
    "href": "A-outlier-detection.html#in-this-chapter",
    "title": "Outlier detection and external regressors",
    "section": "In this chapter",
    "text": "In this chapter\nThe following sections describe\n\nhow to generate useful external regressors for improving seasonal adjustment or reg-arima modelling\nJDemetra+ solutions for outlier detection and in a time series.\n\nThese routines can be used stand alone or as part of a seasonal adjustment process. They can be accessed via the Graphical User Interface (GUI) or [R packages]((#t-r-packs).\nHow to use the generated regressors, or any user-defined variable, in a seasonal adjustment or reg-arima modelling process is discussed in the pre-treatment chapter for classic SA and SA of High-frequency chapter for infra-monthly data. There you will also find out how to fix the corresponding coefficients and how to allocate the effects to the selected component.\nThe external regressors described exclude calendar correction which is detailed here"
  },
  {
    "objectID": "A-outlier-detection.html#tools-map",
    "href": "A-outlier-detection.html#tools-map",
    "title": "Outlier detection and external regressors",
    "section": "Tools Map",
    "text": "Tools Map\n\nExternal regressors using R packages vs GUI\nup coming content\n\n\nOutlier detection using R packages vs GUI\nup coming content"
  },
  {
    "objectID": "A-outlier-detection.html#generating-external-regressors",
    "href": "A-outlier-detection.html#generating-external-regressors",
    "title": "Outlier detection and external regressors",
    "section": "Generating external regressors",
    "text": "Generating external regressors\n\nOutliers\n\nTypes\nThe following outliers are available for automatic detection\n\n\n\nOutliers type\n\n\n\n\n\nSeasonal outlier\n\n\nADD: - specifics for HF data (wo outiler)\n\n\nPre-specifying outliers\nOutliers are well-defined types of auxiliary variables, therefore when they are used (reg-arima or tramo modelling) they don’t need to be explicitly generated beforehand. Pre-specifying outliers is detailed in chapters on pre-treatment in SA and SA of High-frequency data.\n\n\nGenerating regressors for outliers\nNevertheless, explicit regressors corresponding to outliers can be generated with rjd3toolkit functions for independent use. Further details rjd3toolkit help pages.\n\n# Outliers in February 2002, for monthly data\nlibrary(\"rjd3toolkit\")\nao &lt;- ao_variable(frequency = 12, c(2000, 1), length = 12 * 4, date = \"2002-02-01\")\nls &lt;- ls_variable(12, c(2000, 1), length = 12 * 4, date = \"2002-02-01\")\ntc &lt;- tc_variable(12, c(2000, 1), length = 12 * 4, date = \"2002-02-01\")\nso &lt;- so_variable(12, c(2000, 1), length = 12 * 4, date = \"2002-02-01\")\n\n\n\n\nRamps\nA ramp effect means a linear increase or decrease in the level of the series over a specified time interval \\(t_{0}\\) to \\(\\ t_{1}\\). Ramps can overlap other ramps, additive outliers and level shifts. In seasonal adjustment their effected will be allocated to the trend.\nAdding ramps to a seasonal adjustment (or reg-arima/tramo) specification happens in one step in GUI as well as in R, where ramp regressors can nevertheless be independently generated.\n\nAdding ramps in GUI\nIn the specification window\n\n\n\nAdd ramp in GUI\n\n\nThe effect of the ramps is stored in reg_t pre-adjustment series.\n\n\nAdding ramps in R\nUse the function add_ramp\n\n# create a specification from a default specification\ninit_spec &lt;- rjd3x13::spec_x13(\"RSA5c\")\n\n# add ramp on year 2012\nnew_spec &lt;- rjd3toolkit::add_ramp(init_spec, start = \"2012-01-01\", end = \"2012-12-01\")\n\n\n\nGenerating ramp regressors in R\nUse ramp_variable function in rjd3toolkit:\n\n?ramp_variable\n# Ramp variable from January 2001 to September 2001 for a monthly series\nrp &lt;- ramp_variable(frequency = 12, c(2000, 1), length = 12 * 4, range = c(13, 21))\n# Or equivalently\nrp &lt;- ramp_variable(12, c(2000, 1), length = 12 * 4, range = c(\"2001-01-01\", \"2001-09-02\"))\nplot.ts(rp)\n\nMore details rjd3toolkit pages.\n\n\n\nIntervention variables\nIntervention variables are modelled as any possible sequence of ones and zeros, on which differencing (regular and seasonal) can be applied.\nAdding intervention variables to a seasonal adjustment (or reg-arima/tramo) specification happens in one step when using the GUI, whereas two steps are required in R: generating the regressors and the adding them as an user-defined variable.\n\nAdding intervention variables in GUI\nstep 1:\n\nStep 2:\n\n\n\nGenerating intervention variables in R\nUsing intervention_variable function in rjd3toolkit\n\nlibrary(\"rjd3toolkit\")\n? intervention_variable\niv &lt;- intervention_variable(\n    frequency = 12, start = c(2000, 1), length = 60,\n    starts = \"2001-01-01\", ends = \"2001-12-01\"\n)\niv\nplot(iv)\n\niv &lt;- intervention_variable(12, c(2000, 1), 60,\n    starts = \"2001-01-01\", ends = \"2001-12-01\", delta = 1\n)\niv\nplot(iv)\n\niv &lt;- intervention_variable(12, c(2000, 1), 60,\n    starts = \"2001-01-01\", ends = \"2001-12-01\",\n    delta = 0, seasonaldelta = 1\n)\niv\nplot(iv)\n\nMore details rjd3toolkit help pages.\n\n\nAdding intervention variables in R\nIntervention variables can be added to a specification like any other external regressor using the add_usrdefvar. They also need to be declared in a “context” using the modelling_context function.\n\n# creating one or several external regressors (TS objects),\n# which will be gathered in one or several groups\niv1 &lt;- intervention_variable(12, c(2000, 1), 60,\n    starts = \"2001-01-01\", ends = \"2001-12-01\"\n)\niv2 &lt;- intervention_variable(12, c(2000, 1), 60,\n    starts = \"2001-01-01\", ends = \"2001-12-01\", delta = 1\n)\n# regressors as a list of two groups (lists) reg1 and reg2\nvars &lt;- list(reg1 = list(iv1 = iv1), reg2 = list(iv2 = iv2))\n# to use those regressors, input : name=reg1.iv1 and name=reg2.iv2 in add_usrdefvar function\n# creating the modelling context\nmy_context &lt;- modelling_context(variables = vars)\n# customize a default specification\ninit_spec &lt;- rjd3x13::spec_x13(\"RSA5c\")\n# regressors have to be added one by one\nnew_spec &lt;- add_usrdefvar(init_spec, name = \"reg1.iv1\", regeffect = \"Trend\")\nnew_spec &lt;- add_usrdefvar(new_spec, name = \"reg2.iv2\", regeffect = \"Trend\", coef = 0.7)\n# modelling context is needed for the estimation phase\n# raw series\ny &lt;- rjd3toolkit::ABS$X0.2.09.10.M\nsa_x13 &lt;- rjd3x13::x13(y, new_spec, context = my_context)\n\n\n\n\nPeriodic dummies and contrasts\n\nGenerating regressors in R\ndummies :as many time series as type of periods in a year (4,12)\n\n## periodic dummies : add explanations and examples\np &lt;- periodic.dummies(4, c(2000, 1), 60)\nhead(p)\nclass(p)\nq &lt;- periodic.contrasts(4, c(2000, 1), 60)\nq[1:9, ]\n\n\n\n\nTrigonometric variables\nCorrection for stable seasonality.\n\nGenerating in R\n\n\n\nUser-defined variables\nUser defined variables are simply time series used as explanatory regressors in the RegARIMA and the TRAMO models. Although JDemetra+ allows the user to indicate any time series as a variable to avoid misleading or erroneous results, the following rules should be kept:\n\nUser-defined regression variables are used for measuring abnormalities and therefore they should not contain a seasonal pattern.\nJDemetra+ assumes that user-defined regressors are already in an appropriately centred form.\n\nTherefore the mean of each user-defined regressor needs to be subtracted from the regressor or means for each calendar period (month or quarter) need to be subtracted from each of the user-defined regressors.\nJDemetra+ considers two kinds of user-defined regression variables:\n\nStatic variables, usually imported directly from external software (by drag/drop or copy/paste). The observations for static variables cannot be changed. The only way to update static series is to remove them from the list and to re-import them with the same names.\nDynamic variables that are imported into the Variables panel by dragging and dropping series from a browser of the application, available in the Providers window. Dynamic variables are automatically updated each time the application is re-opened. Therefore, it is a convenient solution for creating user-defined variables.\n\n\nIn GUI\nTo create a dynamic variable first right-click on the Variables node in the Workspace window and chose the option New.\n\n\n\nCreating an empty dataset for the user-defined variables\n\n\nNext, double click on the newly created Vars-1 item to display it in the Results panel. By default, JDemetra+ uses the conventions Vars_#number to name the tabs under the Variables node.\n\n\n\nActivation of an empty dataset for the user-defined variables\n\n\nThen, go to Providers window and open your file that contains external variables following the instructions provided here. Drag and drop your external regressors from the Providers window to the Vars-1 window.\n\n\n\nImporting the user-defined variables to JDemetra+\n\n\nThe original name of the series is recorded in the Description column of the Variables window.\n\n\n\nAssigning regressors from the Providers window to the user-defined variables\n\n\nIn order to rename the series in the Variables window, right click on the series and chose Rename.\n\n\n\nA local menu for the user-defined variables\n\n\n\n\nIn R"
  },
  {
    "objectID": "A-outlier-detection.html#outlier-detection",
    "href": "A-outlier-detection.html#outlier-detection",
    "title": "Outlier detection and external regressors",
    "section": "Outlier Detection",
    "text": "Outlier Detection\n\nWith Reg Arima models\n\nWithin an SA processing\nIn a seasonal adjustment estimation or reg-arima modelling outliers are detected by default. This process can be customized by selecting the type of outliers to be taken into account and the critical values to be used for selection. See the relevant chapters on SA and SA of High-frequency data\n\n\nStand alone\nIn version 3;x, R packages rjd3x13 and rjd3tramoseats provide functions for detecting outliers with reg-arima (tramo) algorithms.\nExample using regarima_outliersin rjd3x13:\n\nlibrary(rjd3x13)\n?regarima_outliers\nregarima_outliers(rjd3toolkit::ABS$X0.2.09.10.M,\n    order = c(1, 1, 1), seasonal = c(0, 1, 1),\n    mean = F,\n    X = NULL, X.td = NULL,\n    ao = T, ls = F, tc = T, so = T, cv = 4\n)\n\nExample wit rjd3tramoseats::tramo_outliers\n\nlibrary(rjd3tramoseats)\n?tramo_outliers\ntramo_outliers(rjd3toolkit::ABS$X0.2.09.10.M,\n    order = c(1, 1, 1), seasonal = c(0, 1, 1),\n    mean = F,\n    X = NULL, X.td = NULL,\n    ao = T, ls = F, tc = T, so = T, cv = 4\n)\n\n\n\nSpecific TERROR tool\nUp coming content\n\n\n\nWith structural models (BSM)\nUp coming content"
  },
  {
    "objectID": "A-calendar-correction.html#in-this-chapter",
    "href": "A-calendar-correction.html#in-this-chapter",
    "title": "Calendar correction",
    "section": "In this Chapter",
    "text": "In this Chapter\nThis chapter is divided in two parts. The first one (theory) outlines the rationale for calendar correction and the underlying modelling. The second part (practice) describes how relevant regressors for calendar correction are built in JDemetra+.\nAs calendar effects are deterministic, they can be corrected with a regression model. In the algorithms X13-ARIMA and TRAMO-SEATS it boils down to adding suitable regressors to the pre-treatment phase). This chapter will describe how to generate a set of regressors corresponding to the desired correction, which will happen according to the following steps:\n\nstep 1: generate a calendar (usually national calendar of interest). If this step is skipped a default calendar, not taking into account country-specific holidays will be used.\nstep 2: generate regressors based on the above defined calendar\n\nRegressors will have the same frequency as the raw data, thus an aggregation process will be defined unless the data is daily.\n\nstep 2b: a specific variable for modelling the easter effect (or any other moving holiday effect like ramadan) can also be defined\n\nMost of the functions are designed for quarterly and monthly data. What applies to daily and weekly data will be highlighted.\nRegressors are corrected for deterministic seasonality through a long-term mean correction\n\nstep 3: these regressors have to be plugged-in in pre-adjustment phase of a seasonal adjustment estimation. How to do this is detailed in chapters on pre-treatment and SA of High-Frenquency data.\n\nHow to generate other types of regressors is described here and how to plug them into reg-arima models is detailed here"
  },
  {
    "objectID": "A-calendar-correction.html#tools-map",
    "href": "A-calendar-correction.html#tools-map",
    "title": "Calendar correction",
    "section": "Tools Map",
    "text": "Tools Map\nup coming content"
  },
  {
    "objectID": "A-calendar-correction.html#rationale-for-calendar-correction",
    "href": "A-calendar-correction.html#rationale-for-calendar-correction",
    "title": "Calendar correction",
    "section": "Rationale for Calendar correction",
    "text": "Rationale for Calendar correction\nA calendar is heterogeneous, it at least composed of:\n\ntrading days: days usually worked, taking into account the company’s sector. (Most frequently Mondays through Fridays when not bank holidays).\nweek-ends\nbank holidays\n\nFor a given year as well as throughout the years, every month doesn’t have the same number of days per day-type, which implies that all months/quarters aren’t “equal”, even for a given type of month or quarter. This causes calendar effects which have to be removed to allow sounder comparisons following the same principle as seasonality correction.\nTwo types of effects result from this heterogeneity:\n\nlength of period (month/quarter) (leap-year or direct correction)\ncomposition of period (type of day)\n\nThis second effect is also relevant for daily (and weekly) data.\nAn additional easter effect can be modelled, as for some series, variations linked to Easter can be seen over a few days prior or following Easter. For example, flowers and chocolate sales might rise significantly as Easter approaches. (in practice this effect is very rare, it is better to deactivate by default detection)"
  },
  {
    "objectID": "A-calendar-correction.html#modelling-calendar-effects",
    "href": "A-calendar-correction.html#modelling-calendar-effects",
    "title": "Calendar correction",
    "section": "Modelling calendar effects",
    "text": "Modelling calendar effects\n\nRegression Model for type of days\nFor each period \\(t\\), the days are divided in \\(K\\) groups \\(\\lbrace{D_{t1},\\dots, D_{tK}\\rbrace}\\).\nThe groups of days can be anything (trading days, working days, Sundays + holidays assimilated to Sundays…) ADD\nWe write \\(N_t=\\sum_1^K{D_{ti}}\\), the number of days of the period \\(t\\)\nTwo terms appear:\n\nthe specific effect of a type of day \\(i\\) as a contrast between the number of days \\(i\\) and the number of Sundays and bank holidays\nthe effect of the month’s (or period’s) length.\n\nOnce seasonally adjusted, this term comes down to the leap year effect:\n\nfor all months except Februaries \\(\\bar{N}_t = N_t\\)\nfor Februaries \\(\\bar{N}_t=28.25\\) and \\(N_{t}=28\\) or \\(N_{t}=29\\)\n\nThe effect of one day of the group \\(i\\) is measured by \\(\\alpha_i\\), so that the global effect of the group \\(i\\) for the period \\(t\\) is \\(\\alpha_i D_{ti}\\)\nThe global effect of all the days for the period \\(t\\) is\n\\[\n\\sum_{i=1}^K{\\alpha_i D_{ti}} = \\bar\\alpha N_t + \\sum_{i=1}^K{(\\alpha_i-\\bar\\alpha) D_{ti}}\n\\]\nwhere \\(\\bar\\alpha=\\sum_{i=1}^K{w_i \\alpha_i}\\) with \\(\\sum_{i=1}^Kw_i=1\\)\nSo,\n\\[\n\\sum_{i=1}^K{(\\alpha_i-\\bar\\alpha) w_i} = \\sum_{i=1}^K{\\alpha_iw_i}-\\bar\\alpha\\sum_{i=1}^K w_i=0\n\\]\nLEAP YEAR part to comment\nWe focus now on \\(\\sum_{i=1}^K{(\\alpha_i-\\bar\\alpha) D_{ti}}\\), the actual trading days effects (excluding the length of period effect).\nWriting \\(\\alpha_i-\\bar\\alpha = \\beta_i\\) and using that \\(\\sum_{i=1}^K{\\beta_i w_i} = 0\\), we have that\n\\[\n\\sum_{i=1}^K{\\beta_i D_{ti}}=\\sum_{i=1}^K{\\beta_i(D_{ti} - \\frac{w_i}{w_K}}D_{tK})= \\sum_{i=1}^{K-1}{\\beta_i(D_{ti} - \\frac{w_i}{w_K}}D_{tK})\n\\]\nNote that the relationship is valid for any set of weights \\(w_i\\). It is also clear that the contrasting group of days can be any group:\n\\[\n\\sum_{i=1}^{K-1}{\\beta_i(D_{ti} - \\frac{w_i}{w_K}}D_{tK}) = \\sum_{i=1}^{K, i \\neq J}{\\beta_i(D_{ti} - \\frac{w_i}{w_J}}D_{tJ})\n\\]\nThe “missing” coefficient is easily derived from the others:\n\\[\n\\beta_K = -\\frac{1}{w_K}\\sum_{i=1}^{K-1}{\\beta_i w_i}\n\\]\n\n\nCorrection for deterministic seasonality\nIn the case of seasonal adjustment, we further impose that the regression variables don’t contain deterministic seasonality. That is achieved by removing from each type of period (month, quarter…) its long term average. We write \\(\\bar{D_i^y}\\) the long term average of the yearly number of days in the group \\(i\\) and \\(\\bar{D_{i,J}^y}\\) the long term average of the number of days in the group \\(i\\) for the periods \\(J\\) (for instance, average number of Mondays in January…).\nThe corrected contrast for the time t belonging to the period J is:\n\\[\nC_{ti}=D_{ti}-\\bar{D_{i, J}^y}-\\frac{w_i}{w_K}(D_{tK}- \\bar{D_{K, J}^y})\n\\]\nHow is the long term mean computed? Probabilistic approach (more on this soon)\n\n\nWeights for different groups of days\nWe can define different sets of weights. The usual one consists in giving the same weight to each type of days. \\(w_i\\) is just proportional to the number of days in the group \\(i\\). In the case of “week days”, \\(w_0 = \\frac{5}{7}\\) (weeks) and \\(w_1=\\frac{2}{7}\\) (week-ends). In the case of “trading days”, \\(w_i=\\frac{1}{7}\\) … Another approach consists in using the long term yearly averages, taking into account the actual holidays. We get now that \\(w_i=\\frac{\\bar{D_i^y}}{365.25}\\).\nAfter the removal of the deterministic seasonality, the variables computed using the two sets of weights considered above are very similar. In the case of the “trading days”, the difference for the time \\(t\\), belonging to the period \\(J\\), and for the day \\(i\\) with contrast \\(K\\) is \\((1-\\frac{w_i}{w_K})(D_{tK}- \\bar{D_{K, J}^y})\\), which is usually small. By default, JD+ uses the first approach, which is simpler. The second approach is implemented in the algorithmic modules, but not available through the graphical interface.\n\n\nUse in Reg-ARIMA models\nIn the context of Reg-ARIMA modelling, we can also observe that the global effect of the trading days doesn’t depend neither on the used weights (we project on the same space) nor on the contrasting group (see above) nor on the long term corrections (removed by differencing).\nThe estimated coefficients slightly change if we use different weights (not if we use a different contrasting group). It must also be noted that the choices affect the T-Stat of the different coefficients (not the joint F-Test), which can lead to other solutions when those T-Stats are used for selecting the regression variables (Tramo). Considering that the leap year/length of period variable is nearly independent of the other variables, the test on that variable is not very sensitive to the various specifications.\n\n\nInterpretation\nThe use of different specifications of the trading days doesn’t impact the final results (except through some automatic selection procedure). It just (slightly) changes the way we interpret the estimated coefficients.\n\n\nEaster effect\n\n\nStock series"
  },
  {
    "objectID": "A-calendar-correction.html#usr_def_cal",
    "href": "A-calendar-correction.html#usr_def_cal",
    "title": "Calendar correction",
    "section": "Generating Regressors for calendar correction",
    "text": "Generating Regressors for calendar correction\nThe following parts details how to build customized regressors for calendar correction using\n\ngraphical user interface (GUI)\nrjd3toolkit package.\n\nTo take specific holidays into account a calendar has to be defined, regressors will be built subsequently.\nAs regressors have the same data frequency as the input series, several cases:\n\nfor daily series : regressors are dummies representing each holidays\nfor weekly, monthly and quarterly series regressors are aggregated indicators, the way of grouping different types of days and holidays has to be specified.\n\n\nIn GUI\n\nCreating calendars\nThe customized calendar can be directly linked to the calendar correction option in GUI while specifying a seasonal adjustment process. See chapters on SA or SA of HF data.\n\nDefault Calendar\nIn the graphical user interface, calendars in are stored in the Workspace window in the Utilities section. In the default calendar, country-specific national holidays are not taken into account, it reflects only the usual composition of the weeks in the calendar periods.\n\n\n\nText\n\n\nTo view the details of the default calendar: double click on it\n\n\n\nText\n\n\n\n\nSet Properties\nIn the Properties panel the user can set:\n\nFrequency (monthly, quarterly..)\nTrading days or working days regressors\n\nTrading days: 6 contrast variables\nnumber of Mondays - number of Sundays\nand one regressor for the leap year effect.\nWorking Days: 1 contrast variable (\\(number\\ of\\ working days (monday to friday) - number\\ of\\ Saturdays and Sundays\\),…) and one regressor for the leap year effect.\n\n\n\nText\n\n\nModification of the initial settings for the Default calendar\n\n\nSpectrum visualization\nThe top-right panel displays the spectrum for the given calendar variable. By default, the first variable from the table is shown.\n\nTo change it, click on the calendar variable header.\n\nCalendar variables shouldn’t have a peak neither at a zero frequency (trend) nor the seasonal frequencies.\n\n\n\nText\n\n\n\n\n\nModify an existing Calendar\n\nclick the option Edit from the context menu\nthe list of holidays defined for this calendar is displayed\n\n\n\n\nText\n\n\nEdit a calendar window\n\nTo add a holiday unfold the + menu\nTo remove a holiday click on it and choose the - button\n\n\n\n\nText\n\n\nRemoving a holiday from the calendar\n\nCreating a new calendar\nAn appropriate calendar, containing the required national holidays, needs to be created to adjust a series for country-specific calendar effects.\n\nright click on the Calendar item from the Workspace window and choose Add\n\n\n\n\nText\n\n\nThree options are available:\n\nNational calendars: allows to include country-specific holidays\nComposite calendars : creates calendar as a weighted sum of several national calendars\nChained calendars : allows to chain two national calendars before and after a break\n\n\n\nNational Calendar\nTo define a national calendar: right click on Calendar item in the Utility panel of the workspace window\n\n\n\nText\n\n\n\nTo add a holiday unfold the + menu\nTo remove a holiday from the list click on it and choose the - button.\n\n\n\n\nText\n\n\nFour options are available here:\n- **Fixed** : holiday occurring at the same date\n\n- **Easter Related**: holiday that depends on Easter Sunday date\n\n- **Fixed Week**: fixed holiday that always falls in a specific week of a given month\n\n- **Special Day**:  choose a holiday from a list of pre-defined holidays (link to table)\n\n\n\nText\n\n\n\nto use Julian Easter\n\n\n\n\nText\n\n\nTo add a holiday from this list to the national calendar, choose the Special day item from the Special days list.\n Adding a pre-defined holiday to the calendar\nBy default, when the Special Days option is selected, JDemetra+ always adds Christmas to the list of selected holidays. The user can change this initial choice by specifying the settings in the panel on the right and clicking OK. The settings that can be changed include:\n\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned.\nDay event: a list of pre-defined holidays (link to table)\nOffset: allows to set a holiday as related to a pre-specified holiday by specifying the distance in days (e.g Easter Sunday). Default offset is 1. It can be positive or negative. Positive offset: defines a holiday following the pre-specified holiday. Negative offset: defines a holiday preceding the selected pre-specified.\n Choosing a pre-defined holiday from the list\nTo define a fixed holiday not included in the list of pre-defined holidays:\n\nchoose Fixed from the Special days list: by default January, 1 is displayed. Specify the settings:\n\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned.\nDay: day of month when the fixed holiday is celebrated.\nMonth: month, in which the fixed holiday is celebrated.\n\n\n\n\nText\n\n\nOptions for a fixed holiday\n\nAdd Corpus Christi: example of an Easter related holiday not included in the special day list(link to table). It is is a moving holiday celebrated 60 days after Easter\n\nchoose the Easter related item from the Special days list.\n\n By default Easter + 1 is displayed. Setting can be changed :\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned.\nOffset: To define Corpus Christi enter 60, as it is celebrated 60 days after Easter Sunday.\n\n\n\n\nText\n\n\n\nFixed week option: when dealing with holidays occurring on the same week of a given month. Example: Labour Day in the USA and Canada, celebrated on the first Monday of September in Canada\n\nchoose Fixed Week from the Special days list.\n\n\n\n\nText\n\n\n\nAvailable settings are:\n\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned\nDay of Week: day of week when the holiday is celebrated each year\nMonth: month, in which the holiday is celebrated each year\nWeek: number denoting the place of the week in the month: between 1 and 5\n\n\n\n\nText\n\n\nThe list of the holidays should contain only unique entries. Otherwise, a warning, as shown in the picture below, will be displayed.\n\n\n\nText\n\n\nA calendar without a name cannot be saved. Fill the Name box before saving the calendar.\n\n\n\nText\n\n\nExample : final view of a properly defined calendar for Poland\n\n\n\nText\n\n\nThe calendar is visible in the Workspace window\n\nTo display the available options right-click on it\n\nA national calendar can be edited, duplicated (to create another calendar) and/or analysed (double click to display it in the panel on the right) or deleted.\n\n\nChained Calendar\nCreating a chained calendar is relevant when a major break occurs in the definition of the country-specific holidays.\nFirst define the 2 (or \\(N\\)) national calendars corresponding to each regime as explained in the section above.\nTo define a chained calendar: right click on Calendar item in the Utility panel of the workspace window\n\n\n\nText\n\n\nIn the Properties panel specify:\n\nfirst and the second calendar\nbreak date\n\n\n\n\nText\n\n\n\n\nComposite Calendar\nCreating a composite calendar is relevant when correcting series which include data from more than one country/region. This option can be used, for example, to create the calendar for the European Union or to create the national calendar for a country, in which regional holidays are celebrated.\nFirst define the relevant national calendars corresponding to each member state/region as explained above.\nTo define a chained calendar: right click on Calendar item in the Utility panel of the workspace window\n\n\n\nText\n\n\n\nFill the name box\nMark the regional calendars to be used\nAssign a weight to each calendar.\n\n\n\n\nText\n\n\n\n\nImporting an existing calendar from a file\nRight click on the Calendar item from the Workspace window and choose the Import item from the menu.\n\n\n\nText\n\n\nImporting a calendar to JDemetra+\n\nchoose the appropriate file and open it\n\n\n\n\nText\n\n\nChoosing the file\nJDemetra+ adds it to the calendars list\n\n\n\nText\n\n\nA list of calendars with a newly imported calendar\n\n\nExample of a calendar file\nexample of a html file containing a calendar\n #### Generating regressors\n\n\nType of days\n\n\nLeap year\n\n\nLength of Period\n(adjust param)\n\n\nEaster\n\n\nstock TD\n\n\n\n\nIn R with rjd3toolkit\nVersion 3 of JDemetra+ allows to build calendar regressors using the rjd3toolkit package.\nThe underlying concepts are identical to those available in the graphical user interface (GUI) as described above. R functions replicate the same process and all arguments and outputs are detailed in rjd3toolkit help pages. The sections below provide basic examples.\nNote that, RJDemetra package based on version 2 of JDemetra+, doesn’t allow to build calendars and generate regressors. Thus, two approaches are possible when using version 2\n\nuse built in regressors (“working days” or “trading days”) not taking into account national holidays\nimport user defined calendar regressors\n\n\nCreating calendars\n\nNational Calendar\nCreating a national calendar with rjd3toolkit.\n\n## French calendar\nfrenchCalendar &lt;- national_calendar(days = list(\n    fixed_day(7, 14), # Bastille Day\n    fixed_day(5, 8, validity = list(start = \"1982-05-08\")), # End of 2nd WW\n    special_day(\"NEWYEAR\"),\n    special_day(\"CHRISTMAS\"),\n    special_day(\"MAYDAY\"),\n    special_day(\"EASTERMONDAY\"),\n    special_day(\"ASCENSION\"), #\n    special_day(\"WHITMONDAY\"),\n    special_day(\"ASSUMPTION\"),\n    special_day(\"ALLSAINTSDAY\"),\n    special_day(\"ARMISTICE\")\n))\n\nHolidays can be created with the following ways:\n\nas fixed days (falling on the exact same date every year)\n\n\nday &lt;- fixed_day(\n    month = 12,\n    day = 25,\n    weight = .9,\n    validity = list(start = \"1968-02-01\", end = \"2010-01-01\")\n)\nday # December 25th, with weight=0.9, from February 1968 until January 2010\n\n\nas special days, when on the list of common holidays, which is available in the function’s halp page.\n\n\n# Get the list\n?special_day\n# To define a holiday for the day after Christmas, with validity and weight\nspecial_day(\"CHRISTMAS\",\n    offset = 1, weight = 0.8,\n    validity = list(start = \"2000-01-01\", end = \"2020-12-01\")\n)\n\n\nas a fixed week day\n\n\nfixed_week_day(7, 2, 3) # second Wednesday of July\n\n\nas an easter related holiday\n\n\neaster_day(1) # Easter Monday\neaster_day(-2) # Good Friday\n\nAn example of calendar bringing together all options\n\nMyCalendar &lt;- national_calendar(list(\n    fixed_day(7, 21),\n    special_day(\"NEWYEAR\"),\n    special_day(\"CHRISTMAS\"),\n    fixed_week_day(7, 2, 3), # second Wednesday of July\n    special_day(\"MAYDAY\"),\n    easter_day(1), # Easter Monday\n    easter_day(-2), # Good Friday\n    fixed_day(5, 8, validity = list(start = \"1982-05-08\")), # End of 2nd WW\n    single_day(\"2001-09-11\"), # appearing once\n    special_day(\"ASCENSION\"),\n    easter_day( # Corpus Christi\n        offset = 60,\n        julian = FALSE,\n        weight = 0.5,\n        validity = list(start = \"2000-01-01\", end = \"2020-12-01\")\n    ),\n    special_day(\"WHITMONDAY\"),\n    special_day(\"ASSUMPTION\"),\n    special_day(\"ALLSAINTSDAY\"),\n    special_day(\"ARMISTICE\")\n))\n\nFor any defined calendar, it is possible to retrieve the long term-mean correction values which would be applied on a given set of regressors.\n\n### Long-term means of a calendar\nBE &lt;- national_calendar(list(\n    fixed_day(7, 21),\n    special_day(\"NEWYEAR\"),\n    special_day(\"CHRISTMAS\"),\n    special_day(\"MAYDAY\"),\n    special_day(\"EASTERMONDAY\"),\n    special_day(\"ASCENSION\"),\n    special_day(\"WHITMONDAY\"),\n    special_day(\"ASSUMPTION\"),\n    special_day(\"ALLSAINTSDAY\"),\n    special_day(\"ARMISTICE\")\n))\nclass(BE)\nlt &lt;- long_term_mean(BE, 12,\n    groups = c(1, 1, 1, 1, 1, 0, 0),\n    holiday = 7\n)\n\n\n\nChained Calendar\nCreating a chained calendar is relevant when a major break occurs in the definition of the country-specific holidays.\nFirst define the 2 (or \\(N\\)) national calendars corresponding to each regime as explained in the section above.\n\nBelgium &lt;- national_calendar(list(special_day(\"NEWYEAR\"), fixed_day(7, 21)))\nFrance &lt;- national_calendar(list(special_day(\"NEWYEAR\"), fixed_day(7, 14)))\nchained_cal &lt;- chained_calendar(France, Belgium, \"2000-01-01\")\n\n\n\nComposite Calendar\nCreating a composite calendar is relevant when correcting series which include data from more than one country/region. This option can be used, for example, to create the calendar for the European Union or to create the national calendar for a country, in which regional holidays are celebrated.\n\nBelgium &lt;- national_calendar(list(special_day(\"NEWYEAR\"), fixed_day(7, 21)))\nFrance &lt;- national_calendar(list(special_day(\"NEWYEAR\"), fixed_day(7, 14)))\ncomposite_calendar &lt;- weighted_calendar(list(France, Belgium), weights = c(1, 2))\n\n\n\n\nGenerating regressors\nFirst for monthly, Q, bi monthly…(set this right)\n\nType of days\nThis section describes how to generate regressors to correct for type of days effects. They can be based on a default calendar (no specific holidays taken into account) or on a customized calendar.\n\nTrading day regressors without holidays using rjd3toolkit::td function\n\n# Monthly regressors for Trading Days: each type of day is different\n# contrasts to Sundays (6 series)\n?td\nregs_td &lt;- td(frequency = 12, c(2020, 1), 60, groups = c(1, 2, 3, 4, 5, 6, 0), contrasts = TRUE)\n\nThe groups argument allows to build groups of days, as daus belonging to the same group will be identified by the same number, and to set a reference for contrasts with the number 0.\n\n\nTrading day regressors with pre-defined holidays using rjd3toolkit::calendar_td function\nThe rjd3toolkit::calendar_td function\n\n?calendar_td\n# first define a calendar\nBE &lt;- national_calendar(list(\n    fixed_day(7, 21),\n    special_day(\"NEWYEAR\"),\n    special_day(\"CHRISTMAS\"),\n    special_day(\"MAYDAY\"),\n    special_day(\"EASTERMONDAY\"),\n    special_day(\"ASCENSION\"),\n    special_day(\"WHITMONDAY\"),\n    special_day(\"ASSUMPTION\"),\n    special_day(\"ALLSAINTSDAY\"),\n    special_day(\"ARMISTICE\")\n))\n# generate regressors\ncalendar_td(BE,\n    frequency = 12, c(1980, 1), 240, holiday = 7, groups = c(1, 1, 1, 2, 2, 3, 0),\n    contrasts = FALSE\n)\n# here three groups and one reference are defined\n# Mondays = Tuesdays= Wednesdays (`1`)\n# Thursdays= Fridays (`2`)\n# Saturdays (`3`)\n# Sundays and all holidays (`0`)\n\n\n\n\nLeap year\n\n\nLength of Period\nadjust param\n\n\nEaster Regressor\nCreate a regressor for modelling the easter effect:\n\n# Monthly regressor, five-year long, duration 8 days, effect finishing on Easter Monday\nee &lt;- easter_variable(frequency = 12, c(2020, 1), length = 5 * 12, duration = 8, endpos = 1)\n\nDisplay Easter Sunday dates in given period\nThe function below allows to display the date of Easter Sunday for each year, in the defined period. Dates are displayed in “YYYY-MM-DD” format and as a number of days since January 1st 1970.\n\n# Dates from 2018(included) to 2023 (included)\neaster_dates(2018, 2023)\n\n\n\nstock TD\n\n\nDaily data (dummies)\n\n## dummies corresponding to holidays\nq &lt;- holidays(BE, \"2020-01-01\", 365.25, type = \"All\")\ntail(q)\n\n\nWeekly data"
  },
  {
    "objectID": "A-calendar-correction.html#test-for-residual-calendar-effects",
    "href": "A-calendar-correction.html#test-for-residual-calendar-effects",
    "title": "Calendar correction",
    "section": "Test for Residual Calendar effects",
    "text": "Test for Residual Calendar effects\n(To be added: where exactly to find the tests in GUI and R)\nWe consider below tests on the seasonally adjusted series (\\(sa_t\\)) or on the irregular component (\\(irr_t\\)). When the reasoning applies on both components, we will use \\(y_t\\). The functions \\(stdev\\) stands for “standard deviation” and \\(rms\\) for “root mean squares”\nThe tests are computed on the log-transformed components in the case of multiplicative decomposition.\nTD are the usual contrasts of trading days, 6 variables (no specific calendar).\n\nNon significant irregular\nWhen \\(irr_t\\) is not significant, we don’t compute the test on it, to avoid irrelevant results. We consider that \\(irr_t\\) is significant if \\(stdev( irr_t)&gt;0.01\\) (multiplicative case) or if \\(stdev(irr_t)/rms(sa_t) &gt;0.01\\) (additive case).\n\n\nF test\nThe test is the usual joint F-test on the TD coefficients, computed on the following models:\n\nAutoregressive model (AR modelling option)\nWe compute by OLS:\n\\[\ny_t=\\mu + \\alpha y_{t-1} + \\beta TD_t + \\epsilon_t\n\\]\n\n\nDifference model\nWe compute by OLS:\n\\[\n\\Delta y_t - \\overline{\\Delta y_t}=\\beta TD_t + \\epsilon_t\n\\]\nSo, the latter model is a restriction of the first one (\\(\\alpha =1, \\mu =μ=\\overline{\\Delta y_t}\\))\nThe tests are the usual joint F-tests on \\(\\beta \\quad (H_0:\\beta=0)\\).\nBy default, we compute the tests on the 8 last years of the components, so that they might highlight moving calendar effects.\nRemark:\nIn Tramo, a similar test is computed on the residuals of the Arima model. More exactly, the F-test is computed on \\(e_t=\\beta TD_t + \\epsilon_t\\), where \\(e_t\\) are the one-step-ahead forecast errors."
  },
  {
    "objectID": "A-benchmarking.html#in-this-chapter",
    "href": "A-benchmarking.html#in-this-chapter",
    "title": "Benchmarking and temporal disagreggation",
    "section": "In this chapter",
    "text": "In this chapter\nThe sections below provide guidance on how to implement algortihms on\n\nbenchmarking\ntemporal disaggregation\n\nUsing the GUI with a plug-in or rjd3bench package."
  },
  {
    "objectID": "A-benchmarking.html#benchmarking-overview",
    "href": "A-benchmarking.html#benchmarking-overview",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Benchmarking overview",
    "text": "Benchmarking overview\nOften one has two (or multiple) series of different frequency for the same target variable. Sometimes, however, these series are not coherent in the sense that they don’t match up. Benchmarking[^1] is a method to deal with this situation. An aggregate of a higher-frequency measurement variables is not necessarily equal to the corresponding lower-frequency less-aggregated measurement. Moreover, the sources of data may have different reliability levels. Usually, less frequent data are considered more trustworthy as they are based on larger samples and compiled more precisely. The more reliable measurements, hence often the less frequent, will serve as benchmark.\nIn seasonal adjustment methods benchmarking is the procedure that ensures the consistency over the year between adjusted and non-seasonally adjusted data. It should be noted that the ESS Guidelines on Seasonal Adjustment (2015), do not recommend benchmarking as it introduces a bias in the seasonally adjusted data. The U.S. Census Bureau also points out that “forcing the seasonal adjustment totals to be the same as the original series annual totals can degrade the quality of the seasonal adjustment, especially when the seasonal pattern is undergoing change. It is not natural if trading day adjustment is performed because the aggregate trading day effect over a year is variable and moderately different from zero”[^2]. Nevertheless, some users may need that the annual totals of the seasonally adjusted series match the annual totals of the original, non-seasonally adjusted series[^3].\nAccording to the ESS Guidelines on Seasonal Adjustment (2015), the only benefit of this approach is that there is consistency over the year between adjusted and the non-seasonally adjusted data; this can be of particular interest when low-frequency (e.g. annual) benchmarking figures officially exist (e.g. National Accounts, Balance of Payments, External Trade, etc.) and where users’ needs for time consistency are stronger."
  },
  {
    "objectID": "A-benchmarking.html#tools",
    "href": "A-benchmarking.html#tools",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Tools",
    "text": "Tools\n\nGUI\n\nWith the pre-defined specifications the benchmarking functionality is not applied by default following the ESS Guidelines on Seasonal Adjustment (2015) recommendations. It means that once the user has seasonally adjusted the series with a pre-defined specification the Benchmarking node is empty. To execute benchmarking click on the Specifications button and activate the checkbox in the Benchmarking section.\n\nBenchmarking option – a default view\nThree parameters can be set here. Target specifies the target variable for the benchmarking procedure. It can be either the Original (the raw time series) or the Calendar Adjusted (the time series adjusted for calendar effects). Rho is a value of the AR(1) parameter (set between 0 and 1). By default it is set to 1. Finally, Lambda is a parameter that relates to the weights in the regression equation. It is typically equal to 0 (for an additive decomposition), 0.5 (for a proportional decomposition) or 1 (for a multiplicative decomposition). The default value is 1.\nTo launch the benchmarking procedure click on the Apply button. The results are displayed in four panels. The top-left one compares the original output from the seasonal adjustment procedure with the result from applying a benchmarking to the seasonal adjustment. The bottom-left panel highlights the differences between these two results. The outcomes are also presented in a table in the top-right panel. The relevant statistics concerning relative differences are presented in the bottom-right panel.\n\nThe results of the benchmarking procedure\nBoth pictures and the table can be copied the usual way (see the Simple seasonal adjustment of a single time series scenario).\n\nOptions for benchmarking results\nTo export the result of the benchmarking procedure (benchmarking.result) and the target data (benchmarking.target) one needs to once execute the seasonal adjustment with benchmarking\n\nThe SAProcessing menu\nExpand the \"+\" menu and choose an appropriate data format (here Excel has been chosen). It is possible to save the results in TXT, XLS, CSV, and CSV matrix formats. Note that the available content of the output depends on the output type.\n\nExporting data to an Excel file\nChose the output items that refer to the results from the benchmarking procedure, move them to the window on the right and click OK.\n\nExporting the results of the benchmarking procedure\n\n\n\nBenchmarking and Temporal Disaggregation plugin (version 2.x)\nSelect Tools \\(\\rightarrow\\) Plug-ins for JDemetra+ to install Benchmarking plug-in.\nOnce the plugin is installed, two more options appear in the Workspace window: Benchmarking and Temporal Disaggregation.\n\n\n\nText"
  },
  {
    "objectID": "A-benchmarking.html#benchmarking-with-different-frequencies",
    "href": "A-benchmarking.html#benchmarking-with-different-frequencies",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Benchmarking with different frequencies",
    "text": "Benchmarking with different frequencies\nThese methods provide a high-frequency series (input series) modified so that it fulfils a linear relationship, with another series of low frequency (benchmark), both series measure the same target variable. An example of the relation to be fulfilled could be that the low frequency series (quarterly frequency) coincides with the quarterly sum of the high frequency series (monthly frequency).\nMultivariate benchmarking also forces contemporary linear relations between high frequency series. If these relations do not exist, benchmarking could be carried out for each series separately. Normally contemporary relations are linear and the relations of aggregation are also linear and the same for all series, so the contemporary relations between low frequency series are fulfilled.\nThe benchmarking methods available in the benchmarking and time disaggregation plug-in are: Denton, Cholette, and Cholette multivariate.\n\nUnivariate: Denton and Cholette\nTo run Denton univariate case select:\nStatistical Methods \\(\\rightarrow\\) Benchmarking \\(\\rightarrow\\) Denton or Cholette\n\n\n\nText\n\n\nIn both cases, a new window is displayed to launch one of the methods with the series selected. In the upper left side, drag the high frequency series from the Providers window and drop it in Drop Series here and the low frequency series in Drop Constraint here.\n\nDenton\nIn the top right of the screen, select the Specifications button to set the specifications to apply each method. See below for a description of the available options on Denton method:\n\nType: Aggregation function (Sum, Average, Last or First). This forces the low-frequency series to match the aggregation function selected of the high frequency series.\nMultiplicative: if the checkbox is selected, the proportional Denton method is applied. Otherwise, additive Denton is applied.\nModified Denton: if the checkbox is selected, the modified Denton method is applied. Otherwise, original Denton is applied. It is recommended to select it; as original Denton perform a special treatment on the first observation.\nDifferencing: Number of regular differences. By default 1.\nDefault frequency: periodicity of the low frequency data. The options are: Yearly, HalfYearly, QuadriMonthly, Quarterly, Bimonthly and Monthly.\n\n\n\n\nDenton Specifications\n\n\n\n\nCholette\nSee below for a description of the available options on Cholette method:\n\nType: Aggregation function (Sum, Average, Last or First). This forces the low-frequency series to match the aggregation function selected of the high frequency series.\nAggregation frequency: periodicity of the low frequency data. The options are: Yearly, HalfYearly, QuadriMonthly, Quarterly, Bimonthly and Monthly.\nRho: value between \\(-1\\) and \\(1\\). It is the coefficient of an AR(\\(1\\)) model that follows the error term. The default value is \\(1\\), equivalent to applying Denton.\nLambda: value between \\(0\\) and \\(1\\). It is the parameter \\(\\lambda\\) of the following function to be minimized in Cholette method:\n\\[\n\\sum_t \\left( \\frac{x_t - z_t}{\\left| z_t \\right|^{\\lambda}} - \\rho \\frac{x_{t-1} - z_{t-1}}{\\left| z_{t-1} \\right|^{\\lambda}}\\right)^2\n\\]\nUsually lambda is \\(0\\) or \\(1\\) equivalent to applying additive benchmarking and proportional benchmarking method respectively.\n\n\n\n\nCholette Specifications\n\n\nIn both cases, Denton and Cholette methods, the output is a graph with the original series and the benchmarked series. There is no table with the results, but it is very easy to create one from the graph. Select the graph and select copy, then paste the values in excel (control-V).\n\n\n\nDenton output\n\n\n\n\n\nMulti-variate: Cholette\nUp coming content."
  },
  {
    "objectID": "A-benchmarking.html#a-bench-tempd",
    "href": "A-benchmarking.html#a-bench-tempd",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Temporal Disaggregation",
    "text": "Temporal Disaggregation\nThese methods are used to disaggregate a series from low frequency to high frequency. Temporal disaggregation methods developed in the plug-in are Chow-Lin, Fernández and Litterman.\nWhen there are high frequency related indicators, these methods provide high frequency estimations for a series whose sums, averages,first or last values are consistent with the observed low frequency series, applying a regression model where it is assumed that the high frequency series to be estimated follows a multiple regression with p related series (indicators).\nSee Methods\\(\\rightarrow\\)Temporal disaggregation for more theoretical detail.\n\nTemporal Disaggregation in the GUI\nTo run Temporal Disaggregation methods select Temporal disaggregation\\(\\rightarrow\\) Regression Model:\n\n\n\nTemporal Disggregation\n\n\nA new window is displayed to launch one of the methods with the series selected. In the upper left side drag the low frequency series from the Providers window and drop it in Y box and the proxy series or indicator with high frequency series in X box.\n\n\n\nTemporal Disggregation\n\n\nIn the top right of the screen, select Specifications to set the specifications to apply each method. Here is a description of the available options on Temporal Disaggregation methods:\n\n\n\nTemporal Disggregation\n\n\n\nEstimation span: Specifies the span (data interval) of the time series to be used in the temporal disaggregation process. The user can restrict the span. The common settings are:\n\n\n\n\n\n\n\n\n\nOption\nDescription (expected format)\n\n\n\n\n\nAll\ndefault\n\n\n\nFrom\nfirst observation included (yyyy-mm-dd)\n\n\n\nTo\nlast observation included (yyyy-mm-dd)\n\n\n\nBetween\ninterval [from ; to] included (yyyy-mm-dd to yyyy-mm-dd)\n\n\n\nFirst\nnumber of observtions from the beginning of the series included (dynamic) (integer)\n\n\n\nLast\nnumber of observations from the end of the series (dynamic)(integer)\n\n\n\nExcluding\nexcluding N first observation and P last observation from the computation,dynamic) (integer)\n\n\n\nPreliminary check\ncheck to exclude highly problematic series e.g. the series with a number of identical observations and/or missing values above pre-specified threshold values. (True/False)\n\n\n\n\n\nError: determines the method to be applied and it refers to the model that follows the error term.\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n\nAr1\nChow-Lin method (default)\n\n\n\nWn\nClassical Regression model\n\n\n\nRw\nFernández\n\n\n\nRwAr1\nLitterman\n\n\n\nI2\nIntegrated order 2\n\n\n\nI3\nIntegrated order 3\n\n\n\n\n\nParameter: Coefficient of the AR(1) of the innovations model. It has a value between -1 and 1. This parameter exists only if RWar1 or Ar1 is selected in the error parameter.\nConstant: a constant is included in the model if it is selected.\nTrend: a linear trend is included in the model if it is selected.\nType: Aggregation function (Sum, Average, Last or First). This forces the low-frequency series to match the aggregation function selected of the high frequency series.\nDefault frequency: it is the frequency of the output series.\nAdvanced options: These parameters are related to state space model and the algorithm used to obtain the estimations.\n8.1. Diffuse regression coefficient: Indicates if the coefficients of the regression model are diffuse (T) or fixed unknown (F, default).\n\nHere are the results:\n\n\n\nTemporal Disggregation\n\n\nSelect Model\\(\\rightarrow\\)Summary to see the estimation of \\(rho\\) (coefficient of the AR(1) model) and the coefficient of the regression model. Additionally the BIC, AIC and AICC.\nTo confirm that the model works well, select Model\\(\\rightarrow\\)Residuals\\(\\rightarrow\\)Statistics and see the tests on the residuals of the model:\n\n\n\nTemporal Disggregation\n\n\nSelect MainResults\\(\\rightarrow\\)Table to obtain the disaggregated series and standard deviation.\n\n\n\nTemporal Disggregation\n\n\nSelect MainResults\\(\\rightarrow\\)Chart to see a graph of the disaggregated series and the confidence interval.\n\n\nBenchmarking and Temporal Disaggregation in R (version 3.x)\nUse the [rjd3bench]((https://github.com/rjdemetra/rjd3bench) package and see its documentation pages."
  },
  {
    "objectID": "A-benchmarking.html#benchmarking",
    "href": "A-benchmarking.html#benchmarking",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Benchmarking",
    "text": "Benchmarking\nUp coming content"
  },
  {
    "objectID": "A-benchmarking.html#temporal-disaggregation",
    "href": "A-benchmarking.html#temporal-disaggregation",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Temporal Disaggregation",
    "text": "Temporal Disaggregation\nTo perform Temporal Disaggregation methods use the function temporaldisaggregation:\n\noutput &lt;- rjd3bench::temporaldisaggregation(\n    series = y, indicators = x, model = \"Rw\", freq = 12,\n    conversion = \"Average\", diffuse.algorithm = \"Diffuse\"\n)\n\nThe output is a list containing:\nTo obtain \\(rho\\) estimation:\n\noutput$estimation$parameter"
  },
  {
    "objectID": "A-trend-cycle-estimation.html#in-this-chapter",
    "href": "A-trend-cycle-estimation.html#in-this-chapter",
    "title": "Trend-cycle estimation",
    "section": "In this Chapter",
    "text": "In this Chapter\nThis chapter will cover the implementation of trend estimation methods available in JDemetra+ v 3.\nMore methodological details will be provided here"
  },
  {
    "objectID": "A-trend-cycle-estimation.html#tools-for-access",
    "href": "A-trend-cycle-estimation.html#tools-for-access",
    "title": "Trend-cycle estimation",
    "section": "Tools for access",
    "text": "Tools for access\nFor the time being this algorithms are available in two R packages.\n\nrjd3filters\nrjd3filters is available here, with useful information in the Readme file and function documentation.\n\n\nrjd3x11plus\nrjd3x11plus is available here, with (up coming) useful information in the Readme file and function documentation.\n(Up coming content)"
  },
  {
    "objectID": "A-revision-analysis.html#in-this-chapter",
    "href": "A-revision-analysis.html#in-this-chapter",
    "title": "Revision Analysis",
    "section": "In this Chapter",
    "text": "In this Chapter\nWe will cover how analyse the behaviour of revisions, typically on frequently published (and revised) macro-economic indicators."
  },
  {
    "objectID": "A-revision-analysis.html#tools-for-access",
    "href": "A-revision-analysis.html#tools-for-access",
    "title": "Revision Analysis",
    "section": "Tools for access",
    "text": "Tools for access\nThe rjd3revi”sions packages allows to perform revision analysis.\nMore information is available directly in the package documentation and vignette.\n\nlibrary(rjd3revisions)\nbrowseVignettes(\"rjd3revisions\")\n\nUp coming content."
  },
  {
    "objectID": "A-nowcasting.html",
    "href": "A-nowcasting.html",
    "title": "Nowcasting",
    "section": "",
    "text": "Up coming content.\nIn the meantime the user can refer to the documentation provided with the nowcasting plug-in for version 2.2 and later."
  },
  {
    "objectID": "P_Tools.html",
    "href": "P_Tools.html",
    "title": "Tools",
    "section": "",
    "text": "This part describes the tools allowing to access JDemetra+ algorithms.\nPractical guidance for using them is provided here.\nWhereas, further methodological insights on each algorithm can be found in the Methods part of this book.\nIn this part:\nGraphical User Interface (GUI)\n\nOverview\nData visualization and time series tools\nSeasonal Adjustement and Modelling features\nOutput: series, parameters and diagnostics\n\nR ecosystem:\n\nR packages\n\nOther tools:\n\nProduction tools: Cruncher and quality report\nRevision policies\nPlug-ins for GUI"
  },
  {
    "objectID": "T-GUI-Overview.html#in-this-chapter",
    "href": "T-GUI-Overview.html#in-this-chapter",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter provides general information about using the Graphical User Interface (GUI). Specific indications related to a given algorithm (X13-ARIMA, Tramo-seats, Benchmarking…) are displayed in the relevant chapters, listed here.\nContents:\n\nAvailable algorithms\nInstallation and launch\nImporting data\nGeneral window and menu structure\n\nAdditional chapters related to GUI features, provide information on:\n\nData visualization and generic time series tools\nSpecific Seasonal Adjustement and Modelling features\nOutput: series, parameters and diagnostics\n\n\nAvailable algorithms\n\nv2v3\n\n\nThe Graphical User Interface in the 2.x family gives access to:\n\nSeasonal adjustment (SA) algorithms\n\nX13-ARIMA\nTRAMO-SEATS\nDirect-indirect SA comparisons\n\nOutlier detection (TERROR)\nBenchmarking\n\n\n\nThe Graphical User Interface in the 3.x family gives access in addition to extended SA algorithms for high-frequency data (HF).\n\n\n\n\n\nAvailable Time Series tools\nThe Graphical User Interface in the 2.x and 3.x family give access to generic time series tools:\n\nGraphics\n\ntime domain\nspectral analysis\n\nTests\n\nseasonality tests\nautocorrelation, normality, randomness tests"
  },
  {
    "objectID": "T-GUI-Overview.html#installation-procedure",
    "href": "T-GUI-Overview.html#installation-procedure",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Installation Procedure",
    "text": "Installation Procedure\nThe installation procedure is detailed in this tutorial.\nThis tutorial allows you to install the tools (GUI and R packages) in version 2 and in version 3.\n\nLaunching JDemetra+\nTo open an application, double click on nbdemetra.exe or nbdemetra64.exe depending on the system version (nbdemetra.exe for the 32-bit system version and nbdemetra64.exe for the 64-bit system version).\n\n\n\nLaunching JDemetra+\n\n\nIf the launching of JDemetra+ fails, you can try the following operations:\n\nCheck if Java SE Runtime Environment (JRE) is properly installed by typing in the following command in a terminal:\n\njava --version\n\nCheck the logs in your home directory:\n\n%appdata%/.nbdemetra/dev/var/log/ for Windows;\n~/.nbdemetra/dev/var/log/` for Linux and Solaris;\n~/Library/Application Support/.nbdemetra/dev/var/log/ for Mac OS X.\n\n\nIn order to remove a previously installed JDemetra+ version, the user should delete an appropriate JDemetra+ folder."
  },
  {
    "objectID": "T-GUI-Overview.html#starting-window",
    "href": "T-GUI-Overview.html#starting-window",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Starting Window",
    "text": "Starting Window\nYou can click on the image in the area that interests you:\n       \n\n\nJDemetra+ default window\nBy default, on the left hand side of the window two panels are visible:\n\nThe Workspace panel stores the results generated by the software as well as settings used to create them;\nThe Providers panel organises the imported raw data within each data provider;\n\nThe other key parts of the user interface are:\n\nThe application menu.\nA central empty zone for presenting the actual analyses further called the Results panel."
  },
  {
    "objectID": "T-GUI-Overview.html#providers-window",
    "href": "T-GUI-Overview.html#providers-window",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Providers window",
    "text": "Providers window\n\n\n\nThe Providers window\n\n\nBy default, JDemetra+ supports the following data sources:\n\nJDBC;\nODBC;\nSDMX;\nExcel spreadsheets;\nTSW (input files for the TRAMO-SEATS-Windows application by the Bank of Spain);\nTXT;\nUSCB (input files for the X-13-ARIMA-SEATS application by the U.S. Census Bureau);\nXML.\n\nAll standard databases (Oracle, SQLServer, DB2, MySQL) are supported by JDemetra+ via JDBC, which is a generic interface to many relational databases. Other providers can be added by users by creating plugins (see Plugins section in the Tools menu).\n\nImport data\nTo import data from a given data source:\n\nclick on this data source in the Providers window shown below\nchoose Open option and specify the import details, such as a path to a data file.\n\nThese details vary according to data providers.\n\n\nSpreadsheetText or csv file\n\n\n\n\n\nAn example of importing process for the Excel file :\n\n\nThe example below show how to import the data from an Excel file.\n\nFrom the Providers window right-click on the Spreadsheets branch and choose Open option.\n\nThe Open data source window contains the following options:\n\nSpreadsheet file – a path to access the Excel file.\nData format (or Observartion format in v3) – the data format used to read dates and values. It includes three fields: locale (country), date pattern (data format, e.g. yyyy-mm-dd), number pattern (a metaformat of numeric value, e.g. 0.## represents two digit number).\nFrequency – time series frequency. This can be undefined, yearly, half-yearly, four-monthly, quarterly, bi-monthly, or monthly. When the frequency is set to undefined, JDemetra+ determines the time series frequency by analysing the sequence of dates in the file.\nAggregation type – the type of aggregation (over time for each time series in the dataset) for the imported time series. This can be None, Sum, Average, First, Last, Min or Max. The aggregation can be performed only if the frequency parameter is specified. For example, when frequency is set to Quarterly and aggregation type is set to Average, a monthly time series is transformed to quarterly one with values that are equal to the one third of the sum of the monthly values that belong to the corresponding calendar quarter.\nClean missing  – erases missing values at the start of the series.\n\nNext, in the Source section click the grey “…” button to open the file.\n\nChoose a file and click OK.\n\nThe user may specify Data format, Frequency and Aggregation type, however this step is not compulsory. When these options are specified JDemetra+ is able to convert the time series frequency. Otherwise, the functionality that enables the time series frequency to be converted will not be available.\n\nThe data are organized in a tree structure.\n\n\nOnce imported, your s is visible as a “node” structure\n\n\n\nA structure of a dataset\n\n\n\n\n\n\n\n\nAccepted formats\n\n\n\nIn v2, the formats .xls and .xlsx are accepted.\nIn v3, only the format .xlsx is accepted (.xls files are no longer supported).\n\n\n\n\n\n\n\n\nHow to set-up your spreadsheet\n\n\n\n\n\n\nDates in Excel date format, in the first column (or in the first row)\nTitles of the series in the corresponding cell of the first row (or in the first column)\nTop-left cell \\(A1\\) can include text or it can be left empty\nEmpty cells are interpreted by JDemetra+ as missing values\nIf empty cells are at the beginning of the series they can be ignored using the option clean-missing.\n\n\n\n\nExample of an Excel spreadsheet that can be imported to JDemetra+\n\n\nIn Excel files, series are identified by their names (colnames) in the file.\n\n\n\n\n\nThe example below show how to import the data from an Excel file.\n\nFrom the Providers window right-click on the Txt files branch and choose Open option.\n\nThe Open data source window contains the following options:\n\nText file – a path to access the file.\nCharset – the encoding used to encode the file\nLines to skip – the number of lines to skip before reading the data\nDelimiter – the character used to separate fields in the file\nText qualifier – the characters used to retrieve text fileds\nHas header – check tu use the first line as header\nData format (or Observartion format in v3) – the data format used to read dates and values. It includes three fields: locale (country), date pattern (data format, e.g. yyyy-mm-dd), number pattern (a metaformat of numeric value, e.g. 0.## represents two digit number).\nFrequency – time series frequency. This can be undefined, yearly, half-yearly, four-monthly, quarterly, bi-monthly, or monthly. When the frequency is set to undefined, JDemetra+ determines the time series frequency by analysing the sequence of dates in the file.\nAggregation type – the type of aggregation (over time for each time series in the dataset) for the imported time series. This can be None, Sum, Average, First, Last, Min or Max. The aggregation can be performed only if the frequency parameter is specified. For example, when frequency is set to Quarterly and aggregation type is set to Average, a monthly time series is transformed to quarterly one with values that are equal to the one third of the sum of the monthly values that belong to the corresponding calendar quarter.\nClean missing – erases the missing values of the series.\nPartial aggregation – Allow partial aggregation (only with average and sum aggregation).\n\nNext, in the Source section click the grey “…” button to open the file.\n\nChoose a file and click OK.\n\nThe data are organized in a tree structure.\n\n\n\n\n\n\n\n\nHow to set up you text or csv file\n\n\n\n\n\n\nDates in Excel date format, in the first column (or in the first row)\nTitles of the series in the corresponding cell of the first row (or in the first column)\nTop-left cell \\(A1\\) can include text or it can be left empty\nEmpty cells are interpreted by JDemetra+ as missing values\nIf empty cells are at the beginning of the series they can be ignored using the option clean-missing.\n\n\n\n\nExample of an Excel spreadsheet that can be imported to JDemetra+\n\n\nIn text files, series are identified by their position in the file.\n\n\n\n\n\n\n\n\nWrangling data\nSeries uploaded to the Providers window can be\n\nDisplayed,\nModified\nTested for seasonality / white noise\n\nor used in any available algorithm (link to list)\n\nModelled Modelling\nSeasonnally adjusted\nBenchmarked\n\n\n\nBehaviour options\n\nRestoring data sources\nThe data sources can be restored after re-starting the application so that there is no need to get them again. This functionality can be set in the Behaviour tab available at the Option item from the Tools menu.\n\n\nAdd Star\nYou can also favorite files to find them each time you open the software.\nTo favorite a file:\n\nright-click on the file\nclick on Add star\n\n\n\n\nCreate a new favorite\n\n\nA favorite file will have a little star on top right of the logo:\n\n\n\nExample of a favorite file\n\n\nTo remove a favorite:\n\nright-click on the file\nclick on Remove star\n\n\n\n\nRemove a favorite"
  },
  {
    "objectID": "T-GUI-Overview.html#workspace-structure",
    "href": "T-GUI-Overview.html#workspace-structure",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Workspace Structure",
    "text": "Workspace Structure\nThe workspace is the main data structure used by JDemetra+.\nThe workspace saved by JDemetra+ includes:\n\nMain folder containing several folders that correspond to the different types of items created by the user and;\nThe .xml file that enables the user to import the workspace to the application and to display its content.\n\n\n\n\nExample of a workspace created by JDemetra+.\n\n\nThe workspace can be shared with other users, which eases the burden of work with defining specifications, modelling and seasonal adjustment processes.\nThe main folder contains:\n\na folder SAProcessing with all the result of the SA\nfolders TramoSeatsSpec and/or X13Spec with the custom specifications\na folder Variables for external regressor and variables\na folder Calendars with the calendars used to correct the trading days effect\na folder Output contains all the generated output from the GUI\n\n\n\n\nStructure of a workspace"
  },
  {
    "objectID": "T-GUI-Overview.html#workspace-window",
    "href": "T-GUI-Overview.html#workspace-window",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Workspace window",
    "text": "Workspace window\nThe workspace window displays the characteristics of a workspace but ALSO gives access to other peripheric routines, the results of which won’t be stored in a workspace (as data structure).\nYou can click on the image in the area that interests you:\n     \n\nJDemetra+ default window\nYou can find:\n\nModelling (contains the default and user-defined specifications for modelling; and the output from the modelling process)\nSeasonal adjustment (contains the default and user-defined specifications for seasonal adjustment and the output from the seasonal adjustment process),\nUtilities (calendars and user defined variables).\n\n\nModelling\n(I ll rewrite all this) access to RegArima or Tramo modelling routines\nwhich are the same as the ones used for the pre-treatment phase of seasonal adjustment with X13-ARIMA (Reg-Arima) and TRAMO-SEATS (Tramo) and thus described in the SA chapter.\nThis section is divided into two parts: * Specifications, which presents parameters of the modelling procedure. * Output, which details a typical output produced by the modelling procedure.\nThe specifications and output of the modelling procedure are displayed in the Workspace window.\n\n\n\nThe Workspace window with the nodes for the modelling procedure marked\n\n\n\n\nSeasonal adjustment\n\n\n\nThe Workspace window with the nodes for the seasonal adjustment procedure marked\n\n\nBrief presentation and or link ?"
  },
  {
    "objectID": "T-GUI-Overview.html#results-panel-overview",
    "href": "T-GUI-Overview.html#results-panel-overview",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Results Panel",
    "text": "Results Panel\nResults Panel of seasonal adjustment will be presented in another chapter"
  },
  {
    "objectID": "T-GUI-Overview.html#topbar-menu",
    "href": "T-GUI-Overview.html#topbar-menu",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Top Bar Menu and options",
    "text": "Top Bar Menu and options\nYou can click on the image in the area that interests you:\n        \n\nThe Top bar menus\nThe majority of functionalities are available from the main application menu, which is situated at the very top of the main window. If the user moves the cursor to an entry in the main menu and clicks on the left mouse button, a drop-down menu will appear. Clicking on an entry in the drop-down menu selects the highlighted item.\n\n\n\nThe main menu with selected drop-down menu\n\n\nThe functions available in the main application menu are:\n\nFile\nStatistical methods\nView\nTools\nWindow\nHelp\nRegArimaDoc\nX-13Doc\nTramoDoc\nTramoSeatsDoc\nSAProcessingDoc\n\n\nFile\nThe File menu is intended for working with workspaces and data sources. It offers the following functions:\n\nNew Workspace – creates a new workspace and displays it in the Workspace window with a default name (Workspace_#number);\nOpen Workspace – opens a dialog window, which enables the user to select and open an existing workspace;\nOpen Recent Workspace – presents a list of workspaces recently created by the user and enables the user to open one of them;\nSave Workspace – saves the project file named by the system under the default name (Workspace_#number) and in a default location. The workspace can be re-opened at a later time;\nSave Workspace As… – saves the current workspace under the name chosen by the user in the chosen location. The workspace can be re-opened at a later time;\nOpen Recent – presents a list of datasets recently used and enables the user to open one of them;\nExit – closes an application.\n\n\n\n\nThe content of the File menu\n\n\n\n\nStatistical Methods\nHere just a hint and link to relevant chapters\nThe Statistical methods menu includes functionalities for modelling, analysis and the seasonal adjustment of a time series. They are divided into three groups:\n\nAnomaly Detection – allows for a purely automatic identification of regression effects;\n\n\n\n\nThe Anomaly detection tab.\n\n\n\nModelling – enables time series modelling using the TRAMO and RegARIMA models;\n\n\n\n\nThe Modelling tab.\n\n\n\nSeasonal adjustment – intended for the seasonal adjustment of a time series with the TRAMO-SEATS and X-13ARIMA-SEATS methods.\n\n\n\n\nThe Seasonal adjustment tab.\n\n\n\n\nTools menu\n\n\n\nThe Tools menu\n\n\nThe following functionalities are available from the Tools menu:\n\nContainer – includes several tools for displaying data in a time domain;\nSpectral analysis – contains tools for the analysis of a time series in a frequency domain;\nAggregation – enables the user to investigate a graph of the sum of multiple time series;\nDifferencing – allows for the inspection of the first regular differences of the time series;\nSpreadsheet profiler – offers an Excel-type view of the XLS file imported to JDemetra+.\nPlugins – allows for the installation and activation of plugins, which extend JDemetra+ functionalities.\nOptions – presents the default interface settings and allows for their modification.\n\n\nContainer\nContainer includes basic tools to display the data. The following items are available: Chart, Grid, Growth Chart and List.\n\n\n\nThe Container menu\n\n\ndetailed in data visualization part (link to set up)\n\n\nSpectral analysis\nThe Spectral analysis section provides three spectral graphs that allows an in-depth analysis of a time series in the frequency domain. These graphs are the Auto-regressive Spectrum, the Periodogram and the Tukey Spectrum.\nFor more information the user may refer to the spectral analysis chapter and to the sprectral graphs section.\n\n\n\nTools for spectral analysis\n\n\n\n\nAggregation\nAggregation calculates the sum of the selected series and provides basic information about the selected time series, including the start and end date, the number of observations and a sketch of the data graph.\nlink to data visu chap\n\n\nDifferencing\nThe Differencing window displays the first regular differences for the selected time series together with the corresponding periodogram and the PACF function.\nlink to data visu chap\n\n\nSpreadsheet profiler\nThe Spreadsheet profiler offers an Excel-type view of the XLS file imported to JDemetra+. To use this functionality drag the file name from the Providers window and drop it to the empty Spreadsheet profiler window.\n\n\n\nThe Spreadsheet Profiler window\n\n\n\n\nPlugins\nInstallation an functionalities of plugins are described in the related chapter.\n\n\n\nView\nThe View menu contains functionalities that enable the user to modify how JDemetra+ is viewed. It offers the following items:\n\nSplit – the function is not operational in the current version of the software.\nToolbars – displays selected toolbars under the main menu. The File toolbar contains the Save all icon. The Performance toolbar includes two icons: one to show the performance of the application, the other to stop the application profiling and taking a snapshot. The Other toolbar determines the default behaviour of the program when the user double clicks on the data. It may be useful to plot the data, visualise it on a grid, or to perform any pre-specified action, e.g. execute a seasonal adjustment procedure.\nShow Only Editor – displays only the Results panel and hides other windows (e.g. Workspace and Providers).\nFull Screen – displays the current JDemetra+ view in full screen.\n\n\n\n\nThe View menu\n\n\n\n\nWindow menu\nThe Window menu offers several functions that facilitate the analysis of data and enables the user to adjust the interface view to the user’s needs.\n\n\n\nThe Window menu\n\n\n\nPreview Time Series – opens a window that plots any of the series the user selects from Providers.\nDebug – opens a Preview Time Series window that enables a fast display of the graphs for time series from a large dataset. To display the graph click on the series in the Providers window.\nProviders – opens (if closed) and activates the Providers window.\nVariables – opens (if closed) and activates the Variable window.\nWorkspace – opens (if closed) and activates the Workspace window.\nOutput – a generic window to display outputs in the form of text; useful with certain plug-ins (e.g. tutorial descriptive statistics).\nEditor – activates the editor panel (and update the main menu consequently).\nConfigure Window – enables the user to change the way that the window is displayed (maximise, float, float group, minimise, minimise group). This option is active when some window is displayed in the JD+ interface.\nProperties – opens the Properties window and displays the properties of the marked item (e.g. time series, data source).\nReset Windows – restores the default JDemetra+ view.\nClose Window – closes all windows that are open.\nClose All Documents – closes all documents that are open.\nClose Other Documents – closes all open documents except for the one that is active (which is the last activated one).\nDocument Groups – enables the user to create and manage document groups.\nDocuments – lists all active documents.\n\n\n\nHelp menu\n\n\nAll TS&view\n\n\nSearch option"
  },
  {
    "objectID": "T-GUI-Overview.html#options-window",
    "href": "T-GUI-Overview.html#options-window",
    "title": "Graphical User Interface (GUI): Overview",
    "section": "Options",
    "text": "Options\n\nThe Options window includes five main panels:\n\nDemetra,\nGeneral,\nKeymap,\nAppearance\nand Miscellaneous.\n\nThey are visible in the very top of the Options window.\n\n\n\nMain sections of the Options window\n\n\n\nDemetra panel\n\nv2v3\n\n\nBy default, the Demetra panel is shown. It is divided into seven tabs:\n\nBehaviour,\nDemetra UI,\nStatistics,\nData transfer,\nDemetra Paths,\nProcDocumentItems,\nand Interchange.\n\n\n\n\nDemetra panel in v2\n\n\n\n\nBy default, the Demetra panel is shown. It is divided into three tabs::\n\nCommon UI,\nBehaviour,\nand Demetra Paths.\n\n\n\n\nDemetra panel in v3\n\n\n\n\n\n\nBehaviour tab\n\n\n\nThe content of the Behavior tab\n\n\nThe tab Behaviour defines the default reaction of JDemetra+ to some of the actions performed by the user.\n\nProviders – an option to show only the data providers that are currently available.\n\n\n\n\nThe option Providers\n\n\n\nPersistence – an option to restore the data sources after re-starting the application so that there is no need to fetch them again (Persist opened DataSources) and an option to restore all the content of the chart and grid tools (Persist tools content).\n\n\n\n\nThe option Persistence\n\n\n\nThreading – defines how resources are allocated to the computation (Batch Pool Size controls the number of cores used in parallel computation and Batch Priority defines the priority of computation over other processes). Changing these values might improve computation speed but also reduce user interface responsiveness.\n\n\n\n\nThe option Threading\n\n\n\nTime Series – determines the default behaviour of the program when the user double clicks on the data. It may be useful to plot the data, visualise it on a grid, or to perform any pre-specified action, e.g. execute a seasonal adjustment procedure.\n\n\n\n\nThe option Time Series\n\n\n\n\n\n\n\n\nLow-level options\n\n\n\nIn v3, the option Show low-level options unable the user to access more settings in the specification.\n\n\n\nLow level options on ARIMA specification\n\n\n\n\n\n\nDemetra UI / CommonUI tab\n\nv2v3\n\n\nIn v2, this panel is called Demetra UI.\n\n\n\nThe content of the Demetra UI tab\n\n\n\n\nIn v3, this panel is called CommonUI.\n\n\n\nCommonUI tab in v3\n\n\n\n\n\nThe Demetra UI tab enables the setting of:\n\nA default colour scheme for the graphs (Color scheme).\n\n\n\n\nThe option Charts\n\n\n\nThe data format (uses MS Excel conventions). For example, ###,###.#### implies the numbers in the tables and the y-axis of the graphs will be rounded up to four decimals after the decimal point (Data format (or Observartion format in v3)).\n\n\n\n\nThe option Data format\n\n\n\nThe default number of last years of the time series displayed in charts representing growth rates (Growth rates).\n\n\n\n\nThe option Growth rates\n\n\n\nThe control of the view of the window for adding pre-specified outliers. (Pre-specified Outliers).\n\n\n\n\nThe option Pre-specified Outliers\n\n\n\nThe visibility of the icons in the context menus (Context Menus).\n\n\n\n\nThe option Context Menus\n\n\n\n\nDemetra path tab\nDemetra Paths allows the user to specify the relative location of the folders where the data can be found. In this way, the application can access data from different computers. Otherwise, the user would need to have access to the exact path where the data is located. To add a location, select the data provider, click the “+” button and specify the location.\n\nv2v3\n\n\n\n\n\nThe content of the Demetra Paths tab in v2\n\n\n\n\n\n\n\nThe content of the Demetra Paths tab in v3\n\n\n\n\n\n\n\nStatistics tab\n\nv2v3\n\n\n\n\n\nStatistics tab in v2\n\n\n\n\n\n\n\nSA panel\n\n\n\n\n\nThe Statistics tab includes options to control:\n\nThe number of years used for spectral analysis and for model stability (Default Number of Last Years);\n\n\nv2v3\n\n\n\n\n\nDefault Number of Last Years option in v2\n\n\n\n\n\n\n\nDefault Number of Last Years option in v3\n\n\n\n\n\n\nThe default pre-defined specification for seasonal adjustment (Seasonal Adjustment);\n\n\n\n\nSeasonal Adjustment option\n\n\n\nThe type of the analysis of revision history (Revision History):\n\nFreeParameters – the RegARIMA model parameters and regression coefficients of the RegARIMA model will be re-estimated each time the end point of the data is changed. This argument is ignored if no RegARIMA model is fit to the series.\nComplete – the whole RegARIMA model together with regressors will be re-identified and re-estimated each time the end point of the data is changed. This argument is ignored if no RegARIMA model is fitted to the series.\nNone – the ARIMA parameters and regression coefficients of the RegARIMA model will be fixed throughout the analysis at the values estimated from the entire series (or model span).\n\n\n\n\n\nRevision History option in v2\n\n\n\nThe settings for the quality measures and tests used in a diagnostic procedure:\n\nDefault components – a list of series and diagnostics that are displayed in the SAProcessing \\(\\) Output window. The list of default items can be modified with the respective Select button (see figure below)\n\n\n\n\nThe Default components section on the Statistics tab\n\n\n\nDiagnostics – a list of diagnostics tests, where the user can modify the default settings (see figure “The panel for modification of the settings for the tests in the Basic checks section” below).\n\n\n\nv2v3\n\n\n\n\n\nThe Diagnostics section in v2\n\n\n\n\nIn v3, you can find this settings in the SA panel in the tabs TramoSeats and X13:\n\n\n\nSettings for the quality measures and tests in Tramoseats in v3\n\n\n\n\n\nSettings for the quality measures and tests in X13 in v3\n\n\n\n\n\nAn explanation of the list of the series and diagnostics components that are displayed in the Default components section can be found here.\nTo modify the settings for a particular measure, double click on a selected row (select the test’s name from the list and click on the working tools button), introduce changes in the pop-up window and click the OK button.\nTo reset the default settings for a given test, select this test from the list and click on the backspace button situated below the working tools button. The description of the parameters for each quality measure and test used in a diagnostic procedure can be found in the output from modelling and the output from seasonal adjustment nodes.\n\n\n\nThe panel for modification of the settings for the tests in the Basic checks section\n\n\nThe users can customize the diagnostics and they can specify the default settings for different outputs. Their preferences are saved between different sessions of JDemetra+. This new feature is accessible in the Statistics tab of the Options panel.\n\n\n\nThe settings of the output files\n\n\n\n\nData Transfer tab\n\nv2v3\n\n\nThe Data Transfer tab contains multiple options that define the behaviour of the drag and drop and copy-paste actions. To change the default settings, double click on the selected item. Once the modifications are introduced, confirm them with the OK button.\n\n\n\nThe content of the Data Transfer tab in v2\n\n\n\n\nIn v3, there is no equivalent of the Data Transfer tab.\n\n\n\n\n\nProcDocumentItems tab\n\nv2v3\n\n\nProcDocumentItems includes a list of all reports available for processed documents like seasonal adjustment.\n\n\n\nThe content of the ProcDocumentItems tab in v2\n\n\n\n\nIn v3, there is no equivalent of the ProcDocumentItems tab.\n\n\n\n\n\nInterchange tab\n\nv2v3\n\n\nThe Interchange tab lists the protocols that can be used to export/import information like calendars, specifications, etc. For the time being, the user cannot customize the way the standard exchanges are done. However, such features could be implemented in plug-ins.\n\n\n\nThe content of the Interchange tab in v2\n\n\n\n\nIn v3, there is no equivalent of the Interchange tab.\n\n\n\n\n\n\nGeneral panel\nThe next section, General, allows for the customisation of the proxy settings. A proxy is an intermediate server that allows an application to access the Internet. It is typically used inside a corporate network where Internet access is restricted. In JDemetra+, the proxy is used to get time series from remote servers like .Stat.\n\n\n\nThe General tab\n\n\n\n\nKeymap panel\nKeymap provides a list of default key shortcuts to access some of the functionalities and it allows the user to edit them and to define additional shortcuts.\n\nv2v3\n\n\n\n\n\nThe Keymap tab in v2\n\n\n\n\n\n\n\nThe Keymap tab in v3\n\n\n\n\n\n\n\nSA panel\nThe SA panel is only available in v3.\n\n\n\nSA panel\n\n\n\nGeneral tab\nThe General tab correspond to the Statistics tab from the Demetra panel in v2.\n\n\nTramoSeats and X13 tabs\n\n\n\nTramoseats tab\n\n\nThe TramoSeats and X13 tabs correspond to the settings for the quality measures and tests used in a diagnostic procedure in v2.\n\n\n\nOther panels\nThe Appearance and Miscellaneous panels are tabs automatically provided by the Netbeans platform. They are not used by JDemetra+."
  },
  {
    "objectID": "T-GUI-Data-Viz-TS-Tools.html#in-this-chapter",
    "href": "T-GUI-Data-Viz-TS-Tools.html#in-this-chapter",
    "title": "GUI: data visualization and time series tools",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter describes time series generic tools available in the Graphical User Interface: \n\ndata visualization\nspectral analysis tools\naggregation\ndifferencing\ntests\n\nAdditional chapters related to GUI features, provide information on:\n\nOverview\nSpecific Seasonal Adjustement and Modelling features\nOutput: series, parameters and diagnostics"
  },
  {
    "objectID": "T-GUI-Data-Viz-TS-Tools.html#data-visualization",
    "href": "T-GUI-Data-Viz-TS-Tools.html#data-visualization",
    "title": "GUI: data visualization and time series tools",
    "section": "Data visualization",
    "text": "Data visualization\nContainer includes basic tools to display the data. The following items are available: Chart, Grid, Growth Chart and List.\n\n\n\n** Container menu**\n\n\nSeveral containers can be opened at the same time. Each of them may include multiple time series.\nChart plots the time series as a graph. This function opens an empty window. To display a given series drag and drop the series from the Providers window into the empty window. More than one series can be displayed on one graph. The chart is automatically rescaled after adding a new series.\n\n\n\nLaunching the Chart functionality\n\n\nThe series to be viewed can be also dragged from the other windows (e.g. from the Variables window) or directly from the windows that display the results of the estimation procedure.\n\n\n\nDisplaying the seasonally adjusted series on a separate chart\n\n\nTo adjust the view of the chart and save it to a given location use the local menu, which is displayed after right-clicking on the chart. The explanation of the functions available for the local menu is given below.\n\n\n\nLocal menu basic options for the time series graph\n\n\nTo display the time series value at a given date, hover over it with the cursor. Once the time series is selected by clicking on it with the right mouse button, the options dedicated to this series are available.\n\n\n\nLocal menu options for chart\n\n\nA list of possible actions includes:\n\nOpen – opens selected time series in a new window that contains Chart and Grid panels.\nOpen with – opens the time series in a separate window according to the user choice (Chart & grid or Simple chart). The All ts views option is not currently available.\nSave – saves the marked series in a spreadsheet file or in a text file.\nRename – enables the user to change the time series name.\nFreeze – disables modifications of the chart.\nCopy – copies the series and allows it to be pasted to another application e.g. into Excel.\nPaste – pastes the time series previously marked.\nSplit into yearly components – opens a window that presents the analysed series data split by year. This chart is useful to investigate the differences in time series values caused by the seasonal factors as it gives some information on the existence and size of the deterministic and stochastic seasonality in data.\nRemove – removes a time series from the chart.\nSelect all – selects all the time series presented in the graph.\nShow title – option is not currently available.\nShow legend – displays the names of all the time series presented on the graph.\nEdit format – enables the user to change the data format.\nColor scheme – allows the colour scheme used in the graph to be changed.\nLines thickness – allows the user to choose between thin and thick lines to be used for a graph.\nClear – removes all the time series from the chart.\nShow all – this option is not currently available.\nExport image to – allows the graph to be sent to the printer and saved in the clipboard or as a file in a jpg format.\nConfigure – enables the user to customize the chart and series display.\n\nGrid enables the user to display the selected time series as a table. This function opens an empty window. To display a given series drag and drop the series from the Providers window into the empty window. More than one series can be displayed in one table.\n\n\n\nLaunching the Grid functionality\n\n\nTo display options available for a given time series, left click on any time series’ observation.\n\n\n\nLocal menu options for the Grid view\n\n\nThe options available in Grid are:\n\nTranspose – changes the orientation of the table from horizontal to vertical.\nReverse chronology – displays the series from the last to the first observation.\nSingle time series – removes from the table all time series apart from the selected one.\nUse color scheme – allows the series to be displayed in colour.\nShow bars – presents values in a table as horizontal bars.\nShow crosshair – highlights an active cell.\nZoom – option for modifying the chart size.\n\nWhen none of the series is selected, the local menu offers a reduced list of options. The explanation of the other options can be found below in the ‘Local menu options for chart’ figure in the Container section.\n\n\n\nA reduced list of options for Grid\n\n\nThe Growth chart tab opens an empty window. Once a given series is dropped into it, Growth chart presents the year-over-year or period-over-period growth rates for the selected time series. More than one series can be displayed in a table. The growth chart is automatically rescaled after adding a new series.\n\n\n\nThe Growth chart view with a local menu\n\n\nA left click displays a local menu with the available options. Those that are characteristic for the Growth chart are:\n\nKind – displays m/m (or q/q) and y/y growth rates for all time series in the chart (previous period and previous year options respectively). By default, the period-over-period growth rates are shown.\nEdit last year – for clarity and readability purposes, only five of the last years of observations are shown by default. This setting can be adjusted in the Options section, if required.\n\nThe explanation of other options can be found below in the ‘Local menu options for chart’ figure in the Container section.\nThe List tab provides basic information about the chosen time series, such as; the start and end date, the number of observations and a sketch of the data graph. This function opens an empty window. To display information, drag and drop the series from the Providers window into the List window. A right click displays the local menu with all available options. Apart from the standard options, the local menu for List enables marking the series that match the selected frequency (yearly, half-yearly, quarterly, monthly) by using the Select by frequency option. An explanation of other options can be found below in the ‘Local menu options for chart’ figure in the Container section.\n\n\n\nA view of a list of series\n\n\nFor a selected series a local menu offers an extended list of options. The explanation of the functions available for the local menu is given below in the ‘Local menu options for chart’ figure in the Container section.\n\n\n\nOptions available for a selected series from the list"
  },
  {
    "objectID": "T-GUI-Data-Viz-TS-Tools.html#t-GUI-tstools-spec-graphs",
    "href": "T-GUI-Data-Viz-TS-Tools.html#t-GUI-tstools-spec-graphs",
    "title": "GUI: data visualization and time series tools",
    "section": "Spectral Analysis",
    "text": "Spectral Analysis\nSpectral graphs are available from: Tools → *Spectral analysis.\n\n\n\nTools for spectral analysis\n\n\n\n\n\nTools for spectral analysis\n\n\n\nAuto-regressive spectrum\nWhen the first option is chosen JDemetra+ displays an empty Auto-regressive spectrum window. To start an analysis drag a single time series from the Providers window and drop it into the Drop data here area.\n\n\n\nLaunching an auto-regressive spectrum\n\n\nWhen displaying an Auto-regressive spectrum the number of observations, data transformations and other options such as the specification of the frequency grid and the order of the autoregressive polynomial (30 by default) can be specified by opening the Window → Properties from the main menu.\n\n\n\nAuto-regressive spectrum’s properties\n\n\nThe Auto-regressive-Properties window contains the following options:\n\nLog - log transformation of a time series;\nDifferencing-transforms a data by calculating a regular (order 1,2..) or seasonal (order 4, 12, depending on the time series frequency) differences;\nDifferencing lag-the number of lags that the program will use to take differences. For example, if Differencing lag=3 then the differencing filter does not apply to the first lag (default) but to the third lag.\nLast years-a number of years at the end of the time series taken to produce autoregressive spectrum. By default, it is 0, which means that the whole time series is considered.\nAuto-regressive polynomial order-the number of lags in the AR model that is used to estimate the spectral density. By default, the order of the autoregressive polynomial is set to 30 lags.\nResolution-the value 1 plots the spectral density estimate for the frequencies \\(\\omega_{j}=\\frac{2\\pi j}{n}\\), where \\(n \\in (-\\pi;\\pi)\\) is the size of the sample used to estimate the AR model. Increasing this value, which is set to 5 by default, will increase the precision of this grid.\n\n\n\nPeriodogram\nChoose Tools →Spectral analysis → Periodogram and drag and drop a series from the Providers window to the empty Periodogram window.\n![Launching a periodogram](All_images/image5_342.jpeg)\nThe sample size and data transformations can be specified by opening the Window → Properties, in the main menu. The Periodogram- Properties window contains the following options:\n\nLog - log transformation of a time series;\nDifferencing-transforms the data by calculating regular (order 1,2..) or seasonal (order 4, 12, depending on the time series frequency) differences;\nDifferencing lag-the number of lags that you will use to take differences. For example, if Differencing lag=3 then the differencing filter does not apply to the first lag (default) but to the third lag.\nLast years-the number of years at the end of the time series taken to produce periodogram. By default it is 0, which means that the whole time series is considered.\n\n\n\nAn example of a periodogram\n\n\n\n\n\nPeriodogram’s properties\n\n\n\n\n\nTukey spectrum\nChoose Tools → Spectral analysis → Tukey spectrum and drag and drop a single series from the Providers window to the empty Periodogram window.\n![Launching a Tukey spectrum](All_images//image8_342.jpeg)\nThe Tukey spectrum estimates the spectral density by smoothing the periodogram.\n![An example of a Tukey spectrum](All_images/image9_342.jpeg)\nOptions for the Tuckey window can be specified by opening the Window → Properties from the main menu. The Periodogram- Properties window contains the following options:\n\nLog - log transformation of a time series.\nDifferencing -transforms the data by calculating regular (order 1, 2..) or seasonal (order 4, 12, depending on the time series frequency) differences.\nDifferencing lag-the number of lags that you will use to take differences. For example, if Differencing lag=3 then the differencing filter does not apply to the first lag (default) but to the third lag.\nTaper part–parameter larger than 0 and smaller or equal to one that shapes the curvature of the smoothing function that is applied to the auto-covariance function.\nWindow length–the size of the window that is used to smooth the auto-covariance function. A value of zero includes the whole series.\nWindow type–it refers to the weighting scheme that it is used to smooth the auto-covariance function. The available windows types (Square, Welch, Tukey, Barlett, Hamming, Parzen) are suitable to estimate the spectral density.\n\n\n\n\nTukey spectrum’s properties"
  },
  {
    "objectID": "T-GUI-Data-Viz-TS-Tools.html#aggregation",
    "href": "T-GUI-Data-Viz-TS-Tools.html#aggregation",
    "title": "GUI: data visualization and time series tools",
    "section": "Aggregation",
    "text": "Aggregation\nAggregation calculates the sum of the selected series and provides basic information about the selected time series, including the start and end date, the number of observations and a sketch of the data graph, in the same way as in the List functionality. Aggregation opens an empty window. To sum the selected series, drag and drop them from the Providers window into the Aggregation window. Right click displays the local menu with the available options. The content of the local menu depends on the panel chosen (the panel on the left that contains the list of the series and the panel on the right that presents the graph of an aggregate). The local menu for the list of series offers the option Select by frequency, which marks all the series on the list that are yearly, half-yearly, quarterly or monthly (depending on the user’s choice). The explanation of the other options can be found below in the ‘Local menu options for chart’ figure in the Container section. The local menu for the panel on the left offers functionalities that are analogous to the ones that are available for the List functionalities, while the options available for the local menu in the panel on the left are the same as the ones available in Chart (see Container).\n\n\n\nThe Aggregation tool"
  },
  {
    "objectID": "T-GUI-Data-Viz-TS-Tools.html#differencing",
    "href": "T-GUI-Data-Viz-TS-Tools.html#differencing",
    "title": "GUI: data visualization and time series tools",
    "section": "Differencing",
    "text": "Differencing\nThe Differencing window displays the first regular differences for the selected time series together with the corresponding periodogram and the PACF function. By default, the window presents the results for non-seasonally and seasonally differenced series (( \\(d = 1,D = 1\\))). These settings can be changed through the Properties window (Tools → Properties). A description of a periodogram and the PACF function can be found here.\n\n\n\nThe properties of the Differencing tool\n\n\nTypical results are shown below. The bottom left graph presents the partial autocorrelation coefficients (vertical bars) and the confidence intervals. The right-click local menu offers several functionalities for a differenced series. An explanation of the available options can be found below in the “Local menu options for chart” figure in the Container section.\n\n\n\nThe *Differencing tool\n\n\nFor the Partial autocorrelation and the Periodogram panels the right-button menu offers “a copy series” option that allows data to be exported to another application and a graph to be printed and saved to a clipboard or as a .jpg file."
  },
  {
    "objectID": "T-GUI-Data-Viz-TS-Tools.html#t-GUI-tstools-tests",
    "href": "T-GUI-Data-Viz-TS-Tools.html#t-GUI-tstools-tests",
    "title": "GUI: data visualization and time series tools",
    "section": "Tests",
    "text": "Tests\nHere we describe the GUI access to and display of tests. The underlying method is detailed here\n\nSeasonality Tests\n\nQS test\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\nqs\n\n\nIt is also visible in Main results panel and in diagnostics node.\n\n\nFriedman test for stable seasonality\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\nfriedman\n\n\nIf the null hypothesis of no stable seasonality is rejected at the 1% significance level, then the series is considered to be seasonal and the outcome of the test is displayed in green.\nIt is also visible in Main results panel and in diagnostics node. (to be checked)\n\n\nIdentification of spectral peaks\n\nIn a Tukey spectrum\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\ntktest\n\n\nJDemetra+ considers critical values for \\(\\alpha=1\\%\\) (code “T”) and \\(\\alpha=5\\%\\) (code “t”) at each one of the seasonal frequencies represented in the table below, e.g. frequencies \\(\\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}\\text{and} \\frac{5\\pi}{6}\\) corresponding to 1, 2, 3, 4, 5 and 6 cycles per year in this example, since we are dealing with monthly data.\n\n\nIn AR Spectrum definition\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\nartest\n\n\nJDemetra+ considers critical values for \\(\\alpha=1\\%\\) (code “A”) and \\(\\alpha=5\\%\\) (code “a”) at each one of the seasonal frequencies represented in the table below, e.g. frequencies \\(\\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}\\text{ and } \\frac{5\\pi}{6}\\) corresponding to 1, 2, 3, 4, 5 and 6 cycles per year in this example, since we are dealing with monthly data.\n\n\nIn a Periodogram\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests.\n\n\n\nperiodtest\n\n\n\n\n\n\nTests on residuals\nUp coming content."
  },
  {
    "objectID": "T-GUI-SA-Modelling-Features.html#in-this-chapter",
    "href": "T-GUI-SA-Modelling-Features.html#in-this-chapter",
    "title": "GUI: SA and Modelling Features",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter covers specific Seasonal Adjustment and Modelling features. Modelling refers to reg-Arima or Tramo when used stand alone and not as the first (pre-adjustment) step in seasonal adjustment. Note that the menu and window structure as well as options and results are almost identical in both cases.\nAdditional chapters related to GUI features, provide information on:\n\nOverview\nData visualization and generic time series tools\nOutput: series, parameters and diagnostics\n\nCurrently, this chapter is widely incomplete, additional content will be uploaded in the coming weeks."
  },
  {
    "objectID": "T-GUI-SA-Modelling-Features.html#workspace-window",
    "href": "T-GUI-SA-Modelling-Features.html#workspace-window",
    "title": "GUI: SA and Modelling Features",
    "section": "Workspace Window",
    "text": "Workspace Window\nThe workspace window displays the characteristics of a workspace but gives also access to other peripheric routines, the results of which won’t be stored in a workspace (as data structure)\nContent of Workspace window, divided into three sections:\n\nModelling (contains the default and user-defined specifications for modelling; and the output from the modelling process)\nSeasonal adjustment (contains the default and user-defined specifications for seasonal adjustment and the output from the seasonal adjustment process),\nUtilities (calendars and user defined variables).\n\n\n\n\nThe Workspace window\n\n\n\nModelling\nWhen using reg-Arima or Tramo stand alone.\nThis section is divided into two parts:\n\nSpecifications: parameters of the modelling procedure.\nOutput\n\n ### Seasonal adjustment {#sa-window}\nThis window allows to set up and launch a seasonal adjustment process.\nThis section is divided into two parts:\n\nSpecifications, which presents parameters of the seasonal adjustment procedure.\nOutput, which explains a typical output produced by the seasonal adjustment procedure.\n\nThe specifications and output for the seasonal adjustment procedure are displayed in the Workspace window under the Seasonal adjustment item.\n\n\n\nThe Workspace window with the nodes for the seasonal adjustment procedure marked\n\n\n\n\nResults panel\nThe blank zone in the figure above (on the right of the view) is the location where JDemetra+ displays various windows. More than one window can be displayed at the same time. Windows can overlap with each other with the foremost window being the one in focus or active. The active window has a darkened title bar. The windows in the results panel can be arranged in many different ways, depending on the user’s needs. The example below shows one of the possible views of this panel. The results of the user’s analysis are displayed in an accompanying window. The picture below shows two panels – a window containing seasonal adjustment results (upper panel) and another one containing an autoregressive spectrum (lower panel).\n\n\n\nThe Results panel filled with two windows"
  },
  {
    "objectID": "T-GUI-SA-Modelling-Features.html#statistical-methods",
    "href": "T-GUI-SA-Modelling-Features.html#statistical-methods",
    "title": "GUI: SA and Modelling Features",
    "section": "Statistical Methods Menu",
    "text": "Statistical Methods Menu\n\nAnomaly Detection – allows for a purely automatic identification of regression effects;\n\n\n\n\nThe Anomaly detection tab.\n\n\n\nModelling – enables time series modelling using the TRAMO and RegARIMA models;\n\n\n\n\nThe Modelling tab.\n\n\n\nSeasonal adjustment – intended for the seasonal adjustment of a time series with the TRAMO-SEATS and X-13ARIMA-SEATS methods.\n\n - Tools – provides access to seasonality tests, described here and to Direct-Indirect Seasonal adjustment tools (up coming content)"
  },
  {
    "objectID": "T-GUI-Output.html#in-this-chapter",
    "href": "T-GUI-Output.html#in-this-chapter",
    "title": "GUI: Generating output",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter describes how to generate (export) output (series, parameters, diagnostics) directly from the Graphical User interface: \nWe will cover:\n\nSeasonal Adjustment (SA-Processing)\nModelling (up coming content)\nBenchmarking (up coming content)\n\nWhen running a SA-processing in GUI, series, parameters, diagnostics can be also generated without opening it, using a production module called the cruncher.\nAdditional chapters related to GUI features, provide information on:\n\nOverview\nData visualization and generic time series tools\nSpecific Seasonal Adjustement and Modelling features"
  },
  {
    "objectID": "T-GUI-Output.html#output-from-sa-processing",
    "href": "T-GUI-Output.html#output-from-sa-processing",
    "title": "GUI: Generating output",
    "section": "Output from SA Processing",
    "text": "Output from SA Processing\n\nSteps\n\nOnce a seasonal adjustment process for the dataset is performed Go to the TOP menu bar and follow the path: SAProcessing → Output…\nIn the Batch output window the user can specify which output items will be saved and the folder in which JDemetra+ saves the results. It is possible to save the results in the TXT, XLS, CSV, and CSV matrix formats. In the first step the user should choose the output format from the list.\n\nThe user may choose more than one format as the output can be generated in different formats at the same time.\n\nTo display and modify the settings click on the given output format on the list. The available options depend on the output format.\nFor Csv format the following options are available: folder (location of the file), file prefix (name of the file), presentation (controls how the output is divided into separate files) and series (series included in the file). These options are presented in the next points of this case study.\n\nThe user can define the folder in which the selected results and components will be saved (click the folder item and choose the final destination).\n\nWith the option File Prefix the user can modify the default name of the output saved in the CSV file.\n\nLayout controls how the output is divided into separate files. Expand the list to display available options:\n\nHTable – the output series will be presented in the form of horizontal tables (time series in rows).\nVTable – the output series will be presented in the form of vertical tables (time series in columns).\nList – the output series will be presented in the form of vertical tables (time series in rows). Apart from that, for each time series each file contains in separate columns: the data frequency, the first year and of estimation span, the first period (month or quarter) of observation span and the number of observations. The files do not include dates.\n\n\nThe Content section presents a list of series that will be included into a set of output files. To modify the initial settings click on the grey button in the Content section. The CVS-series window presents two panels: the panel on the left includes a list of all valuable output items. The panel on the right presents the selected output items. Mark the series and use the arrows to change the settings. Confirm your choice with the OK button.\n\nOptions available for the XLS format are the same as for the TXT format with an exception of the Layout section.\n\nBySeries – all results for a given time series are placed in one sheet;\nByComponent – results are grouped by components. Each component type is saved in a separate sheet.\nOneSheet – all results are saved in one sheet.\n\n\nIf the user sets the option layout to ByComponent, the output will be generated as follows:\n\nThe option OneSheet will produce the following XLS file:\n\nBy default, the series in the Excel output files are organised vertically. When the user unmarks the check box the horizontal orientation is used.\n\nIn the case of the TXT format the only available options are folder (location of the file) and series (results included in the output file).\n\nThe CSV matrix produces the CSV file containing information about the model and quality diagnostics of the seasonal adjustment. The user may generate the list of default items or create their own quality report. By default, all the available items are included in the output.\n\nOnce the output settings are selected, click the OK button.\n\nFor each output JDemetra+ provides information on the status of the operation. An example is presented below."
  },
  {
    "objectID": "T-r-packages.html#in-this-chapter",
    "href": "T-r-packages.html#in-this-chapter",
    "title": "Using JDemetra+ in R",
    "section": "In this chapter",
    "text": "In this chapter\nCore JDemetra+ Java algorithms can be accessed in R.This chapter provides an overview of the R ecosystem related to JDemetra+ version 2.x and 3.x (under construction). More details on specific functions are available in the relevant chapters in the Algorithms part of this documentation. Help pages (and vignettes) relative to each package provide a detailed description of all available functions, stating purpose, arguments, output and examples. Whenever possible there are directly linked in this documentation when their use in a selected algorithm is mentioned.\n\nPackages based on JDemetra+ version 2 algorithms\nPackages corresponding to version 2.x core routines:\n\nRJDemetra on CRAN or https://github.com/jdemetra/rjdemetra\nrjdworkspace on https://github.com/InseeFrLab/rjdworkspace\nJDCruncheR on https://github.com/InseeFr/JDCruncheR\nggdemetra on https://github.com/AQLT/ggdemetra\nrjdqa on https://github.com/AQLT/rjdqa\n\n\n\nPackages based on JDemetra+ version 3 algorithms\nPackages corresponding to version 3.x core routines:\n\nrjd3toolkit at https://github.com/rjdemetra/rjd3toolkit\nrjd3x13 on https://github.com/rjdemetra/rjd3x13\nrjd3tramoseats at https://github.com/rjdemetra/rjd3tramoseats\nrjdemetra3 at https://github.com/rjdemetra/rjdemetra3\nrjd3highfreq at https://github.com/rjdemetra/rjd3highfreq\nrjd3x11plus at https://github.com/rjdemetra/rjd3x11plus\nrjd3bench at https://github.com/rjdemetra/rjd3bench\nrjd3revsions at https://github.com/rjdemetra/rjd3revisions\nrjd3sts at https://github.com/rjdemetra/rjd3sts\nrjd3stl at https://github.com/rjdemetra/rjd3stl\nrjd3filters at https://github.com/rjdemetra/rjd3filters\nggdemetra3 on https://github.com/AQLT/ggdemetra3"
  },
  {
    "objectID": "T-r-packages.html#algorithms-available-in-r",
    "href": "T-r-packages.html#algorithms-available-in-r",
    "title": "Using JDemetra+ in R",
    "section": "Algorithms available in R",
    "text": "Algorithms available in R\n\nSeasonal adjustment\n\nUsing JDemetra+ version 2.x\n\n\n\n\n\n\n\n\nAlgorithm\nPackage\nComments\n\n\n\n\nX13-ARIMA\nRJDemetra\nReg-Arima and X-11 decomposition available independently\n\n\nTRAMO-SEATS\nRJDemetra\nTramo available independently\n\n\n\n\n\nUsing JDemetra+ version 3.x\n\n\n\n\n\n\n\n\nAlgorithm\nPackage\nComments\n\n\n\n\nX13-ARIMA\nrjd3x13\nReg-Arima and X-11 decomposition available independently\n\n\nExtended X-11\nrjd3x11plus\nFor high-frequency (infra-monthly) data\n\n\nTRAMO-SEATS\nrjd3tramoseats\nTramo available independently\n\n\nExtended Tramo\nrjd3highfreq\nFor high-frequency data\n\n\nExtended Seats\nrjd3highfreq\nFor high-frequency data\n\n\nSTL\nrjd3stl\nIncluding high-frequency data\n\n\nBasic Structural Models\nrjd3sts\nState space framework\n\n\n\nVersion 3.x includes Revision Policies in X-13 and Tramo-Seats.\nMore details on functions parameters and retrieving output in the chapter dedicated to Seasonal Adjustment\n\n\n\nFiltering and Trend estimation\n\n\n\nAlgorithm\nPackage\n\n\n\n\nMoving average functions\nrjd3filters\n\n\nLocal Polynomial Trend Estimation\nrjd3filters, rjd3x11plus\n\n\n\n\n\nBenchmarking and Temporal disaggregation\n\n\n\nAlgorithm\nPackage\n\n\n\n\nDenton\nrjd3bench\n\n\nCholette\nrjd3bench\n\n\nCubic splines\nrjd3bench\n\n\nTemporal Disaggregation\nrjd3bench"
  },
  {
    "objectID": "T-r-packages.html#utility-functions-available-in-r",
    "href": "T-r-packages.html#utility-functions-available-in-r",
    "title": "Using JDemetra+ in R",
    "section": "Utility functions available in R",
    "text": "Utility functions available in R\nThe packages listed below contain utility functions useful when running a production process with massive datasets.\n\nRunning the cruncher and generating a quality report\nJDemetra+ cruncher is an executable module designed for mass production of seasonally adjusted series .\n\n\n\nPackage\nJD+ version\nComments\n\n\n\n\nrjwsacruncher\n2.x\nestimation update and output\n\n\nJDCruncheR\n2.x\nall the above + Quality Report\n\n\n\n\n\nWrangling JD+ workspaces\nA workspace is a specific JDemetra+ data format (xml files) allowing to use the graphical user interface (GUI) and the cruncher.\n\n\n\nPackage\nJD+ version\nComments\n\n\n\n\nrjdworkspace\n2.x\nupdate meta data, merge workspaces\n\n\nrjdemetra3\n3.x\nidem but under construction\n\n\n\n\n\nGenerating enhanced output in SA estimation\nThis additional packages produce enhanced plots and diagnostic outputs.\n\n\n\nPackage\nJD+ version\nComments\n\n\n\n\nrjdmarkdown\n2.x\nenhanced print of diagnostics\n\n\nggdemetra\n3.x\nplots based on ggplot\n\n\nggdemetra3\n3.x\nplots based on ggplot\n\n\nrjdqa\n2.x\nvisual dashboard on one series"
  },
  {
    "objectID": "T-r-packages.html#t-r-packs-tstools",
    "href": "T-r-packages.html#t-r-packs-tstools",
    "title": "Using JDemetra+ in R",
    "section": "Time series tools",
    "text": "Time series tools\n\nTests\n\nSeasonality tests\n\n\nTests on residuals"
  },
  {
    "objectID": "T-r-packages.html#general-structure",
    "href": "T-r-packages.html#general-structure",
    "title": "Using JDemetra+ in R",
    "section": "General structure",
    "text": "General structure\nThe R object resulting from an estimation is a list of lists containing raw data, parameters, output series and diagnostics.\n\nOutput structure for RJDemetra package\nOrganised by domain:\n\n\n\nV2 SA structure\n\n\nTo retrieve any element just navigate this list of lists.\n\n\nOutput structure for rjd3x13 package\nResults and specification are separated first and then organised by domain.\n\nsa_x13_v3 &lt;- RJDemetra::x13(y_raw, spec = \"RSA5\")\nsa_x13_v3$result\nsa_x13_v3$estimation_spec\nsa_x13_v3$result_spec\nsa_x13_v3$user_defined\n\nTo retrieve any element just navigate this list of lists."
  },
  {
    "objectID": "T-r-packages.html#installation-procedure",
    "href": "T-r-packages.html#installation-procedure",
    "title": "Using JDemetra+ in R",
    "section": "Installation procedure",
    "text": "Installation procedure\n\nversion 2\n\ninstall.packages(\"RJDemetra\")\nremotes::install_github(\"InseeFrLab/rjdworkspace\")\nremotes::install_github(\"InseeFr/JDCruncheR\")\n\n\n\nversion 3\n\n# install.packages(\"remotes\")\n# install.packages(\"devtools\")\nremotes::install_github(\"rjdemetra/rjd3toolkit\")\nremotes::install_github(\"rjdemetra/rjd3x13\")\nremotes::install_github(\"rjdemetra/rjd3tramoseats\")\nremotes::install_github(\"rjdemetra/rjdemetra3\")\nremotes::install_github(\"rjdemetra/rjd3filters\")\nremotes::install_github(\"rjdemetra/rjd3sts\")\nremotes::install_github(\"rjdemetra/rjd3highfreq\")\nremotes::install_github(\"rjdemetra/rjd3x11plus\")\nremotes::install_github(\"rjdemetra/rjd3stl\")\nremotes::install_github(\"rjdemetra/rjd3bench\")\nremotes::install_github(\"rjdemetra/rjd3revisions\")\nremotes::install_github(\"AQLT/ggdemetra3\")"
  },
  {
    "objectID": "T-r-packages.html#rjd3-suite-of-packages-overview",
    "href": "T-r-packages.html#rjd3-suite-of-packages-overview",
    "title": "Using JDemetra+ in R",
    "section": "rjd3 suite of packages: overview",
    "text": "rjd3 suite of packages: overview\nThe sections below provide an overview of each package based on version 3.x of JDemetra+. For detailed description refer to the package’s own R documentation pages and vignettes.\n\nrjd3toolkit\nContains utility functions used in other rjd3 packages and has to be systematically installed before using any other rjd3 package. From a user point of view, it allows to:\n\ncustomize specifications in X13-ARIMA and TRAMO-SEATS\ngenerate user-defined regressors for calendar correction\ngenerate auxiliary variables (outliers, ramps..)\nrun arima model estimations\nperform tests\naccess general functions such as autocorrelations, distributions…\n\nMore details for each part can be found in `rjd3toolkit``R help pages and related vignettes.\n\n\nrjd3x13\nrjd3x13 gives access to X13-ARIMA seasonal adjustment algorithm.\n\nSpecification: created with spec_x11_default(), spec_x13_default(), spec_regarima_default() and customized with rjd3toolkit functions + set_x11()\nApply model with x11(), x13(), fast.x13(), regarima(), fast.regarima()\nRefresh policies: regarima.refresh() and x13.refresh()\n\n\n\nrjd3tramoseats\nrjd3tramoseats gives access to TRAMO-SEATS seasonal adjustment algorithm.\n\nSpecification: created with spec_tramoseats_default(), spec_tramo_default() and customized with rjd3toolkit functions + set_seats()\nApply model with tramoseats(), fast.tramoseats(), tramo(), fast.tramo()\nRefresh policies: tramo.refresh() and tramoseats.refresh()\n\n\n\nrjd3highfreq\nSeasonal adjustment of high frequency (infra-monthly) data:\n\nfractional airline based reg-Arima pre-adjustment\nfractional and multi airline decomposition\n\n\n\nrjd3x11plus\n\nExtension of X-11 decomposition with multiple non integer periodicities.\n\n\n\nrjd3sts\nGives access to structural time series and state space models, has to be installed to use rjd3highfreq. Handles high-frequency data.\nSeveral examples available here\n\n\nrjd3stl\nrjd3stl contains usual STL functions but is also tailored to handle high-frequency data.\n\n\nggdemetra3\nggdemetra3 uses ggplot2 to add seasonal adjustment statistics to your plot (Like ggdemetra but compatible with version 3.x.). Also compatible with high-frequency methods:\n\nlibrary(\"ggdemetra3\")\n\nspec &lt;- spec_x13_default(\"rsa3\") |&gt; set_tradingdays(option = \"WorkingDays\")\np_ipi_fr &lt;- ggplot(data = ipi_c_eu_df, mapping = aes(x = date, y = FR)) +\n    geom_line() +\n    labs(\n        title = \"SA - IPI-FR\",\n        x = NULL, y = NULL\n    )\np_sa &lt;- p_ipi_fr +\n    geom_sa(\n        component = \"y_f(12)\", linetype = 2,\n        spec = spec\n    ) +\n    geom_sa(component = \"sa\", color = \"red\") +\n    geom_sa(component = \"sa_f\", color = \"red\", linetype = 2)\np_sa\np_sa +\n    geom_outlier(\n        geom = \"label_repel\",\n        coefficients = TRUE,\n        ylim = c(NA, 65), force = 10,\n        arrow = arrow(\n            length = unit(0.03, \"npc\"),\n            type = \"closed\", ends = \"last\"\n        ),\n        digits = 2\n    )\n\n\n\nrjd3filters\nThe rjd3filters package allows to:\n\neasily create/combine/apply moving averages moving_average() (much more general than stats::filter()) and study their properties: plot coefficients (plot_coef()), gain (plot_gain()), phase-shift (plot_phase()) and different statics (diagnostic_matrix())\ntrend-cycle extraction with different methods to treat endpoints:\nlp_filter() local polynomial filters of Proietti and Luati (2008) (including Musgrave): Henderson, Uniform, biweight, Trapezoidal, Triweight, Tricube, “Gaussian”, Triangular, Parabolic (= Epanechnikov)\n\nrkhs_filter() Reproducing Kernel Hilbert Space (RKHS) of Dagum and Bianconcini (2008) with same kernels\n\nfst_filter() FST approach of Grun-Rehomme, Guggemos, and Ladiray (2018)\n\ndfa_filter() derivation of AST approach of Wildi and McElroy (2019)\nchange the filter used in X-11 for TC extraction\n\n\nCreate moving averages\n\nlibrary(\"rjd3filters\")\n\nm1 &lt;- moving_average(rep(1, 3), lags = 1)\nm1 # Forward MA\nm2 &lt;- moving_average(rep(1, 3), lags = -1)\nm2 # centred MA\n\nm1 + m2\nm1 - m2\nm1 * m2\n\nCan be used to create all the MA of X-11:\n\ne1 &lt;- moving_average(rep(1, 12), lags = -6)\ne1 &lt;- e1 / sum(e1)\ne2 &lt;- moving_average(rep(1 / 12, 12), lags = -5)\n\n# used to have the 1rst estimate of the trend\ntc_1 &lt;- M2X12 &lt;- (e1 + e2) / 2\ncoef(M2X12) |&gt; round(3)\nsi_1 &lt;- 1 - tc_1\nM3 &lt;- moving_average(rep(1 / 3, 3), lags = -1)\nM3X3 &lt;- M3 * M3\n\n# M3X3 moving average applied to each month\ncoef(M3X3) |&gt; round(3)\nM3X3_seasonal &lt;- to_seasonal(M3X3, 12)\ncoef(M3X3_seasonal) |&gt; round(3)\ns_1 &lt;- M3X3_seasonal * si_1\ns_1_norm &lt;- (1 - M2X12) * s_1\nsa_1 &lt;- 1 - s_1_norm\nhenderson_mm &lt;- moving_average(lp_filter(horizon = 6)$filters.coef[, \"q=6\"],\n    lags = -6\n)\ntc_2 &lt;- henderson_mm * sa_1\nsi_2 &lt;- 1 - tc_2\nM5 &lt;- moving_average(rep(1 / 5, 5), lags = -2)\nM5X5_seasonal &lt;- to_seasonal(M5 * M5, 12)\ns_2 &lt;- M5X5_seasonal * si_2\ns_2_norm &lt;- (1 - M2X12) * s_2\nsa_2 &lt;- 1 - s_2_norm\ntc_f &lt;- henderson_mm * sa_2\n\n\npar(mai = c(0.3, 0.3, 0.2, 0))\nlayout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE))\n\nplot_coef(tc_f)\nplot_coef(sa_2, col = \"orange\", add = TRUE)\nlegend(\"topleft\",\n    legend = c(\"Final TC filter\", \"Final SA filter\"),\n    col = c(\"black\", \"orange\"), lty = 1\n)\n\nplot_gain(tc_f)\nplot_gain(sa_2, col = \"orange\", add = TRUE)\n\nplot_phase(tc_f)\nplot_phase(sa_2, col = \"orange\", add = TRUE)\n\n\n\nApply a moving average\n\ny &lt;- retailsa$AllOtherGenMerchandiseStores\ntrend &lt;- y * tc_1\nsa &lt;- y * sa_1\nplot(window(ts.union(y, trend, sa), start = 2000),\n    plot.type = \"single\",\n    col = c(\"black\", \"orange\", \"lightblue\")\n)\n\n\n\n\nrjd3bench\nTailored for Benchmarking and temporal disaggregation\nSeveral examples here\n\n\nrjd3revisions\nRevision analysis, more info here\n\n\nrjdemetra 3\nThis package allows to wrangle JDemetra+ workspaces in R with functions:\n\nload_workspace\nsave_workspace\n\nUp coming content."
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#in-this-chapter",
    "href": "T-Production-tools-cruncher-QR.html#in-this-chapter",
    "title": "Production, Cruncher and quality report",
    "section": "In this chapter",
    "text": "In this chapter\nThe sections below describe how to\n\nautomate the Seasonal adjustment estimation process\nupdate a workspace when new data is available\nexport output (series, diagnostics, parameters)\ngenerate a quality report usable for selective editing (manual fine tuning)"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#automate-estimation-with-the-cruncher",
    "href": "T-Production-tools-cruncher-QR.html#automate-estimation-with-the-cruncher",
    "title": "Production, Cruncher and quality report",
    "section": "Automate estimation with the cruncher",
    "text": "Automate estimation with the cruncher\nThe cruncher is an additional “executable” module. It can be launched via R or SAS for example.\nObjectives of the cruncher:\n\nupdate a JDemetra+ workspace (with a selected revision policy)\nexport the results (series and diagnostics),\n\nwithout having to open the graphical interface and operate manually. Suitable for a production process.\n\nInstallation procedure\n\nDownload the cruncher\n\nAvailable here https://github.com/jdemetra/jwsacruncher/releases\nClick on the zip code line of the latest release\n\nUnzip locally (or on server)\n\n\n\nHelp pages\nDocumentation is available here or click on the wiki icon on the Github page https://github.com/jdemetra/jwsacruncher/wiki\n\n\nRunning the cruncher in R\nTwo R packages are currently available\n\nrjwsacruncher on CRAN: workspace update and output production\nCruncher (https://github.com/InseeFr/JDCruncheR): same functions as rjwsacruncher but adds a quality report\n\n\nInstallation\n\nrjwsacruncher\n\n\ninstall.packages(rjwsacruncher)\n\n\nJDCruncheR package: download the .zip or .tar.gz file from https://github.com/InseeFr/JDCruncheR/releases.\n\nAdditional packages needed\n\ninstall.packages(c(\"XLConnect\", \"XML\"))\n\n\n\nLoading\n\nlibrary(\"JDCruncheR\")\n\nor\n\nlibrary(\"rjwsacruncher\")\n\n\n\nConnecting the cruncher module\nTo connect the cruncher to the R package, the path to the bin directory containing the cruncher.bat file must be specified. This directory is available once the zip file has been unzipped.\n\noptions(\n    cruncher_bin_directory =\n        \"C:/Software/jwsacruncher-2.2.3/jdemetra-cli-2.2.3/bin\"\n)\n\n\nchecking the current value\n\n\ngetOption(\"cruncher_bin_directory\")\n\n\n\n\nUpdating a workspace\nThe functions described in this section are identical for both packages.\n\nRunning estimations\nThe general context: two use cases\n\nRun first estimation of seasonally adjusted series (from raw series and parameters contained in the workspace)\n\n\ncruncher_and_param(\n    workspace = \"D:/my_folder/my_ws.xml\",\n    rename_multi_documents = FALSE,\n    policy = \"complete\", # name of the revision policy\n    log = my_log_file.txt\n)\n\n\nApply a revision policy to updated raw series\n\nThe function cruncher_and_param() allows to do that\n\ncruncher_and_param(\n    workspace = \"D:/my_folder/my_ws.xml\",\n    rename_multi_documents = FALSE,\n    policy = \"lastoutliers\", # name of the revision policy\n    log = my_log_file.txt\n)\n\nTo use the documentation, compute help() or ?function:\n\n?cruncher_and_param\nhelp(cruncher_and_param)\n\nBefore running SA estimations, set the export options.\n\n\n\nConfiguring output options\nAfter updating the workspace with the selected revision policies, the cruncher generates output - series (csv files) - diagnostics and parameters (demetra_m.csv file)\nThese files will be created in the workspace’s repository, sub-repository ’Output”\n\npath &lt;- \"My_Workspace/Output/SAProcessing\"\n\n\nSelecting time series to export\n\n# returns names of the currently exported series\ngetOption(\"default_tsmatrix_series\")\n# example of setting this option\noptions(default_tsmatrix_series = c(\"sa\", \"sa_f\"))\n# only seasonally adjsuted series (\"sa\") and its forecasts (\"sa_f\") will be exported\n\n\n\nSelecting diagnostics and parameters to exoprt\n\n# returns names of the currently exported diagnostics and parameters\ngetOption(\"default_matrix_item\")\n# example of setting this option\noptions(default_matrix_item = c(\n    \"likelihood.aic\",\n    \"likelihood.aicc\",\n    \"likelihood.bic\",\n    \"likelihood.bicc\"\n))"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#quality-report-with-jdcruncher",
    "href": "T-Production-tools-cruncher-QR.html#quality-report-with-jdcruncher",
    "title": "Production, Cruncher and quality report",
    "section": "Quality report with JDCruncheR",
    "text": "Quality report with JDCruncheR\nThe JDCruncheR package also:\n\ncomputes a quality score\ncreates a quality report from the diagnostics produced by JDemetra+\n\n\nMain steps\nThe three main functions of the package are:\n\nextract_QR to extract the quality report from the csv file (demetra_m.csv) that contains all JD+ diagnostics;\ncompute_score to compute a weighted score based on the diagnostics\nexport_xlsx to export the quality report.\n\n\n# choose the demetra_m.csv file generated by the cruncher\nQR &lt;- extract_QR()\nQR\n\n?compute_score # to see how the score is calculated (formula)\nQR &lt;- compute_score(QR,\n    n_contrib_score = 3\n)\n\nQR\n\nQR &lt;- sort(QR, decreasing = TRUE, sort_variables = \"score\")\nexport_xlsx(QR,\n    file_name = \"U:/quality_report.xls\"\n)\n\n\n\nPiling up results\nWhen working with several workspaces or Seasonal adjustment processings (SAP) within a given workspace, quality reports can be piled up with the function rbind() or by creating a mQR_matrix object with the function mQR_matrix()\n\nQR1 &lt;- extract_QR()\nQR2 &lt;- extract_QR()\nmQR &lt;- mQR_matrix(QR1, QR2)\nmQR\n# naming each object\nnames(mQR) &lt;- c(\"report_1\", \"report_2\")\n# Equivalent to:\nmQR &lt;- mQR_matrix(report_1 = QR1, report_2 = QR2)\nmQR\n\n# score calculation for all reports\nmQR &lt;- compute_score(mQR,\n    n_contrib_score = 3\n)\nexport_xlsx(mQR,\n    export_dir = \"U:/\"\n)\n\n\n\nConditionnal score\nMissing values can be ignored and conditions can be set for indicators:\n\n# oos_mse weight reduced to 1 when the other\n# indicators are \"Bad\" ou \"Severe\"\ncondition1 &lt;- list(\n    indicator = \"oos_mse\",\n    conditions = c(\n        \"residuals_independency\",\n        \"residuals_homoskedasticity\",\n        \"residuals_normality\"\n    ),\n    conditions_modalities = c(\"Bad\", \"Severe\")\n)\nBQ &lt;- compute_score(BQ,\n    n_contrib_score = 5,\n    conditional_indicator = list(condition1),\n    na.rm = TRUE\n)\n\n\n\nCustomize the score computation\nPractical steps if you want to customize the score computation (see package documentation in R)\n\nselect your indicators of interest\nadjust “good”, “bad”…threshold in JD+ GUI if necessary\nby default good=0, uncertain=1, bad or severe=3\nchange this grading system and/or the weights directly in the package functions\nrebuild your package"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#list-of-exportable-series",
    "href": "T-Production-tools-cruncher-QR.html#list-of-exportable-series",
    "title": "Production, Cruncher and quality report",
    "section": "List of exportable series",
    "text": "List of exportable series\nSome available output series will be different when using X13-ARIMA or TRAMO-SEATS."
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#list-of-exportable-diagnostics-and-parameters",
    "href": "T-Production-tools-cruncher-QR.html#list-of-exportable-diagnostics-and-parameters",
    "title": "Production, Cruncher and quality report",
    "section": "List of exportable diagnostics and parameters",
    "text": "List of exportable diagnostics and parameters\nSome parameters and available diagnostics will be different when using X13-ARIMA or TRAMO-SEATS.\n\noptions(\n    default_matrix_item =\n        c(\n            \"period\", \"span.start\", \"span.end\", \"span.n\", \"span.missing\",\n            \"espan.start\", \"espan.end\", \"espan.n\", \"log\", \"adjust\", \"regression.lp\",\n            \"regression.ntd\", \"regression.nmh\", \"regression.td-derived\",\n            \"regression.td-ftest\", \"regression.easter\", \"regression.nout\",\n            \"regression.noutao\", \"regression.noutls\", \"regression.nouttc\",\n            \"regression.noutso\", \"regression.td(*):4\", \"regression.out(*)\",\n            \"regression.user(*)\", \"likelihood.neffectiveobs\", \"likelihood.np\",\n            \"likelihood.logvalue\", \"likelihood.adjustedlogvalue\", \"likelihood.ssqerr\",\n            \"likelihood.aic\", \"likelihood.aicc\", \"likelihood.bic\", \"likelihood.bicc\",\n            \"residuals.ser\", \"residuals.ser-ml\", \"residuals.mean\", \"residuals.skewness:3\",\n            \"residuals.kurtosis:3\", \"residuals.dh\", \"residuals.lb\", \"residuals.lb2:3\",\n            \"residuals.seaslb\", \"residuals.bp\", \"residuals.bp2\", \"residuals.seasbp\",\n            \"residuals.nudruns\", \"residuals.ludruns\", \"residuals.nruns\",\n            \"residuals.lruns\", \"arima\", \"arima.mean\", \"arima.p\", \"arima.d\",\n            \"arima.q\", \"arima.bp\", \"arima.bd\", \"arima.bq\", \"arima.phi(*)\",\n            \"arima.bphi(*)\", \"arima.th(*)\", \"arima.bth(*)\", \"decomposition.seasonality\",\n            \"decomposition.parameters_cutoff\", \"decomposition.model_changed\",\n            \"decomposition.tvar-estimator\", \"decomposition.tvar-estimate\",\n            \"decomposition.tvar-pvalue\", \"decomposition.savar-estimator\",\n            \"decomposition.savar-estimate\", \"decomposition.savar-pvalue\",\n            \"decomposition.svar-estimator\", \"decomposition.svar-estimate\",\n            \"decomposition.svar-pvalue\", \"decomposition.ivar-estimator\",\n            \"decomposition.ivar-estimate\", \"decomposition.ivar-pvalue\", \"decomposition.tscorr-estimator\",\n            \"decomposition.tscorr-estimate\", \"decomposition.tscorr-pvalue\",\n            \"decomposition.ticorr-estimator\", \"decomposition.ticorr-estimate\",\n            \"decomposition.ticorr-pvalue\", \"decomposition.sicorr-estimator\",\n            \"decomposition.sicorr-estimate\", \"decomposition.sicorr-pvalue\",\n            \"decomposition.ar_root(*)\", \"decomposition.ma_root(*)\", \"method\",\n            \"variancedecomposition.cycle\", \"variancedecomposition.seasonality\",\n            \"variancedecomposition.irregular\", \"variancedecomposition.tdh\",\n            \"variancedecomposition.others\", \"variancedecomposition.total\",\n            \"diagnostics.logstat\", \"diagnostics.levelstat\", \"diagnostics.fcast-insample-mean\",\n            \"diagnostics.fcast-outsample-mean\", \"diagnostics.fcast-outsample-variance\",\n            \"diagnostics.seas-lin-f\", \"diagnostics.seas-lin-qs\", \"diagnostics.seas-lin-kw\",\n            \"diagnostics.seas-lin-friedman\", \"diagnostics.seas-lin-periodogram\",\n            \"diagnostics.seas-lin-spectralpeaks\", \"diagnostics.seas-si-combined\",\n            \"diagnostics.seas-si-evolutive\", \"diagnostics.seas-si-stable\",\n            \"diagnostics.seas-res-f\", \"diagnostics.seas-res-qs\", \"diagnostics.seas-res-kw\",\n            \"diagnostics.seas-res-friedman\", \"diagnostics.seas-res-periodogram\",\n            \"diagnostics.seas-res-spectralpeaks\", \"diagnostics.seas-res-combined\",\n            \"diagnostics.seas-res-combined3\", \"diagnostics.seas-res-evolutive\",\n            \"diagnostics.seas-res-stable\", \"diagnostics.seas-i-f\", \"diagnostics.seas-i-qs\",\n            \"diagnostics.seas-i-kw\", \"diagnostics.seas-i-periodogram\", \"diagnostics.seas-i-spectralpeaks\",\n            \"diagnostics.seas-i-combined\", \"diagnostics.seas-i-combined3\",\n            \"diagnostics.seas-i-evolutive\", \"diagnostics.seas-i-stable\",\n            \"diagnostics.seas-sa-f\", \"diagnostics.seas-sa-qs\", \"diagnostics.seas-sa-kw\",\n            \"diagnostics.seas-sa-friedman\", \"diagnostics.seas-sa-periodogram\",\n            \"diagnostics.seas-sa-spectralpeaks\", \"diagnostics.seas-sa-combined\",\n            \"diagnostics.seas-sa-combined3\", \"diagnostics.seas-sa-evolutive\",\n            \"diagnostics.seas-sa-stable\", \"diagnostics.seas-sa-ac1\", \"diagnostics.td-sa-all\",\n            \"diagnostics.td-sa-last\", \"diagnostics.td-i-all\", \"diagnostics.td-i-last\",\n            \"diagnostics.td-res-all\", \"diagnostics.td-res-last\", \"diagnostics.ic-ratio-henderson\",\n            \"diagnostics.ic-ratio\", \"diagnostics.msr-global\", \"diagnostics.msr(*)\",\n            \"decomposition.trendfilter\", \"decomposition.seasfilter\", \"m-statistics.m1\",\n            \"m-statistics.m2\", \"m-statistics.m3\", \"m-statistics.m4\", \"m-statistics.m5\",\n            \"m-statistics.m6\", \"m-statistics.m7\", \"m-statistics.m8\", \"m-statistics.m9\",\n            \"m-statistics.m10\", \"m-statistics.m11\", \"m-statistics.q\", \"m-statistics.q-m2\",\n            \"diagnostics.basic checks.definition:2\", \"diagnostics.basic checks.annual totals:2\",\n            \"diagnostics.visual spectral analysis.spectral seas peaks\", \"diagnostics.visual spectral analysis.spectral td peaks\",\n            \"diagnostics.regarima residuals.normality:2\", \"diagnostics.regarima residuals.independence:2\",\n            \"diagnostics.regarima residuals.spectral td peaks:2\", \"diagnostics.regarima residuals.spectral seas peaks:2\",\n            \"diagnostics.outliers.number of outliers:2\", \"diagnostics.out-of-sample.mean:2\",\n            \"diagnostics.out-of-sample.mse:2\", \"diagnostics.m-statistics.q:2\",\n            \"diagnostics.m-statistics.q-m2:2\", \"diagnostics.seats.seas variance:2\",\n            \"diagnostics.seats.irregular variance:2\", \"diagnostics.seats.seas/irr cross-correlation:2\",\n            \"diagnostics.residual seasonality tests.qs test on sa:2\", \"diagnostics.residual seasonality tests.qs test on i:2\",\n            \"diagnostics.residual seasonality tests.f-test on sa (seasonal dummies):2\",\n            \"diagnostics.residual seasonality tests.f-test on i (seasonal dummies):2\",\n            \"diagnostics.combined seasonality test.combined seasonality test on sa:2\",\n            \"diagnostics.combined seasonality test.combined seasonality test on sa (last 3 years):2\",\n            \"diagnostics.combined seasonality test.combined seasonality test on irregular:2\",\n            \"diagnostics.residual trading days tests.f-test on sa (td):2\",\n            \"diagnostics.residual trading days tests.f-test on i (td):2\",\n            \"diagnostics.quality\"\n        )\n)"
  },
  {
    "objectID": "T-rev-policies-production.html#in-this-chapter",
    "href": "T-rev-policies-production.html#in-this-chapter",
    "title": "Production and revision policies",
    "section": "In this chapter",
    "text": "In this chapter\nThe sections below describe:\n\nhow to update seasonally adjusted series when new data is available\nwhat is a revision policy in a seasonal adjustment context\nthe description of all the revision policies available in JDemetra+\nhow to implement a revision policy using the Graphical User Interface, R or the Cruncher."
  },
  {
    "objectID": "T-rev-policies-production.html#revision-policies",
    "href": "T-rev-policies-production.html#revision-policies",
    "title": "Production and revision policies",
    "section": "Revision Policies",
    "text": "Revision Policies\n\nDefinition and context\nWhen raw data has been modified (extended and/or revised), the previous seasonal adjustment estimation needs updating. It can be redone from scratch (complete re-estimation) or update keeping fixed a predefined set of parameters already estimated. Eurostat’s Guidelines on seasonal adjustment (2015) recommend not to perform a complete re-estimation of the parameters on an infra-annual basis. The set of constraints on the parameters is called “revision policy” or “refresh policy”.\n\n\nOverview\nIn X13-ARIMA and TRAMO-SEATS revision policies are ways to impose constraints on the pre-adjustment phase, while the decomposition phase (X-11 or Seats) will be entirely re-run on new data. The changes induced by X-11 re-estimation stem only from a revised linerarized series, while in Seats they are also induced by the arima model possible coefficient and/ or order changes.\nThe table below lists the available policies as well as their name for implementation with the graphical user interface (GUI), the cruncher or rjd3x13 ans rjd3tramoseats packages."
  },
  {
    "objectID": "T-rev-policies-production.html#implementation-in-gui",
    "href": "T-rev-policies-production.html#implementation-in-gui",
    "title": "Production and revision policies",
    "section": "Implementation in GUI",
    "text": "Implementation in GUI\nTo refresh results from previous estimation open your workspace, then SAprocessing click on a series to highlight it (or select several series), then right-click and choose Refresh, the following panel is displayed.\n\n\nDisplay in results panel\nSections below detail, though an example, the changes in results display brought about by the use of a given revision policy.\n\nConcurrent\nConcurrent adjustment means that the model, filters, outliers, regression parameters and transformation type are all re-identified and the respective parameters and factors re-estimated every time new observations are available. This option in JDemetra+ means that a completely new model is identified, and the previous results are not taken into account, excepted for the user-defined parameters.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Concurrent adjustment option (on the right). The transformation type has changed from none to log. The ARIMA model has been re-identified (it has changed from (0,1,1)(1,1,0) to (1,1,0)(0,1,1)). In contrast to the initial model, in the updated model trading day effects and a leap year effect are no longer included. Also the automatically identified outliers are not the same in both models.\n\n\n\nPartial concurrent adjustment → Fixed model\nThe Partial concurrent adjustment → Fixed model strategy means that the ARIMA model, outliers and other regression parameters are not re-identified and the values of the parameters are fixed. In particular, no new outliers or calendar variables are added to the model as well as no changes neither in the calendar variables nor in the outliers’ types are allowed. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Fixed model option (on the right). The parameters of the ARIMA part are not estimated and their values are the same as before. The trading days and outliers are fixed too and no new regression effects are identified.\n\n\n\nPartial concurrent adjustment → Estimate regression coefficients\nThe Partial current adjustment → Estimate regression coefficients option means that the ARIMA model, outliers and other regression parameters are not re-identified. The coefficients of the ARIMA model are fixed, other coefficients are re-estimated. In particular, no new outliers or calendar variables are added to the model as well as no changes neither in the calendar variables nor in the outliers’ types are allowed. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients option (on the right). The number of estimated parameters is 16 in the initial model and 14 in the revised model (the parameters of the ARIMA model are not estimated.\n\nThe Partial concurrent adjustment→ Estimate regression coefficients revision policy results\n\n\nPartial concurrent adjustment → Estimate regression coefficients + Arima parameters\nThe Partial concurrent adjustment → Estimate regression coefficients + Arima parameters strategy means that the ARIMA model, outliers and other regression parameters are not re-identified. All parameters of the Reg-ARIMA model are re-estimated but the explanatory variables remain the same. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficient + Arima parameters option (on the right). The parameters of the ARIMA part have been re-estimated and their values have been updated. Also regression coefficients have been re-estimated and the number of estimated coefficients in the revised model is the same as in the initial model (i.e. 16 estimated coefficients). The structure of the model remains unchanged while all coefficients have been updated.\n\n\n\nPartial concurrent adjustment → Estimate regression coefficients + outliers\nThe Partial concurrent adjustment → Estimate regression coefficients + outliers option means that the ARIMA model and regression parameters, except outliers, are not re-identified. The parameters of these variables, however, are re-estimated. All outliers are re-identified, i.e. the previous outcome of the outlier detection procedure is not taken into account and all outliers are identified and estimated once again. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients + outliers option (on the right). The parameters of the ARIMA part have been re-estimated and their values have been updated. Also regression coefficients for the calendar variables have been re-estimated. In the revised model there is no Prespecified outliers section. Instead, the outliers were re-identified.\n\n\n\nPartial concurrent adjustment → Estimate regression coefficients + Arima model\nThe Partial concurrent adjustment → Estimate regression coefficients + Arima model option means that the ARIMA model, outliers and regression variables (except the calendar variables) are re-identified. All parameters are re-estimated. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients + Arima model option (on the right). The ARIMA part has been re-identified (a change from (2,1,0)(0,1,1) to (0,1,1)(1,1,1)). Also the regression coefficients for the calendar variables have been re-estimated. In the revised model there is no Prespecified outliers section. Therefore, the outliers were re-identified.\n\n\n\nPartial concurrent adjustment → Estimate regression coefficients + Last outliers\nThe Partial concurrent adjustment → Estimate regression coefficients + Last outliers strategy means that the ARIMA model, outliers (except for the last year of the sample) and other regression parameters are not re-identified. All parameters of the Reg-ARIMA model are re-estimated. The software tests for outliers in the last year of the data span and will include in the model those which are statistically significant. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients + Last outliers option (on the right). The parameters of the ARIMA part have been re-estimated and their values have been updated. Also the regression coefficients have been re-estimated. The number of estimated coefficients in the revised model is larger than the initial model because an additional outlier has been identified in the last year of the data span."
  },
  {
    "objectID": "T-rev-policies-production.html#implementation-with-the-cruncher",
    "href": "T-rev-policies-production.html#implementation-with-the-cruncher",
    "title": "Production and revision policies",
    "section": "Implementation with the cruncher",
    "text": "Implementation with the cruncher\nIn a production process, it might be suitable to use the cruncher in order to automatically update workspaces. When using an R package (rjwsacruncher`` orJDCruncher`) to do so, you will just need to specify the policy’s name as shown below. Available policies and names are detailed in the #Overview section.\n\ncruncher_and_param(\n    workspace = \"D:/my_folder/my_ws.xml\",\n    rename_multi_documents = FALSE,\n    policy = \"stochastic\", # name of the revision policy\n    log = my_log_file.txt\n)"
  },
  {
    "objectID": "T-rev-policies-production.html#implementation-in-r-with-rjd3x13-or-rjd3tramoseats",
    "href": "T-rev-policies-production.html#implementation-in-r-with-rjd3x13-or-rjd3tramoseats",
    "title": "Production and revision policies",
    "section": "Implementation in R with rjd3x13 or rjd3tramoseats",
    "text": "Implementation in R with rjd3x13 or rjd3tramoseats\nWhen performing seasonal adjustment directly in R with rjd3x13 or rjd3tramoseats, you will need to refresh the “result_spec” yielded by the previous estimation with the selected policy. Available policies and names are detailed in the #Overview section. More explanations and code examples are available in the packages’ help pages, corresponding to functions rjd3x13::x13_refresh, rjd3x13::regarima_refresh,rjd3tramoseats::tramoseats_refresh, rjd3tramoseats::tramo_refresh."
  },
  {
    "objectID": "T-plug-ins.html#main-functions",
    "href": "T-plug-ins.html#main-functions",
    "title": "Plug-ins GUI",
    "section": "Main functions",
    "text": "Main functions\n\nDefault Plugins\n\n\n\n\n\n\n\n\nName\nCategory\nDescription\n\n\n\n\nNbDemetra – Anomaly detection\nSA core algorithms\nIdentification of outliers\n\n\nNbDemetra – Spreadsheet\nIO (Input/output)\nTime series providers for spreadsheet (Excel, OpenOffice)\n\n\nNbDemetra – Common\nIO (Input/output)\nCommon time series providers, like XML and TXT\n\n\nNbDemetra – JDBC\nIO (Input/output)\nTime series provider for the JDBC sources\n\n\nNbDemetra – ODBC\nIO (Input/output)\nTime series provider for the ODBC sources\n\n\nNbDemetra – SDMX\nIO (Input/output)\nTime series provider for SDMX files\n\n\nNbDemetra – Core\nSA core algorithms\nEncapsulation of the core algorithms\n\n\nNbDemetra – UI\nSA core algorithms\nBasic graphical components\n\n\nNbDemetra – Branding\nSA core algorithms\n\n\n\nNbDemetra – SA\nSA core algorithms\nDefault SA framework, including TRAMO-SEATS and X-13ARIMA-SEATS. This implementation can lead to small differences in comparison with the original programs.\n\n\n\nThis list is displayed in the Installed panel. This panel is available from the Plugin functionality and it is activated from the Tools menu."
  },
  {
    "objectID": "T-plug-ins.html#plugins-list",
    "href": "T-plug-ins.html#plugins-list",
    "title": "Plug-ins GUI",
    "section": "Plugins-list",
    "text": "Plugins-list\n\nEurostat plug-ins\nThe Quality Report (QR) Eurostat plug-in is available here and can be installed as indicated below\n\n\nBundesbank plug-ins\n\nConCur: The plug-in ConCur supports the controlled current adjustment approach. It supports the storage of the current components and offers graphical tools to compare forecasted and re-estimated figures. Furthermore, a pre-defined summary of the output containing the most important quality measures can be exported to HTML files.\nKIX: The plug-in KIX (German for chain-linked index) has been designed to facilitate the handling of this index type. It offers addition and subtraction of two or more chain-linked time series as well as the computation of contributions of growth.\n\nKIX2.0: KIX 2.0 offers addition and subtraction of two or more chain-linked time series as well as the computation of contributions of growth following the concept of annual overlap. Contributions to growth are calculated with the partial contribution to growth approach.\nKIXE: KIX_E offers addition and subtraction of two or more chain-linked time series as well as the computation of contributions of growth following the concept of one-period overlap. Contributions to growth are calculated with the aid of the Ribe (1999) contribution to growth approach.\nKIX: The program KIX-CC offers for continuously chain-linked indices the aggregation or disaggregation of two or more indices, or the calculation of contributions to growth.\n\nTransReg: The plug-in TransReg allows the user to carry out grouping and centring of user-defined regression variables in JD+.\nXlsx2Ws: The plug-in Xlsx2Ws allows the converting of specific workspace information to a xlsx file and vice versa.\n\n\n\nNational Bank of Belgium plug-ins\n\nAccessThis JDemetra+ extension is a pure java library for reading time series from MS Access databases. It currently supports versions 2000-2016 read/write and 97 read-only.Being a pure Java library, you don’t need MS Access installed in order to read Access files. (edit versions info here)\nSDMX: This plugin provides time series from SDMX to JDemetra+ by querying web services or parsing files.\nSA Advanced: This module provides some experimental seasonal adjustment methods (with Reg-ARIMA preprocessing), basic structural models, generalized airline models and airline + seasonal noise models (called mixed airline).\n\ngairline: generalized airline model\nmairline: mixed airline model\nmixedfreq: mixed frequencies seasonal adjustment\nsssts: Seasonal specific structural time series\nsts: Structural time series\n\nBenchmarking: This module provides some experimental methods for temporal disaggregation and multi-variate benchmarking:Chow-Lin, Fernandez, Litterman, Cholette, Calendarization.\nNowcasting: Nowcasting is often defined as the prediction of the present, the very near future and the very recent past. The plug-in developed at the National Bank of Belgium helps to operationalize the process of nowcasting. It can be used to specify and estimate dynamic factor models and visualize how the real-time dataflow updates expectations, as for instance in Banbura and Modugno (2010). The software can also be used to perform pseudo out-of-sample forecasting evaluations that consider the calendar of data releases, contributing to the formalization of the nowcasting problem originally proposed by Giannone, et al. (2008) or Evans (2005)."
  },
  {
    "objectID": "T-plug-ins.html#t-plug-ins-inst",
    "href": "T-plug-ins.html#t-plug-ins-inst",
    "title": "Plug-ins GUI",
    "section": "Installation procedure",
    "text": "Installation procedure\nInstallation from GUI\nmenu&gt;tools&gt; plug-ins\nThe Plugins window includes five panels: Updates, Available plugins, Downloaded, Installed and Settings, some of them however are not operational in the current version of the software.\n\nThe Updates panel offers the user the option to manually check if some updates of the already installed plugins are available. This functionality, however, is currently not operational for the JDemetra+ plugins.\nThe Available plugins panel allows the downloading of all plugins that are related to JDemetra+. This functionality, however, is currently not operational for the JDemetra+ plugins.\nThe Downloaded panel is designed for the installation of new plugins from a local machine. This process in explained in more detail below.\nThe Settings panel is designated for adding update centres, which are the locations that hold plugins. For each centre the user can specify proxy settings and a time interval to automatically check for any updates. At the moment this functionality is not operational for the JDemetra+ plugins.\n\nInstallation of the new plugins from the local machine can be done from the Plugin functionality activated from the Tools menu.\nInstallation of the new plugins from the local machine can be done from the Plugin functionality activated from the Tools menu.\n\nActivation of the Plugin functionality from the Tools menu\nTo start the process, go to the Downloaded panel and click on the Add Plugins… option. Next the user should select the plugins from the folder in which the plugins have been saved and click the OK button.\n``\n\nThe Downloaded panel – the choice of available plugins\nThe new plugin is now visible in the panel.\n\nA downloaded plugin\nClick on it and choose the Install button.\n\nStarting an installation procedure\nThere is a wizard that allows the user to install the marked plugin(s). In the first step choose Next to continue or Cancel to terminate the process.\n\nInstallation wizard window\nNext, mark the terms of agreements and choose Install.\n\nInitiating installation process\nThen the process is started.\n\nInstallation in progress\nAfter a while JDemetra+ will provide an update in the installation process. Click Finish to close the window.\n\nInstallation completed\nOnce the process is finished, the newly installed plugin is automatically integrated within the software. The picture below compares the view of the Workspace window before (on the left) and after (on the right) the installation of the NbDemetra-ODBC plugin.\n\nThe impact of the plugin on the interface\nThe list of all installed plugins is displayed in the fourth panel. To modify the current settings mark the plugin (by clicking the checkbox in the Select column) and chose an action.\nThe following options are available:\n\nActivate – activates the marked plugin if it is currently inactive. The option is available for inactive plugins (see the picture below);\nDeactivate – deactivates the marked plugin if it is currently active. The option is available for active plugins (see the picture below);\nUninstall – uninstalls the marked plugin.\n\nInactive plugins can be activated or uninstalled.\n\nActive plugins can be deactivated or uninstalled\n\nList of plugins – deactivation\nThere is a wizard that allows the user to activate/deactivate/uninstall the marked plugin(s). The example below illustrates the deactivation process. In the first step the user is expected to confirm or cancel the deactivation.\n\nPlugin’s deactivation process\nIn the second step the user should decide if the software will be restarted immediately after the uninstallation is completed or not.\n\nThe final step of the installation procedure\nIt is possible to delay the restart of the application, although the restart is necessary to complete the process."
  },
  {
    "objectID": "P_Methods.html",
    "href": "P_Methods.html",
    "title": "Methods",
    "section": "",
    "text": "This part provides underlying methodological background on all the algorithms featured in JDemetra+.\nPractical guidance on how to use these algorithms can be found here, whereas detailed description of all the available tools allowing to use them can be found in the Tools part of this book.\nIn this part:\n\nSpectral analysis tools\nTests for seasonality and residuals\nReg-Arima modelling\nX-11: moving average based decomposition\nSEATS: Arima model based decomposition\nSTL: Loess based decomposition\nStructural time series and state space framework\nSeasonal Adjustment of High-Frequency Data\nTrend Estimation\nBenchmarking and temporal disaggregation"
  },
  {
    "objectID": "M-spectral-analysis.html#in-this-chapter",
    "href": "M-spectral-analysis.html#in-this-chapter",
    "title": "Spectral Analysis Principles and Tools",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter provides some guidance on spectral analysis, which will allow to understand the principle of various spectral analysis tools available in JDemetra+, via Graphical User Interface and R packages.\n\nexplanation of spectral graphs here, but description in GUI chap\noutputs of tests ?\ndescription of spectral graphs in GUI can be found here"
  },
  {
    "objectID": "M-spectral-analysis.html#spectral-analysis-concepts",
    "href": "M-spectral-analysis.html#spectral-analysis-concepts",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Spectral analysis concepts",
    "text": "Spectral analysis concepts\nA time series \\(x_{t}\\) with stationary covariance, mean \\(μ\\) and \\(k^{th}\\) autocovariance \\(E((x_{t}-\\mu)(x_{t-k}\\mu))=\\gamma(k)\\) can be described as a weighted sum of periodic trigonometric functions: \\(sin(\\omega t)\\) and \\(cos(\\omega t)\\), where \\(\\omega=\\frac{2*pi}{T}\\) denotes frequency. Spectral analysis investigates this frequency domain representation of \\(x_{t}\\) to determine how important cycles of different frequencies are in accounting for the behaviour of \\(x_{t}\\).\nAssuming that the autocovariances \\(\\gamma(k)\\) are absolutely summable(\\(\\sum_{k=-\\infty}^{\\infty}|\\gamma(k)|&lt;\\infty\\)), the autocovariance generating function, which summarizes these autocovariances through a scalar valued function, is given by Equation 1 (HAMILTON, J.D. (1994)).\n\\[\nacgf(z)=\\sum_{k=-\\infty}^{\\infty}{z^{k}\\gamma(k)}\n\\tag{1}\\]\nwhere \\(z\\) denotes a complex scalar.\nOnce the Equation 1 is divided by \\(\\pi\\) and evaluated at some \\(z{=e}^{-i\\omega}=cos\\omega-isin\\omega\\), where \\(i=\\sqrt{-1}\\) and \\(\\omega\\) is a real scalar, \\(-\\infty &lt; \\ \\omega &lt; \\infty\\), the result of this transformation is called a population spectrum \\(f(\\omega)\\)for \\(\\ x_{t}\\), given in Equation 2 (HAMILTON, J.D. (1994)).\n\\[\nf(\\omega)=\\frac{1}{\\pi}\\sum_{k=-\\infty}^{\\infty}{e^{-ik\\omega}\\gamma(k)}\n\\tag{2}\\]\nTherefore, the analysis of the population spectrum in the frequency domain is equivalent to the examination of the autocovariance function in the time domain analysis; however it provides an alternative way of inspecting the process. Because \\(f(\\omega)\\text{dω}\\) is interpreted as a contribution to the variance of components with frequencies in the range \\((\\omega,\\ \\omega+d\\omega)\\), a peak in the spectrum indicates an important contribution to the variance at frequencies near the value that corresponds to this peak.\nAs \\(e^{-i\\omega}=cos\\omega-isin\\omega\\), the spectrum can be also expressed as in Equation 3.\n\\[\nf(\\omega)=\\frac{1}{\\pi}\\sum_{k=-\\infty}^{\\infty}{(cos\\omega k-isin\\omega k)\\gamma(k)}\n\\tag{3}\\]\nEquation 3 can be presented as:\n\\[\nf(\\omega)=\\frac{1}{\\pi}[\\ \\gamma(0)+2\\sum_{k=1}^{\\infty}{\\ \\gamma(k)}cos\\text{ωk}]\n\\tag{4}\\]\nThis implies that if autocovariances are absolutely summable the population spectrum exists and is a continuous, real-valued function of \\(\\omega\\). Due to the properties of trigonometric functions \\((\\cos(-\\omega k)=\\cos(\\text{ωk})\\) and \\(\\cos(\\omega+2\\pi j)k=cos(\\omega k))\\) the spectrum is a periodic, even function of \\(\\omega\\), symmetric around \\(\\omega=0\\). Therefore, the analysis of the spectrum can be reduced to the interval \\((-\\pi,\\pi)\\). The spectrum is non-negative for all \\(\\omega \\in (-\\pi,\\pi)\\).\nThe shortest cycle that can be distinguished in a time series lasts two periods. The frequency which corresponds to this cycle is \\(\\omega=\\pi\\) and is called the Nyquist frequency. The frequency of the longest cycles that can be observed in the time series with \\(n\\) observations is \\(\\omega=\\frac{2\\pi}{n}\\) and is called the fundamental (Fourier) frequency.\nNote that if \\(x_{t}\\) is a white noise process with zero mean and variance \\(\\sigma^{2}\\), then for all \\(|k|&gt; 0\\) \\(\\gamma(k)=0\\) and the spectrum of \\(x_{t}\\) is constant (\\(f(\\omega)=\\frac{\\sigma^{2}}{\\pi}\\)) since each frequency in the spectrum contributes equally to the variance of the process (BROCKWELL, P.J., and DAVIS, R.A. (2002)).\nThe aim of spectral analysis is to determine how important cycles of different frequencies are in accounting for the behaviour of a time series. Since spectral analysis can be used to detect the presence of periodic components, it is a natural diagnostic tool for detecting trading day effects as well as seasonal.\nAmong the tools used for spectral analysis are the autoregressive spectrum and the periodogram.\nThe explanations given in the subsections of this node derive mainly from DE ANTONIO, D., and PALATE, J. (2015) and BROCKWELL, P.J., and DAVIS, R.A. (2006)."
  },
  {
    "objectID": "M-spectral-analysis.html#spectral-density-of-an-arima-model",
    "href": "M-spectral-analysis.html#spectral-density-of-an-arima-model",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Spectral density of an ARIMA model",
    "text": "Spectral density of an ARIMA model\n\nEstimation\n\nMethod 1: Periodogram\nFor any given frequency \\(\\omega\\) the sample periodogram is the sample analog of the sample spectrum. In general, the periodogram is used to identify the periodic components of unknown frequency in the time series. X-13ARIMA-SEATS and TRAMO-SEATS use this tool for detecting seasonality in raw time series and seasonally adjusted series. Apart from this it is applied for checking randomness of the residuals from the ARIMA model.\nTo define a periodogram, first consider a vector of complex numbers\n\\[\n\\mathbf{x}=\\begin{bmatrix}\n  x_{1} \\\\\n  x_{2} \\\\\n  . \\\\\n  . \\\\\n  . \\\\\n  x_{n} \\\\\n  \\end{bmatrix} \\in \\mathbb{C}^{n}\n\\tag{5}\\]\nwhere \\(\\mathbb{C}^{n}\\) is the set of all column vectors with complex-valued components.\nThe Fourier frequencies associated with the sample size \\(n\\) are defined as a set of values \\(ω_{j}=\\frac{2\\pi j}{n}\\), \\(j=-[\\frac{n-1}{2}],\\ldots,[\\frac{n}{2}]\\), \\(-\\pi&lt; \\omega_{j} \\leq \\pi\\), \\(j\\in F_{n}\\), where \\({[n]}\\) denotes the largest integer less than or equal to \\(n\\). The Fourier frequencies, which are called harmonics, are given by integer multiples of the fundamental frequency \\(\\ \\frac{2\\pi}{n}\\).\nNow the \\(n\\) vectors \\(e_{j}=n^{-\\frac{1}{2}}(e^{-i\\omega_{j}},e^{-i{2\\omega}_{j}},\\ldots,e^{-inω_{j}})^{'}\\) can be defined. Vectors \\(e_{1},\\ldots, e_{n}\\) are orthonormal in the sense that:\n\\[\n{\\mathbf{e}_{j}^{*}\\mathbf{e}}_{k}=n^{-1}\\sum_{r=1}^{n}e^{ir(\\omega_{j}-\\omega_{k})}={ \\begin{matrix}\n1,\\ if\\ j=k \\\\\n0,\\ if\\ j \\neq k \\\\\n\\end{matrix}}\n\\tag{6}\\]\nwhere \\(\\mathbf{e}_{j}^{*}\\) denotes the row vector, which \\(k^{th}\\) component is the complex conjugate of the \\(k^{th}\\) component of \\(\\mathbf{e}_{j}\\). These vectors are a basis of \\(F_{n}\\), so that any \\(\\mathbf{x}\\in\\mathbb{C}^{n}\\) can be expressed as a sum of \\(n\\) components:\n\\[\n\\mathbf{x}=\\sum_{j=-[\\frac{n-1}{2}]}^{[\\frac{n}{2}]}{a_{j}\\mathbf{e}_{j}}\n\\tag{7}\\]\nwhere the coefficients \\(a_{j}=\\mathbf{e}_{j}^{*}\\mathbf{x}=n^{-\\frac{1}{2}}\\sum_{t=1}^{n}x_{t}e^{-it\\omega_{j}}\\) are derived from Equation 7 by multiplying the equation on the left by \\(\\mathbf{e}_{j}^{*}\\) and using Equation 5.\nThe sequence of \\(\\{a_{j},j\\in F_{n}\\}\\) is referred as a discrete Fourier transform of \\(\\mathbf{x}\\mathbb{\\in C}^{n}\\) and the periodogram \\(I(\\omega_{j})\\) of \\(\\mathbf{x}\\) at Fourier frequency \\(\\omega_{j}=\\frac{2\\pi j}{n}\\) is defined as the square of the Fourier transform \\(\\{a_{j}\\}\\) of \\(\\mathbf{x}\\):\n\\[\n{I(\\omega_{j})\\mathbf{=}{|a_{j} |^{2}}_{\\ }=n^{-\\ 1}|\\sum_{t=1}^{n}x_{t}e^{-it\\omega_{j}} |^{2}}_{\\mathbf{\\ }}\n\\tag{8}\\]\nFrom Equation 6 and Equation 7 it can be shown that a periodogram decomposes the total sum of squares \\(\\sum_{t=1}^{n}|x_{t} |^{2}\\) into a sum of components associated with the Fourier frequencies \\(ω_{j}\\):\n\\[\n\\sum_{t=1}^{n}{|x_{t}|}^{2}=\\sum_{j=-[\\frac{n-1}{2}]}^{[\\frac{n}{2}]}|a_{j}|^{2}=\\sum_{j=-[\\frac{n-1}{2}]}^{[\\frac{n}{2}]}{I(\\omega_{j})}\n\\tag{9}\\]\nIf \\(\\ \\mathbf{x\\  \\in}\\ {R}^{n}\\), \\(\\omega_{j}\\) and \\({-\\omega}_{j}\\) are both in \\([-\\pi,-\\pi]\\) and \\(a_{j}\\) is presented in its polar form (i.e. \\(a_{j}=r_{j}\\exp(i\\theta_{j})\\)), where \\(r_{j}\\) is the modulus of \\(a_{j}\\), then Equation 7 can be rewritten in the form:\n\\[\n\\mathbf{x}=a_{0}\\mathbf{e}_{0}+\\sum_{j=1}^{[\\frac{n-1}{2}]}{ {2^{1/2}r}_{j}{(\\mathbf{c}}_{j}\\cos\\theta_{j}{-\\mathbf{s}}_{j}\\sin\\theta_{j})+a_{n/2}\\mathbf{e}_{n/2}}\n\\tag{10}\\]\nThe orthonormal basis for \\({R}^{n}\\) is \\(\\{\\mathbf{e}_{0},\\mathbf{c}_{1},\\mathbf{s}_{1},\\ldots,\\mathbf{c}_{[\\frac{n-1}{2}]},\\mathbf{s}_{[\\frac{n-1}{2}]},\\mathbf{e}_{\\frac{n}{2}(excluded\\ if\\ n\\ is\\ odd)}\\}\\), where:\n\\(\\mathbf{e}_{0}\\) is a vector composed of n elements equal to \\(n^{-1/2}\\), which implies that \\(\\mathbf{a}_{0}\\mathbf{e}_{0}={(n^{-1}\\sum_{t=1}^{n}x_{t},\\ldots,n^{-1}\\sum_{t=1}^{n}x_{t})}^{'}\\);\n\\[\n\\mathbf{c}_{j}=(\\frac{n}{2})^{-1/2}{(\\cos\\omega_{j},\\cos{2\\omega}_{j},\\ldots,\\cos{n\\omega_{j}})}^{'}, for 1 \\leq j \\leq [\\frac{(n-1)}{2}]\n\\]\n\\[\n\\mathbf{s}_{j}={(\\frac{n}{2})}^{-1/2}{(\\sin{\\omega_{j}},\\sin{2\\omega_{j}},\\ldots,\\sin{n\\omega_{j}})}^{'},\\ for\\ 1 \\leq j \\leq [\\frac{(n-1)}{2}]\n\\]\n\\[\n\\mathbf{e}_{n/2}={(-(n^{-\\frac{1}{2}}),n^{-\\frac{1}{2}},\\ldots,{-(n)}^{-\\frac{1}{2}}),n^{-\\frac{1}{2}})}^{'}\n\\]\nEquation 9 can be seen as an OLS regression of \\(x_{t}\\) on a constant and the trigonometric terms. As the vector of explanatory variables includes \\(n\\) elements, the number of explanatory variables in Equation 9 is equal to the number of observations. HAMILTON, J.D. (1994) shows that the explanatory variables are linearly independent, which implies that an OLS regression yields a perfect fit (i.e. without an error term). The coefficients have the form of a simple OLS projection of the data on the orthonormal basis:\n\\[\n\\widehat{a}_{0}=\\frac{1}{\\sqrt{n}}\\sum_{t=1}^{n}x_{t}\n\\tag{11}\\]\n\\[\n\\widehat{a}_{n/2}=\\frac{1}{\\sqrt{n}}\\sum_{t=1}^{n}{(-1)}^{t}x_{t}(  \\text{only when n is even})\n\\tag{12}\\]\n\\[\n\\widehat{a}_{0}=\\frac{1}{\\sqrt{n}}\\sum_{t=1}^{n}x_{t}\n\\tag{13}\\]\n\\[\n{\\widehat{\\alpha}}_{j}=2^{1/2}r_{j}\\cos{\\theta_{j}}={(\\frac{n}{2})}^{-1/2}\\sum_{t=1}^{n}x_{t}\\cos{(t\\frac{2\\pi j}{n})}, j  =1,\\ldots,[\\frac{n-1}{2}]\n\\tag{14}\\]\n\\[\n{\\widehat{\\beta}}_{j}=2^{1/2}r_{j}\\sin{\\theta_{j}}={(\\frac{n}{2})}^{-1/2}\\sum_{t=1}^{n}x_{t}\\sin{(t\\frac{2\\pi j}{n})}, j=1,\\ldots,[\\frac{n-1}{2}]\n\\tag{15}\\]\nWith Equation 9 the total sum of squares \\(\\sum_{t=1}^{n}|x_{t} |^{2}\\) can be decomposed into \\(2 \\times [\\frac{n-1}{2}]\\) components corresponding to \\(\\mathbf{c}_{j}\\) and \\(\\mathbf{s}_{j}\\), which are grouped to produce the “frequency \\(ω_{j}\\)” component for \\(1 \\geq j \\geq [\\frac{n-1}{2}]\\). As it is shown in the table below, the value of the periodogram at the frequency \\(\\omega_{j}\\) is the contribution of the \\(j^{\\text{th}}\\) harmonic to the total sum of squares \\(\\sum_{t=1}^{n}|x_{t} |^{2}\\).\nDecomposition of sum of squares into components corresponding to the harmonics\n\n\n\n\n\n\n\n\nFrequency\nDegrees of freedom\nSum of squares decomposition\n\n\n\n\n\\(\\omega_{0}\\) (mean)\n1\n\\({a_{0}^{2}}_{\\ }=n^{-1}(\\sum_{t=1}^{n}x_{t})^{2}=I(0)\\)\n\n\n\\(\\omega_{1}\\)\n2\n\\({2r_{1}^{2}}_{\\ }=2{|a_{1}|}^{2}=2I(\\omega_{1})\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(\\omega_{k}\\)\n2\n\\({2r_{k}^{2}}_{\\ }=2{|a_{k}|}^{2}=2I(\\omega_{k})\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(\\omega_{n/2}=\\pi\\) (excluded if \\(n\\) is odd)\n1\n\\(a_{n/2}^{2}=I(\\pi)\\)\n\n\nTotal\n\\(\\mathbf{n}\\)\n\\(\\sum_{\\mathbf{t=1}}^{\\mathbf{n}}\\mathbf{x}_{\\mathbf{t}}^{\\mathbf{2}}\\)\n\n\n\nSource: DE ANTONIO, D., and PALATE, J. (2015).\nObviously, if series were random then each component \\(I(\\omega_{j})\\) would have the same expectation. On the contrary, when the series contains a systematic sine component having a frequency \\(j\\) and amplitude \\(A\\) then the sum of squares \\(I(\\omega_{j})\\) increases with \\(A\\). In practice, it is unlikely that the frequency \\(j\\) of an unknown systematic sine component would exactly match any of the frequencies, for which periodogram have been calculated. Therefore, the periodogram would show an increase in intensities in the immediate vicinity of \\(j\\). (BOX, G.E.P., JENKINS, G.M., and REINSEL, G.C. (2007).\nNote that in JDemetra+ the periodogram object corresponds exactly to the contribution to the sum of squares of the standardised data, since the series are divided by their standard deviation for computational reasons.\nUsing the decomposition presented in table above the periodogram can be expressed as:\n\\[\nI(\\omega_{j})\\mathbf{=}\\begin{matrix}r_{j}^{2}=\\frac{1}{2}{(\\alpha}_{j}^{2}+\\beta_{j}^{2})=\\ {\\frac{1}{n}(\\sum_{t=1}^{n}{x_{t}\\cos{({t\\frac{2\\pi j}{n}}_{\\ })\\ }})}^{2}+\\frac{1}{n}(\\sum_{t=1}^{n}{x_{t}\\sin(t\\frac{2\\pi j}{n})_{\\ }})^{2} \\\\\n\\end{matrix}\n\\tag{16}\\]\nwhere \\(j=0,\\ldots,[\\frac{n}{2}]\\).\nSince \\(\\mathbf{x}-\\overline{\\mathbf{x}}\\) are generated by an orthonormal basis, and \\(\\overline{\\mathbf{x}}\\mathbf{=}a_{0}\\mathbf{e}_{0}\\) Equation 9 can be rearranged to show that the sum of squares is equal to the sum of the squared coefficients:\n\\[\n\\mathbf{x}-a_{0}\\mathbf{e}_{0}=\\sum_{j=1}^{[(n-1)/2]}(\\alpha_{j}\\mathbf{c}_{j}+\\beta_{j}\\mathbf{s}_{j})+a_{n/2}\\mathbf{e}_{n/2}\n\\tag{17}\\]\nThus the sample variance of \\(x_{t}\\) can be expressed as:\n\\[\nn^{-1}\\sum_{t=1}^{n}{(x_{t}-\\overline{x})}^{2}=n^{-1}(\\sum_{k=1}^{[(n-1)/2]}2{r_{j}}^{2}\n+{a_{n/2}}^{2})\n\\tag{18}\\]\nwhere \\(a_{n/2}^{2}\\) is excluded if \\(n\\) is odd.\nThe term \\(2{r_{j}}^{2}\\) in Equation 18 is then the contribution of the \\(j^{\\text{th}}\\) harmonic to the variance and Equation 18 shows then how the total variance is partitioned.\nThe periodogram ordinate \\(I(\\omega_{j})\\) and the autocovariance coefficient \\(\\gamma(k)\\) are both quadratic forms of \\(x_{t}\\). It can be shown that the periodogram and autocovariance function are related and the periodogram can be written in terms of the sample autocovariance function for any non-zero Fourier frequency \\(ω_{j}\\) (The proof is given in BROCKWELL, P.J., and DAVIS, R.A. (2006)).\n\\[\nI(\\omega_{j})=\\sum_{|k |&lt; n}^{\\ }{\\widehat{\\gamma}(k)}_{\\ }e^{-ik\\omega_{j}}={\\widehat{\\gamma}(0)}_{\\ }+2\\sum_{k=1}^{n-1}{\\widehat{\\gamma}(k)\\cos{(k\\omega_{j})}}_{\\ }\n\\tag{19}\\]\nand for the zero frequency \\(\\ I(0)=n|\\overline{x}|^{2}\\).\nOnce comparing Equation 19 with an expression of the spectral density of a stationary process:\n\\[\nf(\\omega_{\\ })=\\frac{1}{2\\pi}\\sum_{k &lt;-\\infty}^{\\infty}{\\gamma(k)}_{\\ }e^{-ik\\omega_{\\ }}=\\frac{1}{2\\pi}[{\\gamma(0)}_{\\ }+2(\\sum_{k=1}^{\\infty}{\\gamma(k)\\cos{(k\\omega_{\\ })}})]\n\\tag{20}\\]\nIt can be noticed that a periodogram is a sample analogue of the population spectrum. In fact, it can be shown that the periodogram is asymptotically unbiased but inconsistent estimator of the population spectrum \\(f(\\omega)\\). Therefore, the periodogram is a wildly fluctuating, with high variance, estimate of the spectrum. However, the consistent estimator can be achieved by applying the different linear smoothing filters to the periodogram, called lag-window estimators. The lag-window estimators implemented in JDemetra+ includes square, Welch, Tukey, Barlett, Hanning and Parzen. They are described in DE ANTONIO, D., and PALATE, J. (2015). Alternatively, the model-based consistent estimation procedure, resulting in autoregressive spectrum estimator, can be applied.\n\n\nMethod 2: Autoregressive spectrum estimation\nBROCKWELL, P.J., and DAVIS, R.A. (2006) point out that for any real-valued stationary process \\((x_{t})\\) with continuous spectral density \\(f(\\omega)\\) it is possible to find both \\(AR(p)\\) and \\(MA(q)\\) processes which spectral densities are arbitrarily close to \\(f(\\omega)\\). For this reason, in some sense, \\((x_{t})\\) can be approximated by either \\(AR(p)\\) or \\(MA(q)\\) process. This fact is a basis of one of the methods of achieving a consistent estimator of the spectrum, which is called an autoregressive spectrum estimation. It is based on the approximation of the stochastic process \\((x_{t})\\) by an autoregressive process of sufficiently high order \\(p\\):\n\\[\nx_{t}=\\mu+(\\phi_{1}B+\\ldots+\\phi_{p}B^{p})x_{t}+\\varepsilon_{t}\n\\tag{21}\\]\nwhere \\(\\varepsilon_{t}\\) is a white-noise variable with mean zero and a constant variance.\nThe autoregressive spectrum estimator for the series \\(x_{t}\\) is defined as (Definition from ‘X-12-ARIMA Reference Manual’ (2011)).\n\\[\n\\widehat{s}(\\omega)=10\\operatorname{\\times}{\\log_{10}\\frac{\\sigma_{x}^{2}}{2\\pi{|1-\\sum_{k=1}^{p}{\\widehat{\\phi}}_{k}e^{-ik\\omega}|}^{2}}}\n\\tag{22}\\]\nwhere:\n\n\\(\\omega\\)– frequency, \\(0 \\leq \\omega \\leq \\pi\\);\n\\(\\sigma_{x}^{2}\\) innovation variance of the sample residuals;\n\\(\\widehat{\\phi}_{k}\\)–\\(\\text{AR}(k)\\) coefficient estimates of the linear regression of \\(x_{t}-\\overline{x}\\) on \\(x_{t-k}-\\overline{x}\\), \\(1 \\leq k \\leq p\\).\n\nThe autoregressive spectrum estimator is used in the visual spectral analysis tool for detecting significant peaks in the spectrum. The criterion of visual significance, implemented in JDemetra+, is based on the range \\({\\widehat{s}}^{\\max}-{\\widehat{s}}^{\\min}\\) of the \\(\\widehat{s}(\\omega)\\) values, where \\({\\widehat{s}}^{\\max}=\\max_{k}\\widehat{s}(\\omega_{k})\\); \\({\\widehat{s}}^{\\min}=\\min_{k}\\widehat{s}(\\omega_{k});\\) and \\(\\widehat{s}(\\omega_{k})\\) is \\(k^{\\text{th}}\\) value of autoregressive spectrum estimator.\nA particular value is considered to be visually significant if, at a trading day or at a seasonal frequency \\(\\omega_{k}\\) (other than the seasonal frequency \\(\\omega_{60}=\\pi\\)), \\(\\widehat{s}(\\omega_{k})\\) is above the median of the plotted values of \\(\\widehat{s}(\\omega_{k})\\) and is larger than both neighbouring values \\(\\widehat{s}(\\omega_{k-1})\\) and \\(\\widehat{s}(\\omega_{k+1})\\) by at least \\(\\frac{6}{52}\\) times the range \\({\\widehat{s}}^{\\max}-{\\widehat{s}}^{\\min}\\).\nFollowing the suggestion of SOUKUP, R.J., and FINDLEY, D.F. (1999), JDemetra+ uses an autoregressive model spectral estimator of model order 30. This order yields high resolution of strong components, meaning peaks that are sharply defined in the plot of \\(\\widehat{s}(\\omega)\\) with 61 frequencies. The minimum number of observations needed to compute the spectrum is set to \\(n=80\\) for monthly data and to \\(n=60\\) for quarterly series while the maximum number of observations considered for the estimation is 121. Consequently, with these settings it is possible to identify up to 30 peaks in the plot of 61 frequencies. By choosing \\(\\omega_{k}=\\frac{\\text{πk}}{60}\\) for \\(k=0,1,...,60\\) the density estimates are calculated at exact seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year).\nThe model order can also be selected based on the AIC criterion (in practice it is much lower than 30). A lower order produces the smoother spectrum, but the contrast between the spectral amplitudes at the trading day frequencies and neighbouring frequencies is weaker, and therefore not as suitable for automatic detection.\nSOUKUP, R.J., and FINDLEY, D.F. (1999) also explain that the periodogram can be used in the visual significance test as it has as good as those of the AR(30) spectrum abilities to detect trading day effect, but also has a greater false alarm rate, which is defined as the fraction of the 50 replicates for which a visually significant spectral peak occurred at one of the trading day frequencies being considered in the designated output spectra (SOUKUP, R.J., and FINDLEY, D.F. (1999)).\n\n\nMethod 3: Tukey spectrum\nThe Tukey spectrum belongs to the class of lag-window estimators. A lag window estimator of the spectral density \\(f(\\omega)=\\frac{1}{2\\pi}\\sum_{k&lt;-\\infty}^{\\infty}\\gamma(k)e^{i k \\omega}\\) is defined as follows:\n\\[\n\\hat{f}_{L}(\\omega)=\\frac{1}{2\\pi}\\sum_{|h|\\leq r} w(h/r)\\hat{\\gamma}(h)e^{i h \\omega}\n\\]\nwhere \\(\\hat{\\gamma}(.)\\) is the sample autocovariance function, \\(w(.)\\) is the lag window, and \\(r\\) is the truncation lag. \\(|w(x)|\\) is always less than or equal to one, \\(w(0)=1\\) and \\(w(x)=0\\) for \\(|x|&gt; 1\\). The simple idea behind this formula is to down-weight the autocovariance function for high lags where \\(\\hat{\\gamma}(h)\\) is more unreliable. This estimator requires choosing \\(r\\) as a function of the sample size such that \\(r/narrow 0\\) and \\(r\\rightarrow \\infty\\) when \\(narrow \\infty\\) . These conditions guarantee that the estimator converges to the true density.\nJDemetra+ implements the so-called Blackman-Tukey (or Tukey-Hanning) estimator, which is given by \\(w(h/r)=0.5(1+cos(\\pi h/r))\\) if \\(|h/r|\\leq 1\\) and \\(0\\) otherwise.\nThe choice of large truncation lags \\(r\\) decreases the bias, of course, but it also increases the variance of the spectral estimate and decreases the bandwidth.\nJDemetra+ allows the user to modify all the parameters of this estimator, including the window function."
  },
  {
    "objectID": "M-spectral-analysis.html#m-spectral-analysis-m-spectrum-id-peaks",
    "href": "M-spectral-analysis.html#m-spectral-analysis-m-spectrum-id-peaks",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Identification of spectral peaks",
    "text": "Identification of spectral peaks\nThe sections below describe the test, their practical implementation in the Graphical User interface can be found here\nIn order to decide whether a series has a seasonal component that is predictable (stable) enough, these tests use visual criteria and formal tests for the periodogram. The periodogram is calculated using complete years, so that the set of Fourier frequencies contains exactly all seasonal frequencies.\nThe tests rely on two basic principles:\n\nThe peaks associated with seasonal frequencies should be larger than the median spectrum for all frequencies and;\nThe peaks should exceed the spectrum of the two adjacent values by more than a critical value.\n\nJDemetra+ performs this test on the original series. If these two requirements are met, the test results are displayed in green. The statistical significance of each of the seasonal peaks (i.e. frequencies \\(\\frac{\\pi}{6},\\ \\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\ \\frac{2\\pi}{3}\\) and \\(\\frac{5\\pi}{6}\\) corresponding to 1, 2, 3, 4 and 5 cycles per year) is also displayed. The seasonal and trading days frequencies depends on the frequency of time series. They are shown in the table below. The symbol \\(d\\) denotes a default frequency and is described below the table.\nThe seasonal and trading day frequencies by time series frequency\n\n\n\n\n\n\n\n\nNumber of months per period (year)\nSeasonal frequency\nTrading day frequency (radians)\n\n\n\n\n12\n\\(\\frac{\\pi}{6},\\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\frac{2\\pi}{3},\\ \\frac{5\\pi}{6},\\ \\pi\\)\n\\(d\\),2.714\n\n\n4\n\\(\\frac{\\pi}{2}\\), \\(\\pi\\)\n\\(d\\), 1.292, 1.850, 2.128\n\n\n3\n\\(\\pi\\)\n\\(d\\)\n\n\n2\n\\(\\pi\\)\n\\(d\\)\n\n\n\nThe calendar (trading day or working day) effects, related to the variation in the number of different days of the week per period, can induce periodic patterns in the data that can be similar to those resulting from pure seasonal effects. From the theoretical point of view, trading day variability is mainly due to the fact that the average number of days in the months or quarters is not equal to a multiple of 7 (the average number of days of a month in the year of 365.25 days is equal to \\(\\frac{365.25}{12}=30.4375\\) days). This effect occurs \\(\\frac{365.25}{12} \\times \\frac{1}{7}=4.3482\\) times per month: one time for each one of the four complete weeks of each month, and a residual of 0.3482 cycles per month, i.e. \\(0.3482 \\times 2\\pi=2.1878\\) radians. This turns out to be a fundamental frequency for the effects associated with monthly data. In JDemetra+ the fundamental frequency corresponding to 0.3482 cycles per month is used in place of the closest frequency \\(\\frac{\\text{πk}}{60}\\). Thus, the quantity \\(\\frac{\\pi \\times 42}{60}\\) is replaced by \\(\\omega_{42}=0.3482 \\times 2\\pi=2.1878\\). The frequencies neighbouring \\(\\omega_{42}\\), i.e. \\(\\omega_{41}\\) and \\(\\omega_{43}\\) are set to, respectively, \\(2.1865-\\frac{1}{60}\\) and \\(2.1865+\\frac{1}{60}\\).\nThe default frequencies (\\(d\\)) for calendar effect are: 2.188 (monthly series) and 0.280 (quarterly series). They are computed as:\n\\[\n\\omega_{\\text{ce}}=\\frac{2\\pi}{7}(n-7 \\times [\\frac{n}{7}])\n\\tag{23}\\]\nwhere \\(n=\\frac{365.25}{s}\\), \\(s=4\\) for quarterly series and \\(s=12\\) for monthly series.\nOther frequencies that correspond to trading day frequencies are: 2.714 (monthly series) and 1.292, 1.850, 2.128 (quarterly series).\nIn particular, the calendar frequency in monthly data (marked in red on the figure below) is very close to the seasonal frequency corresponding to 4 cycles per year \\(\\text{ω}_{40}=\\frac{2}{3}\\pi=2.0944\\).\n\n\n\nPeriodogram with seasonal (grey) and calendar (red) frequencies highlighted\n\n\nThis implies that it may be hard to disentangle both effects using the frequency domain techniques.\n\nIn a Tukey spectrum\nCurrent JDemetra+ implementation of the seasonality test is based on a \\(F(d_{1},d_{2})\\) approximation that has been originally proposed by Maravall (2012) for TRAMO-SEATS. This test is has been designed for a Blackman-Tukey window based on a particular choices of the truncation lag \\(r\\) and sample size. Following this approach, we determine visually significant peaks for a frequency \\(\\omega_{j}\\) when\n\\[\n\\frac{2 f_{x}(\\omega_{j})}{[f_{x}(\\omega_{j+1})+ f_{x}(\\omega_{j-1})]} \\ge CV(\\omega_{j})\n\\]\nwhere \\(CV(\\omega_{j})\\) is the critical value of a \\(F(d_{1},d_{2})\\) distribution, where the degrees of freedom are determined using simulations. For \\(\\omega_{j}=\\pi\\), we have a significant peak when \\(\\frac{f_{x}(\\omega_{[n/2]})}{[f_{x}(\\omega_{[(n-1)/2]})]} \\ge CV(\\omega_{j})\\)\nTwo significant levels for this test are considered: \\(\\alpha=0.05\\) (code “t”) and \\(\\alpha=0.01\\) (code “T”).\nAs opposed to the AR spectrum test, which is computed on the basis of the last \\(120\\) data points, we will use here all available observations. Those critical values have been calculated given the recommended truncation lag \\(r=79\\) for a sample size within the interval \\(\\in [80,119]\\) and \\(r=112\\) for \\(n \\in [120,300]\\) . The \\(F\\) approximation is less accurate for sample sizes larger than \\(300\\). For quarterly data, \\(r=44\\), but there are no recommendations regarding the required sample size.\nPractical implementation in GUI is detailed here\n\n\nIn AR Spectrum definition\nThe estimator of the spectral density at frequency \\(\\lambda \\in [0,\\pi]\\) will be given by the assumption that the series will follow an AR(p) process with large \\(p\\). The spectral density of such model, with an innovation variance \\(var(x_{t})=\\sigma^2_x\\), is expressed as follows:\n\\[\n10\\times log_{10} f_x(\\lambda)=10\\times log_{10} \\frac{\\sigma^2_x}{2\\pi |\\phi(e^{i\\lambda})|^2 }=10\\times log_{10} \\frac{\\sigma^2_x}{2\\pi |1-\\sum_{k=1}^{p}\\phi_k e^{i k \\lambda})|^2 }\n\\]\nwhere:\n\n\\(\\phi_k\\) denotes the AR(k) coefficient ;\n\\(e^{-ik\\lambda}=cos⁡(-ik\\lambda)+i sin⁡(-ik\\lambda)\\).\n\nSoukup and Findely (1999) suggest the use of p=30, which in practice much larger than the order that would result from the AIC criterion. The minimum number of observations needed to compute the spectrum is set to n=80 for monthly data (or n=60) for quarterly series. In turn, the maximum number of observations considered for the estimation is n=121. This choice offers enough resolution, being able to identify a maximum of 30 peaks in a plot of 61 frequencies: by choosing \\(\\lambda_j=\\pi j/60\\),for \\(j=0,1,…,60\\), we are able to calculate our density estimates at exact seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year). Note that \\(x\\) cycles per year can be converted into cycles per month by simply dividing by twelve, \\(x/12\\), and to radians by applying the transformation \\(2\\pi(x/12)\\).\nThe traditional trading day frequency corresponding to 0.348 cycles per month is used in place of the closest frequency \\(\\pi j/60\\). Thus, we replace \\(\\pi 42/60\\) by \\(\\lambda_{42}=0.348\\times 2 \\pi=2.1865\\). The frequencies neighbouring \\(\\lambda_{42}\\) are set to \\(\\lambda_{41}=2.1865-1/60\\) and \\(\\lambda_{43}=2.1865+1/60\\). The periodogram below illustrates the proximity of this trading day frequency \\(\\lambda_{42}\\) (red shade) and the frequency corresponding to 4 cycles per year \\(\\lambda_{40}=2.0944\\). This proximity is precisely what poses the identification problems: the AR spectrum boils down to a smoothed version of the periodogram and the contribution of the of the trading day frequency may be obscured by the leakage resulting from the potential seasonal peak at \\(\\lambda_{40}\\), and vice-versa.\n\n\n\nPeriodogram with seasonal (grey) and calendar (red) frequencies highlighted\n\n\nJDemetra+ allows the user to modify the number of lags of this estimator and to change the number of observations used to determine the AR parameters. These two options can improve the resolution of this estimator.\nThe statistical significance of the peaks associated to a given frequency can be informally tested using a visual criterion, which has proved to perform well in simulation experiments. Visually significant peaks for a frequency \\(\\lambda_{j}\\) satisfy both conditions:\n\n\\(\\frac{f_{x}(\\lambda_{j})-\\max \\{f_{x}(\\lambda_{j+1}),f_{x}(\\lambda_{j-1})\\}}{[\\max_{k}f_{x}(\\lambda_{k})-\\min_{i}f_{x}(\\lambda_{i})]}\\ge CV(\\lambda_{j})\\), where \\(CV(\\lambda_{j})\\) can be set equal to \\(6/52\\) for all \\(j\\)\n\\(f_{x}(\\lambda_{j})&gt; median_{j} \\{ f_{x}(\\lambda_{j})\\}\\), which guarantees \\(f_{x}(\\lambda_{j})\\) it is not a local peak.\n\nThe first condition implies that if we divide the range \\(\\max_{k}f_{x}(\\lambda_{k})-\\min_{i}f_{x}(\\lambda_{i})\\) in 52 parts (traditionally represented by stars) the height of each pick should be at least 6 stars.\nSeasonal and trading day frequencies by time series frequency\n\n\n\n\n\n\n\n\nNumber of months per full period\nSeasonal frequency\nTrading day frequency (radians)\n\n\n\n\n12\n\\(\\frac{\\pi}{6},\\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\frac{2\\pi}{3},\\ \\frac{5\\pi}{6},\\ \\pi\\)\n\\(d\\), 2.714\n\n\n6\n\\(\\frac{\\pi}{3},\\frac{2\\pi}{3}\\), \\(\\pi\\)\n\\(d\\)\n\n\n4\n\\(\\frac{\\pi}{2}\\), \\(\\pi\\)\n\\(d\\), 1.292, 1.850, 2.128\n\n\n3\n\\(\\pi\\)\n\\(d\\)\n\n\n2\n\\(\\pi\\)\n\\(d\\)\n\n\n\nCurrently, only seasonal frequencies are tested, but the program allows you to manually plot the AR spectrum and focus your attention on both seasonal and trading day frequencies. Agustin Maravall has conducted a simulation experiment to calculate \\(CV(\\lambda_{42})\\) (trading day frequency) and proposes to set for all \\(j\\) equal to the critical value associated to the trading frequency, but this is currently not part of the current automatic testing procedure of JDemetra+.\nPractical implementation in GUI is detailed here\n\n\nIn a Periodogram\nThe periodogram \\(I(\\omega_j)\\) of \\(\\mathbf{X} \\in \\mathbb{C}^n\\) is defined as the squared of the Fourier transform\n\\[\nI(\\omega_{j})=a_{j}^{2}=n^{-1}|\\sum_{t=1}^{n}\\mathbf{X_t} e^{-it\\omega_j}|^{2},\n\\]\nwhere the Fourier frequencies \\(\\omega_{j}\\) are given by multiples of the fundamental frequency \\(\\frac{2\\pi}{n}\\):\n\\[\n\\omega_{j}=\\frac{2\\pi j}{n},-\\pi &lt; \\omega_{j} \\leq \\pi\n\\]\nAn orthonormal basis in \\(\\mathbb{R}^n\\):\n\\[\n\\{ e_0, ~~~~~~c_1, s_1, ~~~~~\\ldots~~~~~\\ , ~~~~c_{[(n-1)/2]}, s_{[(n-1)/2]}~~~~,~~~~~~ e_{n/2} \\},\n\\]\nwhere \\(e_{n/2}\\) is excluded if \\(n\\) is odd,\ncan be used to project the data and obtain the spectral decomposition\nThus, the periodogram is given by the projection coefficients and represents the contribution of the jth harmonic to the total sum of squares, as illustrated by Brockwell and Davis (1991):\n\n\n\nSource\nDegrees of freedom\n\n\n\n\nFrequency \\(\\omega_{0}\\)\n1\n\n\nFrequency \\(\\omega_{1}\\)\n2\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\nFrequency \\(\\omega_{k}\\)\n2\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\nFrequency \\(\\omega_{n/2}=\\pi\\)\n1\n\n\n(excluded if \\(n\\) is odd)\n\n\n\n\\(=========\\)\n\\(======\\)\n\n\nTotal\nn\n\n\n\n\\[\n~~~~\n\\]\nIn JDemetra+, the periodogram of \\(\\mathbf{X} \\in \\mathbb{R}^n\\) is computed for the standardized time series.\n\nDefining a F-test\nBrockwell and Davis (1991, section 10.2) exploit the fact that the periodogram can be expressed as the projection on the orthonormal basis defined above to derive a test. Thus, under the null hypothesis:\n\n\\(2I(\\omega_{k})=\\|P_{\\bar{sp}_{\\{ c_{k},s_{k}\\}}} \\mathbf{X} \\|^{2} \\sim \\sigma^{2} \\chi^{2}(2)\\), for Fourier frequencies \\(0 &lt; \\omega_{k}=2\\pi k/n &lt; \\pi\\)\n\\(I(\\pi)=\\|P_{\\bar{sp}_{\\{ e_{n/2}\\}}} \\mathbf{X} \\|^{2} \\sim \\sigma^{2} \\chi^{2}(1)\\), for \\(\\pi\\)\n\nBecause \\(I(\\omega_{k})\\) is independent from the projection error sum of squares, we can define our F-test statistic as follows:\n\n\\(\\frac{ 2I(\\omega_{k})}{\\|\\mathbf{X}-P_{\\bar{sp}_{\\{ e_0,c_{k},s_{k}\\}}} \\mathbf{X}\\|^2} \\frac{n-3}{2} \\sim F(2,n-3)\\), for Fourier frequencies \\(0 &lt; \\omega_{k}=2\\pi k/n &lt; \\pi\\)\n\\(\\frac{ I(\\pi)}{\\|\\mathbf{X}-P_{\\bar{sp}_{\\{ e_0,e_{n/2}\\}}} \\mathbf{X}\\|^2} \\frac{n-2}{1} \\sim F(1,n-2)\\), for \\(\\pi\\)\n\nwhere:\n-\\(\\|\\mathbf{X}-P_{\\bar{sp}_{\\{ e_0,c_{k},s_{k}\\}}} \\mathbf{X}\\|^2=\\sum_{i=1}^{n}\\mathbf{X^2_i}-I(0)-2I(\\omega_{k}) \\sim \\sigma^{2} \\chi^{2}(n-3)\\) for Fourier frequencies \\(0 &lt; \\omega_{k}=2\\pi k/n &lt; \\pi\\)\n-\\(\\|\\mathbf{X}-P_{\\bar{sp}_{\\{ e_0,e_{n/2}\\}}} \\mathbf{X}\\|^2=\\sum_{i=1}^{n}\\mathbf{X^2_i}-I(0)-I(\\pi) \\sim \\sigma^{2} \\chi^{2}(n-2)\\) for \\(\\pi\\)\nThus, we reject the null if our F-test statistic computed at a given seasonal frequency (different from \\(\\pi\\)) is larger than \\(F_{1-α}(2,n-3)\\). If we consider \\(\\pi\\), our test statistic follows a \\(F_{1-α}(1,n-2)\\) distribution.\nThe implementation of JDemetra+ considers simultaneously the whole set of seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year). Thus, the resulting test-statistic is:\n\\[\n\\frac{ 2I(\\pi/6)+ 2I(\\pi/3)+ 2I(2\\pi/3)+ 2I(5\\pi/6)+ \\delta I(\\pi)}{\\|\\mathbf{X}-P_{\\bar{sp}_{\\{ e_0,c_{1},s_{1},c_{2},s_{2},c_{3},s_{3},c_{4},s_{4},c_{5},s_{5}, \\delta e_{n/2}\\}}} \\mathbf{X}\\|^2} \\frac{n-12}{11} \\sim F(11-\\delta,n-12+\\delta)\n\\]\nwhere \\(\\delta=1\\) if \\(n\\) is even and 0 otherwise.\nIn small samples, the test performs better when the periodogram is evaluated as the exact seasonal frequencies. JDemetra+ modifies the sample size to ensure the seasonal frequencies belong to the set of Fourier frequencies. This strategy provides a very simple and effective way to eliminate the leakage problem.\nPractical implementation in GUI is detailed here"
  },
  {
    "objectID": "M-spectral-analysis.html#m-spectral-analysis-m-spectrum-graphs",
    "href": "M-spectral-analysis.html#m-spectral-analysis-m-spectrum-graphs",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Spectral graphs",
    "text": "Spectral graphs\nThe section below provides guidance on interpretation of spectral graphs, the display of which in the Graphical User Interface can be found here\nThe interpretation of the spectral graph is rather straightforward. When the values of a spectral graph for low frequencies (i.e. one year and more) are large in relation to its other values it means that the long-term movements dominate in the series. When the values of a spectral graph for high frequencies (i.e. below one year) are large in relation to its other values it means that the series are rather trendless and contains a lot of noise. When the values of a spectral graph are distributed randomly around a constant without any visible peaks, then it is highly probable that the series is a random process. The presence of seasonality in a time series is manifested in a spectral graph by the peaks on the seasonal frequencies."
  },
  {
    "objectID": "M-reg-arima-modelling.html#overview",
    "href": "M-reg-arima-modelling.html#overview",
    "title": "Reg-Arima models",
    "section": "Overview",
    "text": "Overview\nThe primary aim of seasonal adjustment is to remove the unobservable seasonal component from the observed series. The decomposition routines implemented in the seasonal adjustment methods make specific assumptions concerning the input series. One of the crucial assumptions is that the input series is stochastic, i.e. it is clean of deterministic effects. Another important limitation derives from the symmetric linear filter used in TRAMO-SEATS and X-13ARIMA-SEATS. A symmetric linear filter cannot be applied to the first and last observations with the same set of weights as for the central observations[^1]. Therefore, for the most recent observations these filters provide estimates that are subject to revisions.\nTo overcome these constrains both seasonal adjustment methods discussed here include a modelling step that aims to analyse the time series development and provide a better input for decomposition purposes. The tool that is frequently used for this purpose is the ARIMA model, as discussed by BOX, G.E.P., and JENKINS, G.M. (1970). However, time series are often affected by the outliers, other deterministic effects and missing observations. The presence of these effects is not in line with the ARIMA model assumptions. The presence of outliers and other deterministic effects impede the identification of an optimal ARIMA model due to the important bias in the estimation of parameters of sample autocorrelation functions (both global and partial)[^3]. Therefore, the original series need to be corrected for any deterministic effects and missing observations. This process is called linearisation and results in the stochastic series that can be modelled by ARIMA.\nFor this purpose both TRAMO and Reg-ARIMA use regression models with ARIMA errors. With these models TRAMO and Reg-ARIMA also produce forecasts."
  },
  {
    "objectID": "M-X11-decomposition.html#m-X11-intro",
    "href": "M-X11-decomposition.html#m-X11-intro",
    "title": "X11 decomposition",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter provides details on - algorithm steps - computation stages and detailed output series - quality measures - filter length choices - extreme values correction\nThe practical implementation as well as all the options, using the graphical user interface or R packages are described in this chapter\nref to add: the X11 method"
  },
  {
    "objectID": "M-X11-decomposition.html#m-X11-ma",
    "href": "M-X11-decomposition.html#m-X11-ma",
    "title": "X11 decomposition",
    "section": "Moving averages in X11",
    "text": "Moving averages in X11\nMoving averages (MA) are the building blocks of X11. They will be used successively to accomplish three goals:\n- removing seasonality \n\n- extracting seasonality \n\n- estimating Trend on non seasonal series\nThe type of MA used for each of these tasks and the computation steps are described in the sections below.\n\nDefinitions\nA moving average of order \\(p+f+1\\) and coefficients \\((\\theta_i)\\) is the operator \\(M\\) defined as: \\[\nMX_t = \\sum_{i=-p}^{f}\\theta_i X_{t+i}\n\\]\nThe series value in \\(t\\) is replaced by a weighted average of \\(p\\) past values, the current value and the \\(f\\) future values. If \\(p=f\\), the moving average is centered and if \\(\\theta_{-i} = \\theta_i\\), it is symmetrical.\nExample of simple moving average of order 3:\n\\[\nMX_t = \\frac{1}{3}(X_{t-1}+X_{t}+ X_{t+1})\n\\]\nA moving average is a linear operator, \\(M(X_t+Y_t) = M(X_t)+M(Y_t)\\).\n\n\nCombined moving averages\nCentred and symmetrical moving averages preserve linear trends, which is a desirable propriety. They cannot have an even order, thus for even orders they are obtained by combining simple moving averages as arithmetic means of p moving averages of the same order (ie. length): \\(M_{p\\times order}\\)\nCombination example for order 12:\nThere are two intuitive ways to create a Moving Average of order 12:\n\\[\nM1X_t = \\frac{1}{12}(X_{t-6}+X_{t-5}+ X_{t-4}+ X_{t-3}+ X_{t-2}+ X_{t-1}\n\\] \\[\n+ X_{t}+ X_{t+1}+ X_{t+2}+ X_{t+3}+ X_{t+4}+X_{t+5})\n\\] The other being: \\[\nM2X_t = \\frac{1}{12}(X_{t-5}+ X_{t-4}+ X_{t-3}+ X_{t-2}+ X_{t-1}+ X_{t}\n\\] \\[\n+ X_{t+1}+ X_{t+2}+ X_{t+3}+ X_{t+4}+X_{t+5}+X_{t+6})\n\\]\nA centred and symmetrical MA with an even order (here 12) can be created:\n\\[\nM_{2\\times 12}= \\frac{1}{2}(M1X_t+M2X_t)\n\\] which is:\n\\[\nM_{2\\times 12} =\\frac{1}{24}(X_{t-6}) +\\frac{1}{12}(X_{t-5}+ X_{t-4}\n\\] \\[\n+X_{t-3}+ X_{t-2}+ X_{t-1}+ X_{t}+X_{t+1}+ X_{t+2}\n\\] \\[\n+ X_{t+3}+ X_{t+4}+X_{t+5})+\\frac{1}{24}(X_{t+6})\n\\]\n\n\nSupressing locally constant seasonality\nApplying a moving average of an order equal to the periodicity of the raw series removes a locally stable seasonality (\\(\\sum_{i=1}^{12}S_{t+i} = 0\\))\nA moving average of order, 12 will remove a locally stable monthly seasonality: \\(M_{1\\times 12}(S)=0\\) and also \\(M_{2\\times 12}(S)=0\\) with linear trend preservation."
  },
  {
    "objectID": "M-X11-decomposition.html#X11-steps",
    "href": "M-X11-decomposition.html#X11-steps",
    "title": "X11 decomposition",
    "section": "X11 algorithm steps",
    "text": "X11 algorithm steps\nThe X11 decomposition algorithm has eight main steps, outlined below for a monthly time series. (For a quarterly time series a \\(2\\times 4\\) moving average would be used, instead of \\(2\\times 12\\))\nStep 1: Estimation of the trend-cycle with a \\(2\\times 12\\) MA \\[\nTC_t^{(1)}=M_{2\\times 12}(X_t)\n\\]\nStep 2: Estimation of the seasonal+irregular component \\[\n(S_t+I_t)^{(1)}= X_t - TC_t^{(1)}\n\\]\nStep 3: Estimation of the seasonal component by applying a \\(3\\times 3\\) MA to each month \\[\nS_t^{(1)}= M_{3\\times 3}\\left[(S_t+I_t)^{(1)}\\right]\n\\text{ and normalisation }\nSnorm_t^{(1)}=S_t^{(1)} - M_{2\\times 12}\\left(S_t^{(1)}\\right)\n\\]\nStep 4: First estimation of the seasonally adjusted series \\[\nXsa_t^{(1)}= (TC_t+I_t)^{(1)} = X_t-Snorm_t^{(1)}\n\\]\nStep 5: Refined estimation of the trend-cycle with a Henderson filter, which yields a better approximation fo trends than \\(2\\times 12\\) MA, but cannot be applied on a seasonal series \\[\nTC_t^{(2)}=H_{13}(Xsa_t^{(1)})\n\\] Step 6: Refined estimation of the seasonal+irregular part \\[\n(S_t+I_t)^{(2)}= X_t - TC_t^{(2)}\n\\]\nStep 7: Refined estimation of the seasonal component by applying a \\(3\\times 5\\) MA (generally) to each month/quarter \\[\nS_t^{(2)}= M_{3\\times 5}\\left[(S_t+I_t)^{(2)}\\right]\n\\text{ and normalisation }\nSnorm_t^{(2)}=S_t^{(2)} - M_{2\\times 12}\\left(S_t^{(2)}\\right)\n\\]\nStep 8: Final estimation of the seasonally adjusted series \\[\nXsa_t^{(2)}= X_t - Snorm_t^{(2)}\n\\]"
  },
  {
    "objectID": "M-X11-decomposition.html#m-X11-stages-output",
    "href": "M-X11-decomposition.html#m-X11-stages-output",
    "title": "X11 decomposition",
    "section": "Processing stages and output",
    "text": "Processing stages and output\nTo evaluate the different components of a series, while taking into account the possible presence of extreme observations, X11 will proceed iteratively: - estimation of components - search for disruptive effects in the irregular component - estimation of components over a corrected series - search for disruptive effects in the irregular component - …\nThe steps described above will be run six times, at least.\nThe algorithm is split into\n\nfour processing stages called A, B, C and D\ntwo diagnostics parts: E tables and Quality Measures (Summary and Detailed )\n\n\n\n\nStage A: Pre-adjustment\nIf a pre-treatment is performed using X-13-Arima algorithm is A step is not used, results in A table appearing in JDemetra+ output are a copy of pre-treatment results.\nDetailed series produced at the end of stage A, including estimated effect from the Reg-Arima part\n(to be checked: v2 vs v3 display, in GUI and R, here info based on v2)\n\nTable A1: Original raw series;\nTable A1a: Forecast of Original Series;\nTable A2: Leap year effect;\nTable A6: Trading Day effect (1 or 6 variables);\nTable A7: The Easter effect;\nTable A8: Total Outlier Effect;\nTable A8i: Additive outlier effect;\nTable A8t: Level shift effect;\nTable A8s: Transitory effect;\nTable A9: Effect of user-defined regression variables assigned to the seasonally adjusted series or for which the component has not been defined;\nTable 9sa: Effect of user-defined regression variables assigned to the seasonally adjusted series;\nTable9u: Effect of user-defined regression variables for which the component has not been defined.\n\n\n\nStage B: First automatic correction of the series\nThis stage consists of a first estimation and down-weighting of extreme observations. This stage is performed by applying twice the algorithm steps outlined above. It starts with the linearised or raw series copied in table B1 lead to table B20, containing adjustment values for extreme observations. B1 corrected with weights from B20 allows to compute the series C1 which will start the next stage.\nDetailed series produced at the end of stage B:\n\nTable B1: Original series after adjustment by the Reg-ARIMA model;\nTable B2: Unmodified Trend (preliminary estimation using composite moving average);\nTable B3: Unmodified Seasonal: Irregular Component (preliminary estimation);\nTable B4: Replacement Values for Extreme SI Values;\nTable B5: Seasonal Component;\nTable B6: Seasonally Adjusted Series;\nTable B7: Trend (estimation using Henderson moving average);\nTable B8: Unmodified Seasonal: Irregular Component;\nTable B9: Replacement Values for Extreme SI Values;\nTable B10: Seasonal Component;\nTable B11: Seasonally Adjusted Series;\nTable B13: Irregular Component;\nTable B17: Preliminary Weights for the Irregular;\nTable B20: Adjustment Values for the original series B1, allow to compute C1.\n\n(Up coming here: computation steps from B1 to B20)\n\n\nStage C: Second automatic correction of the series**\nFollowing the same steps as Stage B, this stage leads to table C20, which allows to compute the final “cleaned up” series shown in D1.\nDetailed series produced at the end of stage C:\n\nTable C1: Modified Raw Series;\nTable C2: Trend (preliminary estimation using composite moving average);\nTable C4: Modified Seasonal: Irregular Component;\nTable C5: Seasonal Component;\nTable C6: Seasonally Adjusted Series;\nTable C7: Trend (estimation using Henderson moving average);\nTable C9: Seasonal: Irregular Component;\nTable C10: Seasonal Component;\nTable C11: Seasonally Adjusted Series;\nTable C13: Irregular Component;\nTable C20: Adjustment Values for the original series B1, allow to compute D1.\n\n(To be checked: C20 weights will be applied to B1 not C1)\n(Up coming here: computation steps from C1 to C20)\n\n\nStage D: Final decomposition and seasonal adjustment\nIn this part, all algorithm steps are applied one last time, finally leading to the computation of the final components\nDetailed series produced at the end of stage D:\n\nTable D1: Modified Raw Series;\nTable D2: Trend (preliminary estimation using composite moving average);\nTable D4: Modified Seasonal: Irregular Component;\nTable D5: Seasonal Component;\nTable D6: Seasonally Adjusted Series;\nTable D7: Trend (estimation using Henderson moving average);\nTable D8: Unmodified Seasonal: Irregular Component;\nTable D9: Replacement Values for Extreme SI Values;\nTable D10: Final Seasonal Factors;\nTable D10A: Forecast of Final Seasonal Factors;\nTable D11: Final Seasonally Adjusted Series;\nTable D11A: Forecast of Final Seasonally Adjusted Series;\nTable D12: Final Trend (estimation using Henderson moving average);\nTable D12A: Forecast of Final Trend Component;\nTable D13: Final Irregular Component;\nTable D16: Seasonal and Calendar Effects;\nTable D16A: Forecast of Seasonal and Calendar Component;\nTable D18: Combined Calendar Effects Factors.\n\nAll final components include pre-adjustment effects stemming from outliers or regressors used in the pre-treatment step. (to be checked: v2 vs v3,here info based on v2)\nD10 doesn’t contain calendar effects which are added in D16.\n(Up coming here: computation steps from D1 to D20)\n\n\nStage E: Components modified for large extreme values\nIn this part, additional series will are computed and used in the Quality Measures part\nDetailed series produced at the end of stage E:\n\nTable E1: Raw Series Modified for Large Extreme Values\nTable E2: SA Series Modified for Large Extreme Values\nTable E3: Final Irregular Component Adjusted for Large Extreme Values\nTable E11: Robust Estimation of the Final SA Series\n\n(Up coming here: computation steps for E Tables)"
  },
  {
    "objectID": "M-X11-decomposition.html#m-X11-qm",
    "href": "M-X11-decomposition.html#m-X11-qm",
    "title": "X11 decomposition",
    "section": "Quality Measures",
    "text": "Quality Measures\nAll the diagnostics below can be displayed in the GUI by expanding the NODES\nDecomposition(X11) &gt; Quality Measures &gt; Summary\nDecomposition(X11) &gt; Quality Measures &gt; Details\n\nM-statisctics\nM statistics are specific quality measures (ref: Lothian and Mory (1979))\n\n\\(0&lt;M_x&lt;3\\), acceptance region \\(M_x \\leq 1\\)\n11 statistics of the decomposition quality (M1 to M11) and 2 summary indicators (Q et Q-M2)\n\nDetailed description:\n\n\\(M1\\) measures the contribution of the irregular component to the total variance. When it is above 1 some changes in outlier correction should be considered.\n\\(M2\\), which is a very similar to \\(M1\\), is calculated on the basis of the contribution of the irregular component to the stationary portion of the variance. When it is above 1, some changes in an outlier correction should be considered.\n\\(M3\\) compares the irregular to the trend taken from a preliminary estimate of the seasonally adjusted series. If this ratio is too large, it is difficult to separate the two components from each other. When it is above 1 some changes in outlier correction should be considered.\n\\(M4\\) tests the randomness of the irregular component. A value above 1 denotes a correlation in the irregular component. In such case a shorter seasonal moving average filter should be considered.\n\\(M5\\) is used to compare the significance of changes in the trend with that in the irregular. When it is above 1 some changes in outlier correction should be considered.\n\\(M6\\) checks the \\(\\text{SI}\\) (seasonal: irregular components ratio). If annual changes in the irregular component are too small in relation to the annual changes in the seasonal component, the \\(3 \\times 5\\) seasonal filter used for the estimation of the seasonal component is not flexible enough to follow the seasonal movement. In such case a longer seasonal moving average filter should be considered. It should be stressed that \\(M6\\) is calculated only if the \\(3 \\times 5\\) filter has been applied in the model.\n\\(M7\\) is the combined test for the presence of an identifiable seasonality. The test compares the relative contribution of stable and moving seasonality[^m-X11-decomposition-2].\n\\(M8\\) to \\(M11\\) measure if the movements due to the short-term quasi-random variations and movements due to the long-term changes are not changing too much over the years. If the changes are too strong then the seasonal factors could be erroneous. In such case a correction for a seasonal break or the change of the seasonal filter should be considered.\n\nThe \\(Q\\) statistic is a composite indicator calculated from the \\(M\\) statistics.\n\\[\n\\small\nQ = \\frac{10M1 + 11M2 + 10M3 + 8M4 + 11M5 + 10M6 + 18M7 + 7M8 + 7M9 + 4M10 + 4M11}{100}\n\\]\n\\(Q = Q - M2\\) (also called \\(Q2\\)) is the \\(Q\\) statistic for which the \\(M2\\) statistics was excluded from the formula, i.e.:\n\\[\n\\small\nQ - M2 = \\frac{10M1 + 10M3 + 8M4 + 11M5 + 10M6 + 18M7 + 7M8 + 7M9 + 4M10 + 4M11}{89}\n\\]\nIf a time series does not cover at least 6 years, the \\(M8\\), \\(M9\\), \\(M10\\) and \\(M11\\) statistics cannot be calculated. In this case the \\(Q\\) statistic is computed as:\n\\[\n\\small\nQ = \\frac{14M1 + 15M2 + 10M3 + 8M4 + 11M5 + 10M6 + 32M7}{100}\n\\]\n\n\nDetailed Quality measures\n\nAverage percent change (or Average differences) without regard to sign over the indicated span\nThe first table presents the average percent change without regard to sign of the percent changes (multiplicative model) or average differences (additive model) over several periods (from 1 to 12 for a monthly series, from 1 to 4 for a quarterly series) for the following series:\n\n\\(O\\): Original series (Table A1);\n\\(\\text{CI}\\): Final seasonally adjusted series (Table D11);\n\\(I\\): Final irregular component (Table D13);\n\\(C\\): Final trend (Table D12);\n\\(S\\): Final seasonal factors (Table D10);\n\\(P\\): Preliminary adjustment coefficients, i.e. regressors estimated by the Reg-Arima model (Table A2);\n\\(TD\\& H\\): Final calendar component (Tables A6 and A7);\n\\(\\text{Mod.O}\\): Original series adjusted for extreme values (Table E1);\n\\(\\text{Mod.CI}\\): Final seasonally adjusted series corrected for extreme values (Table E2);\n\\(\\text{Mod.I}\\): Final irregular component adjusted for extreme values (Table E3).\n\nIn the case of an additive decomposition, for each component the average absolute changes over several periods are calculated as:\n\\[\n\\text{Component}_{d} = \\frac{1}{n - d}\\sum_{t = d + 1}^{n}|Table_{t} - Table_{t - d}|\n\\]\nwhere:\n\\(d\\): time lag in periods (from a monthly time series \\(d\\) varies from to 4 or from 1 to 12);\n\\(n\\): total number of observations per period;\n\\(\\text{Component}\\): the name of the component;\n\\(\\text{Table}\\): the name of the table that corresponds to the component.\n\nFor the multiplicative decomposition the following formula is used:\n\\[\n\\text{Component}_{d} = \\frac{1}{n - d}\\sum_{t = d+1}^{n}{|\\frac{\\text{Tabl}e_{t}}{\\text{Table}_{t - d}} - 1|}\n\\] .\n\n\nRelative contribution to the variance of the differences in the components of the original series\nRelative contributions of the different components to the differences (additive model) or percent changes (multiplicative model) in the original series is displayed express the relative importance of the changes in each component. Assuming that the components are independent, the following relation is valid:\n\\[\nO_{d}^{2} \\approx C_{d}^{2} + S_{d}^{2} + I_{d}^{2} + P_{d}^{2} + {TD\\& H}_{d}^{2}\n\\]\nIn order to simplify the analysis, the approximation can be replaced by the following equation:\n\\[\nO_{d}^{*2} = C_{d}^{2} + S_{d}^{2} + I_{d}^{2} + P_{d}^{2} + {TD\\& H}_{d}^{2}\n\\]\nThe column \\(\\text{Total}\\) denotes total changes in the raw time series.\nData presented in Table F2B indicate the relative contribution of each component to the percent changes (differences) in the original series over each span, and are calculated as:\n\\(\\frac{I_{d}^{2}}{O_{d}^{*2}}\\), \\(\\frac{C_{d}^{2}}{O_{d}^{*2}}\\), \\(\\frac{S_{d}^{2}}{O_{d}^{*2}}\\), \\(\\frac{P_{d}^{2}}{O_{d}^{*2}}\\) and \\(\\frac{TD\\& H_{d}^{2}}{O_{d}^{*2}}\\) where: \\(O_{d}^{*2} = I_{d}^{2} + C_{d}^{2} + S_{d}^{2} + P_{d}^{2}{+ TD\\& H}_{d}^{2}\\).\nThe last column presents the Ratio calculated as: \\(100 \\times\\frac{O_{d}^{*2}}{O_{d}^{2}}\\), which is an indicator of how well the approximation \\({(O_{d}^{*})}^{2} \\approx O_{d}^{2}\\) holds.\n\n\n\nAverage differences with regard to sign and standard deviation over indicated span\nWhen an additive decomposition is used, Table F2C presents the average and standard deviation of changes calculated for each time lag \\(d\\), taking into consideration the sign of the changes of the raw series and its components. In case of a multiplicative decomposition the respective table shows the average percent differences and related standard deviations.\n\n\n\nAverage duration of run\nAverage duration of run is an average number of consecutive monthly (or quarterly) changes in the same direction (no change is counted as a change in the same direction as the preceding change). JDemetra+ displays this indicator for the seasonally adjusted series, for the trend and for the irregular component.\n\n\n\nAverage duration of run\n\n\n\n\nI/C ratio over indicated span and global\nThe \\(\\frac{I}{C}\\) ratios for each value of time lag \\(d\\), presented in Table F2E, are computed on a basis of the data in Table F2A. Global IC is displayed below the table\n\n\n\nI/C ratio\n\n\n\n\nRelative contribution to the stationary part of the variance in the original series\nThe relative contribution of components to the variance of the stationary part of the original series is calculated for the irregular component (\\(I\\)), trend made stationary (\\(C\\)), seasonal component (\\(S\\)) and calendar effects (TD&H).\nThe trend is made stationary by by extracting a linear trend from the trend component presented in Table D12.\n\n\n\nRelative contribution to the stationary part of the variance in the original series\n\n\n\n\nAutocorrelations in the irregular\nThe last table shows the autocorrelogram of the irregular component from Table D13. In the case of multiplicative decomposition it is calculated for time lags between 1 and the number of periods per year +2 using the formula:\n\\[\n\\text{Corr}_{k}I = \\frac{\\sum_{t = k + 1}^{N}{(I_{t} - 1)(I_{t - k} - 1)}}{\\sum_{t = 1}^{N}{(I_{t} - 1)}^{2}}\n\\]\nwhere \\(N\\) is number of observations in the time series and \\(k\\) the lag.\nFor the additive decomposition the formula is:\n\\[\nCorr_{k}I_{t} = \\frac{\\sum_{t = k + 1}^{N}{(I_{t} \\times I_{t - k})}}{\\sum_{t = 1}^{N}{(I_{t})}^{2}}\n\\]\n\n\n\nAutocorrelations in the irregular\n\n\n\n\nHeteroskedasticity\nA Cochran test on equal variances within each period is performed in the extreme value detection procedure to check if the irregular component is heteroskedastic. In this procedure the standard errors of the irregular component are used for an identification of extreme values. If the null hypothesis (for all the periods (months, quarters) the variances of the irregular component are identical) is rejected, the standard errors will be computed separately for each period. This will happen only if in the option Calendarsigma=signif has been selected.\n\n\n\nHeteroskedasticity\n\n\n\n\nMoving seasonality ratios (MSR)\nFor each \\(i^{\\text{th}}\\) month we will be looking at the mean annual changes for each component by calculating:\n\\[\n{\\overline{S}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}|S_{i,t} - S_{i,t - 1}|\n\\]\nand\n\\[\n{\\overline{I}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}| I_{i,t} - I_{i,t - 1}|\n\\]\nwhere \\(N_{i}\\) refers to the number of months \\(\\text{i}\\) in the data, and the moving seasonality ratio of month \\(i\\):\n\\[\nMSR_{i} = \\frac{\\overline{I}_{i}}{\\overline{S}_{i}}\n\\]\nThe Moving Seasonality Ratio (MSR) is used to measure the amount of noise in the Seasonal-Irregular component. By studying these values, the user can select for each period the seasonal filter that is the most suitable given the noisiness of the series.\n\n\n\nText"
  },
  {
    "objectID": "M-X11-decomposition.html#m-X11-filters-length-choice",
    "href": "M-X11-decomposition.html#m-X11-filters-length-choice",
    "title": "X11 decomposition",
    "section": "Filter length choice",
    "text": "Filter length choice\n\nTrend estimation with Henderson Moving average\nIn iteration B (Table B7), iteration C (Table C7) and iteration D (Table D7 and Table D12) the trend component is extracted from an estimate of the seasonally adjusted series using Henderson moving averages.\nThe algorithm chooses between different filter lengths automatically according to the \\(I/C\\) ratio, the user can modify this choice (first step is computed with \\(H_{13}\\))\n\n\n\nText\n\n\n\n\nSeasonality extraction filters\nIn iteration D, Table D10 shows an estimate of the seasonal factors implemented on the basis of the modified SI (Seasonal: Irregular) factors estimated in Tables D4 and D9bis. This component will have to be smoothed to estimate the seasonal component; depending on the importance of the irregular in the SI component\n\nStep 1: Estimating the irregular and seasonal components\nAn estimate of the seasonal component is obtained by smoothing, month by month and therefore column by column, Table D9bis using a simple 7-term moving average, i.e. of coefficients \\(\\frac{1}{7} \\left\\{1,\\ 1,\\ 1,\\ 1,\\ 1,\\ 1,\\ 1\\right\\}\\). In order not to lose three points at the beginning and end of each column, all columns are completed as follows. Let us assume that the column that corresponds to the month is composed of \\(N\\) values \\(\\left\\{ x_{1},\\ x_{2},\\ x_{3},\\ \\ldots x_{N - 1},\\ x_{N} \\right\\}\\). It will be transformed into a series \\(\\left\\{ {x_{- 2},x_{- 1}{,x}_{0},x}_{1},\\ x_{2},\\ x_{3},\\ \\ldots x_{N - 1},\\ x_{N},x_{N + 1},\\ x_{N + 1},\\ x_{N + 2},\\ x_{N + 3} \\right\\}\\) with \\(x_{- 2} = x_{- 1} = x_{0} = \\frac{x_{1} + x_{2} + x_{3}}{3}\\) and \\(x_{N + 1} = x_{N + 2} = x_{N + 3} = \\frac{x_{N} + x_{N - 1} + x_{N - 2}}{3}\\). We then have the required estimates: \\(S = M_{7}(D9bis)\\) and \\(I = D9bis - S\\).\n\n\nStep 2: Calculating the Moving Seasonality Ratios\nFor each \\(i^{\\text{th}}\\) month the mean annual changes for each component is obtained by calculating\n\\[\n{\\overline{S}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}\\left| S_{i,t} - S_{i,t - 1} \\right|\n\\]\nand\n\\[\n{\\overline{I}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}\\left| I_{i,t} - I_{i,t - 1} \\right|\n\\]\nwhere \\(N_{i}\\) refers to the number of months \\(\\text{i}\\)in the data, and the moving seasonality ratio of month \\(i\\):\n\\[\nMSR_{i} = \\frac{\\ {\\overline{I}}_{i}}{ {\\overline{S}}_{i}}\n\\]\nThese ratios are presented in Detailed Quality Measures\n\n\nStep 3: Calculating the overall Moving Seasonality Ratio\nThe overall Moving Seasonality Ratio is calculated as follows:\n\\[\n\\text{MSR}_{i} = \\frac{\\sum_{i}^{}{N_{i}\\ }\\ {\\overline{I}}_{i}}{\\sum_{i}^{}N_{i}{\\overline{S}}_{i}}\n\\]\n\n\nStep 4: Selecting a moving average and estimating the seasonal\ncomponent\nDepending on the value of the ratio, the program automatically selects a moving average that is applied, column by column (i.e. month by month) to the Seasonal/Irregular component in Table D8 modified, for extreme values, using values in Table D9.\nThe default selection procedure of a moving average is based on the Moving Seasonality Ratio in the following way:\n\nIf this ratio occurs within zone A (MSR &lt; 2.5), a \\(3 \\times 3\\) moving average is used; if it occurs within zone C (3.5 &lt; MSR &lt; 5.5), a \\(3 \\times 5\\) moving average is selected; if it occurs within zone E (MSR  6.5), a \\(3 \\times 9\\) moving average is used;\nIf the MSR occurs within zone B or D, one year of observations is removed from the end of the series, and the MSR is recalculated. If the ratio again occurs within zones B or D, we start over again, removing a maximum of five years of observations. If this does not work, i.e. if we are again within zones B or D, a \\(3 \\times 5\\) moving average is selected.\n\nThe chosen symmetric moving average corresponds, as the case may be 5 (\\(3 \\times 3\\)), 7 (\\(3 \\times 5\\)) or 11 (\\(3 \\times 9\\) \\(3 \\times 9\\)) terms, and therefore does not provide an estimate for the values of seasonal factors in the first 2 (or 3 or 5) and the last 2 (or 3 or 5) years. These are then calculated using associated asymmetric moving averages."
  },
  {
    "objectID": "M-X11-decomposition.html#X11-I-correc",
    "href": "M-X11-decomposition.html#X11-I-correc",
    "title": "X11 decomposition",
    "section": "Extreme values: identification and replacement",
    "text": "Extreme values: identification and replacement\nThough it is recommended rely on the pre-adjustment stage to correct for outliers (transparent method with explicit modelling), X11 has its own (historical) module for identification and treatment of extreme values based on a comparison between the actual and the theoretical value of \\(I\\).\nStages B and C aim only at correcting for extreme values and contain several iterations of the following steps.\nIf the irregular is heteroskedastic the standard deviations used for identifying outliers will be computed separately period by period or for distinct groups of several periods.\nStep 1: \\(I\\) is estimated once \\(S\\) has been extracted from \\(S+I\\)\n\nfor each year the standard deviation \\(\\sigma\\) is computed on the 5 neighbouring years\n\\(I\\) has a theoretical value \\(m\\), for multiplicative model \\(m=1\\), \\(m=0\\) for an additive model\nfor a given year \\(y\\): any point such as \\(\\lvert I_t - m\\rvert &gt;2,5 \\sigma_y\\) is considered as an extreme value and suppressed….\n…all the yearly sigmas (\\(\\sigma_y\\)) are computed without those points (more robust sigmas )\n\nStep 2: The distance \\(\\lvert I_t - m\\rvert\\) is computed for each point and evaluated with \\(\\sigma_{y}\\) as a benchmark, a weight \\(w_t\\) is then assigned to each point, 3 cases:\n\nvalue unchanged\n\n\\[\n\\lvert I_t - m\\rvert &lt;1.5 \\sigma_y \\Rightarrow  w_t=1\n\\]\n\nvalue downsized\n\n\\[\n1,5 \\sigma_y&lt;\\lvert I_t - m\\rvert &lt;2,5 \\sigma_y \\Rightarrow w_t=\\frac{2.5 \\sigma_y -\\lvert I_t - m\\rvert}{2.5 \\sigma_y-1.5 \\sigma_y}\n\\]\n\nvalue removed and replaced\n\n\\[\n\\lvert I_t - m\\rvert &gt;2,5 \\sigma_y \\Rightarrow w_t=0\n\\]\nStep3:\nUsing this weights, a new value of \\(S+I\\) will be computed:\n\nif \\(w_{t}=1\\), \\(S+I\\) remains unchanged for point {t}\nif \\(w_{t}&lt;1\\) then the new value of \\(S+I\\) will be an average of \\(w_{t}*(S+I)_{t}\\) and the values of \\((S+I)\\) of the two closest neighbours in the future and in the past with \\(w=1\\)"
  },
  {
    "objectID": "M-SEATS-decomposition.html#m-seats-intro",
    "href": "M-SEATS-decomposition.html#m-seats-intro",
    "title": "SEATS decomposition",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter provides details on seats algorithm steps - series](#m-seats-stages-output) - quality measures - filter length choices - extreme values correction\nThe practical implementation as well as all the options, using the graphical user interface or R packages are described in this chapter"
  },
  {
    "objectID": "M-SEATS-decomposition.html#seats-steps",
    "href": "M-SEATS-decomposition.html#seats-steps",
    "title": "SEATS decomposition",
    "section": "SEATS steps",
    "text": "SEATS steps\nSEATS decomposes the linearized series into trend, seasonal, transitory and irregular components, provides forecasts for these components, together with the associated standard errors, and finally assign the deterministic effects to each component yielding the final components.\n\nInput from Tramo\nIn JDemetra+ the input for the model based signal extraction procedure is always provided by TRAMO and includes the original series \\(y_{t}\\), the linearized series \\(x_{t}\\) (i.e. the original series \\(y_{t}\\) with the deterministic effects removed), the ARIMA model for the stochastic (linearized) time series \\(x_{t}\\) and the deterministic effects (calendar effects, outliers and other regression variable effects).\n\n\nARIMA modelling of the input series\nOne of the fundamental assumptions made by SEATS is that the linearized time series \\(x_{t}\\) follows the ARIMA model:\n\\[\n\\phi(B)\\delta(B)x_{t} = \\theta(B)a_{t}\n\\tag{1}\\]\nwhere:\n\n\\(B\\) – the backshift operator \\((Bx_{t} = x_{t - 1})\\);\n\\(\\delta(B)\\) – a non-stationary autoregressive (AR) polynomial in \\(B\\) (unit roots);\n\\(\\theta(B)\\) – an invertible moving average (MA) polynomial in \\(B\\) and in \\(B^{S}\\), which can be expressed in the multiplicative form \\((1 + \\vartheta_{1}B + \\ldots{+ \\ \\vartheta}{q}B^{q})(1 + \\Theta{1}B^{s} + \\ldots{+ \\ \\Theta}_{Q}B^{\\text{sQ}})\\) ;\n\\(phi(B)\\) – a stationary autoregressive (AR) polynomial in \\(B\\) and in \\(B^{S}\\) containing regular and seasonal unit roots, with s representing the number of observations per year;\n\\(a_{t}\\) – a white-noise variable with the variance\\(V(a)\\).\n\nIt should be noted that the stochastic time series can be predicted using its past observations and making an error. The variable \\(a_{t}\\), which is assumed to be white noise, is the fundamental innovation to the series at time t, that is the part that cannot be predicted based on the past history of the series.\nDenoting \\(\\varphi(B) = \\phi(B)\\delta(B)\\),can be written in a more concise form as\n\\[\n\\varphi(B)x_{t} = \\theta(B)a_{t}\n\\tag{2}\\]\nwhere \\(\\varphi(B)\\) contains both the stationary and the nonstationary roots.\n\n\nDerivation of the models for the components\nLet us consider the additive decomposition model\n\\[\nx_{t} = \\sum_{i = 1}^{k}x_{\\text{it}}\n\\tag{3}\\]\nwhere i refers to the orthogonal components: trend, seasonal, transitory or irregular. Apart from the irregular component, supposed to be a white noise, it is assumed that each component follows the ARIMA model which can be represented, using the notation of Equation 2 as:\n\\[\n\\varphi_{i}(B)\\ x_{\\text{it}} = \\theta_{i}(B)a_{\\text{it}}\n\\tag{4}\\]\nwhere\n\n\\(\\varphi_{i}(B) = \\phi_{i}(B)\\delta_{i}(B),...x_{\\text{it}}\\) is the i-th unobserved component,\n\\(\\varphi_{i}(B)\\) and \\(\\theta_{i}(B)\\) are finite polynomials of order \\(p_{i}\\) and \\(q_{i}\\), respectively,\n\\(a_{\\text{it}}\\), the disturbance associated with such component, is a white noise process with zero mean and constant variance \\(V(a_{i})\\) and \\(a_{\\text{it}}\\) and \\(a_{\\text{jt}}\\) are not correlated for \\(i \\neq j\\) and for any \\(t\\)..\n\nThese disturbances are functions of the innovations in the series and are called “pseudo-innovations” in the literature concerning the AMB decomposition as they refer to the components that are never observed In the JDemetra+ documentation the term “innovations” is used to refer to “pseudo-innovations”.(GÓMEZ, V., and MARAVALL, A. (2001a).\nThe following assumptions hold for Equation 4. For each \\(\\text{i}\\) the polynomials \\(\\phi_{i}(B)\\), \\(\\delta_{i}(B)\\) and \\(\\theta_{i}(B)\\) are prime and of finite order. The roots of \\(\\delta_{i}(B)\\) lies on the unit circle; those of \\(\\phi_{i}(B)\\) lie outside, while all the roots of \\(\\theta_{i}(B)\\) are on or outside the unit circle. This means that nonstationary and noninvertible components are allowed. Since different roots of the AR polynomial induce peaks in the spectrum of the series at different frequencies, and given that different components are associated with the spectral peaks for different frequencies, it is assumed that for \\(i \\neq j\\) the polynomials\\(\\ \\phi_{i}(B)\\) and \\(\\phi_{j}(B)\\) do not share any common root (they are coprime). Finally, it is assumed that the polynomials \\(\\theta_{i}(B),\\ i = 1,\\ldots,k\\) are prime share no unit root in common, guaranteeing the invertibility of the overall series. In fact, since the unit root of \\(\\theta_{i}(B)\\) induce a spectral zero, when the polynomials \\(\\theta_{i}(B),\\ i = 1,\\ldots,k\\) share no unit root in common, there is no frequency for which all component spectra become zero.\nFor description of the spectrum see chapter on Spectral Analysis.(MARAVALL, A. (1995).\nSince aggregation of ARIMA models yields ARIMA models, the series \\(x_{t}\\) will also follow an ARIMA model, as in Equation 2, and consequently the following identity can be derived:\n\\[\n\\frac{\\theta(B)}{\\varphi(B)}a_{t} = \\sum_{i = 1}^{k}{\\frac{\\theta_{i}(B)}{\\varphi_{i}(B)}a_{\\text{it}}}\n\\tag{5}\\]\nIn the ARIMA model based approach implemented in SEATS, the ARIMA model identified and estimated for the observed series \\(x_{t}\\) is decomposed to derive the models for the components. In particular, the AR polynomials for the components, \\(\\varphi_{i}(B)\\), are easily derived through the factorization of the AR polynomial \\(\\varphi(B)\\):\n\\[\n\\varphi(B) = \\prod_{i = 1}^{k}{\\varphi_{i}(B)}\n\\tag{6}\\]\nwhile the MA polynomials for the components, together with the innovation variances \\(V(a_{i})\\), cannot simply be obtained through the relationship:\n\\[\n\\theta(B)a_{t} = \\sum_{i= 1}^{k}{\\varphi_{\\text{ni}}(B)}\\theta_{i}(B)a_{\\text{it}}\n\\tag{7}\\]\nwhere \\(\\varphi_{\\text{ni}}(B)\\) is the product of all \\(\\varphi_{j}(B),\\ j = 1,\\ldots,k\\), except from \\(\\varphi_{i}(B)\\). Further assumptions are therefore needed to cope with the under identification problem: i) \\(p_{i} \\geq q_{i}\\) and ii) the canonical decomposition, i.e. the decomposition that allocate all additive white noise to the irregular component (yielding non invertible components except the irregular).\nTo understand how SEATS factorizes the AR polynomials, first a concept of a root will be explored.(Description based on KAISER, R., and MARAVALL, A. (2000) and MARAVALL, A. (2008c).)\nEquation 2 can be expressed as:\n\\[\n\\psi^{- 1}(B)x_{t} = a_{t}(1 + \\varphi_{1}B + \\ldots\\varphi_{p}B^{p})x_{t} =(1 + \\theta_{1}B + \\ldots\\theta_{q}B^{q})a_{t}\n\\tag{8}\\]\nLet us now consider Equation 2 in the inverted form:\n\\[\n\\theta(B)y_{t} = \\varphi(B)a_{t}\n\\tag{9}\\]\nIf both sides of Equation 8 multiplied by \\(x_{t-k}\\) with \\(k &gt; q\\), and expectations are taken, the right hand side of the equation vanishes and the left hand side becomes:\n\\[\n\\varphi(B)\\gamma_{k} = \\gamma_{k} + \\varphi_{1}\\gamma_{k-1} + \\ldots\\varphi_{p}\\gamma_{k-p} = 0\n\\tag{10}\\]\nwhere \\(B\\) operates on the subindex \\(k\\).\nThe autocorrelation function \\(\\gamma_{k}\\) is a solution of Equation 10 with the characteristic equation:\n\\[\nz^{p} +\\varphi_{1}z^{p-1} + \\ldots\\varphi_{p-1}z + \\varphi_{p} = 0\n\\tag{11}\\]\nIf \\(z_{1}\\),…,\\(\\ z_{p}\\) are the roots of Equation 11, the solutions of Equation 10 can be expressed as:\n\\[\n\\gamma_{k} = \\sum_{i = 1}^{p}z_{i}^{k}\n\\tag{12}\\]\nand will converge to zero as \\(karrow \\infty\\) when \\(|r_{i}| &lt; 1,\\ i = 1,\\ldots,p\\). From Equation 10 and Equation 12 it can be noticed that \\(z_{1} = B_{i}^{-1}\\), meaning that \\(z_{1}\\),…,\\(\\ z_{p}\\) are the inverses of the roots \\(B_{1},\\ldots,B_{p}\\) of the polynomial \\(\\varphi(B)\\). The convergence of \\(\\gamma_{k}\\) implies that the roots of the \\(\\varphi(B)\\) are larger than 1 in modulus (lie outside the unit circle). Therefore, from the Equation 13.\n\\[\n{\\varphi(B)}^{- 1} = \\frac{1}{(1-z_{1})\\ldots(1-z_{1})}\n\\tag{13}\\]\nit can be derived that \\({\\varphi(B)}^{- 1}\\) is convergent and all its inverse roots are less than 1 in modulus.\nEquation 11 has real and complex roots (solutions). Complex number \\(x = a + bi\\), with \\(a\\) and \\(\\text{b}\\) both real numbers, can be represented as \\(x = r(cos(\\omega) + i\\ sin(\\omega))\\), where \\(i\\) is the imaginary unit \\({i}^{2}=-1)\\), \\(r\\) is the modulus of \\(x\\), that is \\(r=|x| = \\sqrt{a^{2} + b^{2}}\\) and \\(\\omega\\) is the argument (frequency). When roots are complex, they are always in pairs of complex conjugates. The representation of the complex number \\(x = a + bi\\) has a geometric interpretation in the complex plane established by the real axis and the orthogonal imaginary axis.\n\n\n\nGeometric representation of a complex number and of its conjugate\n\n\nRepresenting the roots of the characteristic Equation 11 in the complex plane enhances understanding how they are allocated to the components. When the modulus \\(r\\) of the roots in \\(\\text{z}\\) are greater than 1 (i.e. modulus of the roots in \\(\\varphi(B)&lt; 1\\)), the solution of the characteristic equation has a systematic explosive process, which means that the impact of the given impulse on the time series is more and more pronounced in time. This behaviour is not in line with the developments that can be identified in actual economic series. Therefore, the models estimated by TRAMO-SEATS (and X-13ARIMA-SEATS) have never inverse roots in \\(B\\) with modulus greater than 1.\nThe characteristic equations associated with the regular and the seasonal differences have roots in \\(\\varphi(B)\\) with modulus \\(r = 1\\). They are called non-stationary roots and can be represented on the unit circle. Let us consider the seasonal differencing operator applied to a quarterly time series \\((1-B^{4})\\). Its characteristic equation is \\({(z}^{4}-1) = 0\\) with solutions given by\\(z = \\sqrt[4]{1}\\), i.e. \\(z_{1,2} = \\pm 1\\) and \\(z_{3,4} = \\pm i1\\). The first two solutions are real and the last two are complex conjugates. They are represented by the black points on the unit circle on the figure below.\n\n\n\nUnit roots on the unit circle\n\n\nFor the seasonal differencing operator \\((1-B^{12})\\) applied to the monthly time series the characteristic equation \\({(z}^{12}-1) = 0\\) has twelve non-stationary solutions given by \\(z = \\sqrt[12]{1}:\\) two real and ten complex conjugates, represented by the white circles in unit roots figure above.\nThe complex conjugates roots generate the periodic movements of the type:\n\\[\nz_{t} = A^{t}\\cos(\\omega t + W)\n\\tag{14}\\]\nwhere:\n\n\\(A\\) – amplitude;\n\\(\\omega\\) – angular frequency (in radians);\n\\(W\\) – phase (angle at \\(t = 0)\\).\n\nThe frequency \\(f\\), i.e. the number of cycles per unit time, is \\(\\frac{\\omega}{2\\pi}\\). If it is multiplied by s, the number of observations per year, the number of cycles completed in one year is derived. The period of function in Equation 14, denoted by \\(\\tau\\), is the number of units of time (months/quarters) it takes for a full circle to be completed.\nFor quarterly series the seasonal movements are produced by complex conjugates roots with angular frequencies at \\(\\frac{\\pi}{2}\\) (one cycle per year) and \\(\\pi\\) (two cycles per year). The corresponding number of cycles per year and the length of the movements are presented in the table below.\nSeasonal frequencies for a quarterly time series\n\n\n\n\n\n\n\n\n\nAngular frequency (\\(\\omega\\))\nFrequency (cycles per unit time) (\\(f\\))\nCycles per year\nLength of the movement measured in quarters (\\(\\tau\\))\n\n\n\n\n\\(\\frac{\\pi}{2}\\)\n0.25\n1\n4\n\n\n\\(\\pi\\)\n0.5\n2\n2\n\n\n\nFor monthly time series the seasonal movements are produced by complex conjugates roots at the angular frequencies: \\(\\frac{\\pi}{6},\\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}, \\frac{5\\pi}{6}\\) and \\(\\pi\\). The corresponding number of cycles per year and the length of the movements are presented in the table below:\nSeasonal frequencies for a monthly time series\n\n\n\n\n\n\n\n\n\nAngular frequency (\\(\\omega\\))\nFrequency (cycles per time unit) (\\(f\\))\nCycles per year\nLength of the movement measured in months (\\(\\tau\\))\n\n\n\n\n\\(\\frac{\\pi}{6}\\)\n0.083\n1\n12\n\n\n\\(\\frac{\\pi}{3}\\)\n0.167\n2\n6\n\n\n\\(\\frac{\\pi}{2}\\)\n0.250\n3\n4\n\n\n\\(\\frac{2\\pi}{3}\\)\n0.333\n4\n3\n\n\n\\(\\frac{5\\pi}{6}\\)\n0.417\n5\n2.4\n\n\n\\(\\pi\\)\n0.500\n6\n2\n\n\n\nIn JDemetra+ SEATS assigns the roots of the AR full polynomial to the components according to their associated modulus and frequency (For details see MARAVALL, A., CAPORELLO, G., PÉREZ, D., and LÓPEZ, R. (2014))\n\nRoots of \\((1-B)^{d}\\) are assigned to trend component.\nRoots of \\((1-B^{s})^{d_{s}} = {((1-B)(1+B + \\ldots + B^{s-1}))}^{d_{s}}\\) are assigned to the trend component (root of \\({(1-B)}^{d_{s}}\\)) and to the seasonal component (roots of \\({(1+B + \\ldots + B^{s-1})}^{d_{s}}\\)).\nWhen the modulus of the inverse of a real positive root of \\(\\varphi(B)\\) is greater than \\(k\\) or equal to \\(k\\), where \\(k\\) is the threshold value controlled by the Trend boundary parameter, then the root is assigned to the trend component. Otherwise it is assigned to the transitory component.\nReal negative inverse roots of \\(\\text{ϕ}_{p}(B)\\) associated with the seasonal two-period cycle are assigned to the seasonal component if their modulus is greater than k, where \\(k\\) is the threshold value controlled by the Seasonal boundary and the Seas. boundary (unique) parameters. Otherwise they are assigned to the transitory component.\nComplex roots, for which the argument (angular frequency) is close enough to the seasonal frequency are assigned to the seasonal component. Closeness is controlled by the Seasonal tolerance and Seasonal tolerance (unique) parameters. Otherwise they are assigned to the transitory component.\nIf \\(d_{s}\\) (seasonal differencing order) is present and \\(\\text{Bphi} &lt; 0\\) (\\(\\text{Bphi}\\) is the estimate of the seasonal autoregressive parameter), the real positive inverse root is assigned to the trend component and the other (\\(s-1\\)) inverse roots are assigned to the seasonal component. When \\(d_{s} = 0\\), the root is assigned to the seasonal when \\(\\text{Bphi} &lt; - 0.2\\) and/or the overall test for seasonality indicates presence of seasonality. Otherwise it goes to the transitory component. Also, when \\(\\text{Bphi} &gt; 0\\), roots are assigned to the transitory component.\n\nIt should be highlighted that when \\(Q &gt; P\\), where \\(Q\\) and \\(P\\) denote the orders of the polynomials \\(\\varphi(B)\\) and \\(\\theta(B)\\), the SEATS decomposition yields a pure MA \\((Q - P)\\) component (hence transitory). In this case the transitory component will appear even when there is no AR factor allocated to it.\nOnce these rules are applied, the factorization of the AR polynomial presented by Equation 2 yields to the identification of the AR polynomials for the components which contain, respectively, the AR roots associated with the trend component, the seasonal component and the transitory component.\nThe AR roots close to or at the trading day frequency generates a stochastic trading day component. A stochastic trading day component is always modelled as a stationary ARMA(2,2), where the AR part contains the roots close to the TD frequency, and the MA(2) is obtained from the model decomposition (MARAVALL, A., and PÉREZ, D. (2011)). This component, estimated by SEATS, is not implemented by the current version of JDemetra+.\nThen with the partial fraction expansion the spectrum of the final components are obtained.\nFor example, the Airline model for a monthly time series:\n\\[\n(1-B)(1-B^{12})x_{t} = (1+\\theta_{1}B)(1+\\Theta_{1}B^{12})\\ a_{t}\n\\tag{15}\\]\nis decomposed by SEATS into the model for the trend component:\n\\[\n(1-B)(1-B)c_{t} =(1+\\theta_{c,1}B + \\theta_{c,2}B^{2})a_{c,t}\n\\tag{16}\\]\nand the model for the seasonal component:\n\\[\n(1+B + \\ldots + B^{11})s_{t} = (1+\\theta_{s,1}B + \\ldots + {\\theta_{s,11}B}^{11})a_{s,t},\n\\tag{17}\\]\nAs a result, the Airline model is decomposed as follows:\n\\[\n\\small\n\\frac{(1+\\theta_{1}B)(1+\\Theta_{1}B^{12})}{(1-B)(1-B)}a_{t} = \\frac{(1+\\theta_{s,1}B + \\ldots + {\\theta_{s,11}B}^{11})}{(1+B + \\ldots + B^{11})}a_{s,t} + \\frac{(1+\\theta_{c,1}B + \\theta_{c,2}B^{2})}{(1-B)(1-B)}a_{c,t} + u_{t}\n\\tag{18}\\]\nThe transitory component is not present in this case and the irregular component is the white noise.\nThe partial fractions decomposition is performed in a frequency domain. In essence, it consists in portioning of the pseudo-spectrum of \\(x_{t}\\) into additive spectra of the components. When the AMB decomposition of the ARIMA model results in the non-negative spectra for all components, the decomposition is called admissible. In such case an infinite number of admissible decompositions exists, i.e. decompositions that yield the non-negative spectra of all components.\nTherefore, the MA polynomials and the innovation variances cannot be yet identified from the model of \\(x_{t}\\). As sketched above, to solve this under identification problem and identify a unique decomposition, it is assumed that for each component the order of the MA polynomial is no greater than the order of the AR polynomial and the canonical solution of S.C. Hillmer and G.C. Tiao is applied, i.e. all additive white noise is added to the irregular component As a consequence all components derived from the canonical decomposition, except from the irregular, have a spectral minimum of zero and are thus non invertible.\nGiven the stochastic features of the series, it can be shown by that the canonical decomposition produces as stable as possible trend and seasonal components since it maximizes the variance of the irregular and minimizes the variance of the other components. However, there is a price to be paid as canonical components can produce larger revisions in the preliminary estimators of the component than any other admissible decomposition.\nThe term pseudo-spectrum is used for a non-stationary time series, while the term spectrum is used for a stationary time series.\nIf the ARIMA model estimated in TRAMO does not accept an admissible decomposition, SEATS replaces it with a decomposable approximation. The modified model is therefore used to decompose the series. There are also other rare situations when the ARIMA model chosen by TRAMO is changed by SEATS. It happens when, for example, the ARIMA models generate unstable seasonality or produce a senseless decomposition. Such examples are discussed by MARAVALL, A. (2009).\nHILLMER, S.C., and TIAO, G.C. (1982).\nGÓMEZ, V., and MARAVALL, A. (2001a).\nHILLMER, S.C., and TIAO, G.C. (1982).\nMARAVALL, A. (1986).\nThe figure below represents the pseudo-spectrum for the canonical trend and an admissible trend.\n\n\n\nA comparison of canonical trend and admissible trend\n\n\nA pseudo-spectrum is denoted by\\(g_{i}(\\omega)\\), where \\(\\omega\\) represents the angular frequency. The pseudo-spectrum of \\(x_{\\text{it}}\\) is defined as the Fourier transform of ACGF of \\(x_{t}\\) which is expressed as:\n\\[\n\\frac{\\psi_{i}(B)\\psi_{i}(F)}{\\delta_{i}(B)\\delta_{i}(F)}V(a_{i})\n\\tag{19}\\]\nwhere:\n\n\\(\\psi_{i}(F) = \\frac{\\theta_{i}(F)}{\\phi_{i}(F)}\\)\n\\(\\psi_{i}(B) = \\frac{\\theta_{i}(B)}{\\phi_{i}(B)}\\)\n\nA pseudo-spectrum for a monthly time series \\(x_{t}\\) is presented in the figure below: The pseudo-spectrum for a monthly series. The frequency \\(\\omega = 0\\) is associated with the trend, frequencies in the range \\([0 + \\epsilon_{1},\\ \\frac{\\pi}{6} - \\epsilon_{2}]\\) with \\([0 + \\epsilon_{1},\\ \\frac{\\pi}{6} - \\epsilon_{2}]\\) \\(\\epsilon_{1},\\ \\epsilon_{2} &gt; 0\\) and \\(\\epsilon_{1} &lt; \\ \\frac{\\pi}{6} - \\epsilon_{2}\\) are usually associated with the business-cycle and correspond to a period longer than a year and bounded.\nThe frequencies in the range \\([\\frac{\\pi}{6},\\pi]\\) are associated with the short term movements, whose cycle is completed in less than a year. If a series contains an important periodic component, its spectrum reveals a peak around the corresponding frequency and in the ARIMA model it is captured by an AR root. In the example below spectral peaks occur at the frequency \\(\\omega = 0\\) and at the seasonal frequencies (\\(\\frac{\\pi}{6}\\), \\(\\frac{2\\pi}{6},\\ \\frac{3\\pi}{6},\\ \\frac{4\\pi}{6},\\frac{5\\pi}{6},\\pi\\)).\n\n\n\nThe pseudo-spectrum for a monthly series\n\n\nIn the decomposition procedure, the pseudo-spectrum of the time series \\(x_{t}\\) is divided into the spectra of its components (in the example figure below, four components were obtained).\n\n\n\nThe pseudo-spectra for the components\n\n\n\n\nEstimation of the components\nThe various components are estimated using Wiener-Kolmogorow (WK) filters. JDemetra+ includes three options to estimate the WK filter, namely Burman, KalmanSmoother and MCElroyMatrix[^m-seats-decomposition_old-12]. Here the first of above mentioned options, proposed by BURMAN, J.P. (1980) will be explained.\nThe estimation procedure and the properties of the WK filter are easier to explain with a two-component model. Let the seasonally adjusted series (\\(s_{t}\\)) be the signal of interest and the seasonal component (\\(n_{t}\\)) be the remainder, “the noise”. The series is given by the model in Equation 2 and from Equation 4 the models for theoretical components are:\n\\[\n\\varphi_{s}(B)s_{t} = \\theta_{s}(B)a_{\\text{st}}\n\\tag{20}\\]\nand\n\\[\n\\varphi_{n}(B)n_{t} = \\theta_{n}(B)a_{\\text{nt}}\n\\tag{21}\\]\nFrom Equation 6 and Equation 7 it is clear that \\(\\varphi(B) = \\varphi_{s}(B)\\varphi_{n}(B)\\) and \\(\\theta(B)a_{t} = \\theta_{s}(B)a_{\\text{st}}+\\theta_{n}(B)a_{\\text{nt}}\\).\nAs the time series components are never observed, their estimators have to be used. Let us note \\(X_{T}\\) an infinite realization of the time series \\(x_{t}\\). SEATS computes the Minimum Mean Square Error (MMSE) estimator of \\(s_{t}\\), e.g. the estimator \\(\\widehat{s}_{t}\\) that minimizes \\(E\\lbrack({s_{t}-\\widehat{s}_{t})}^{2}|X_{T})\\rbrack\\). Under the normality assumption \\(\\widehat{s}_{t|T}\\) is also equal to the conditional expectation \\(E(s_{t}|X_{T})\\), so it can be presented as a linear function of the elements in \\(X_{T}\\).WHITTLE (1963) shows that the MMSE estimator of \\(\\widehat{s}_{t}\\) is:\n\\[\n{\\widehat{s}}_{t} = k_{s}\\frac{\\psi_{s}(B)\\psi_{s}(F)}{\\psi(B)\\psi(F)}x_{t}\n\\tag{22}\\]\nwhere\n\n\\(\\psi(B)= \\frac{\\theta(B)}{\\phi(B)}\\),\n\\(k_{s}=\\frac{V(a_{s})}{V(a)}\\),\n\n\\(V(a_{s})\\) is the variance of \\(a_{st}\\) and \\(V(a)\\) is the variance of \\(a_{t}\\).\nExpressing the \\(\\psi(B)\\) polynomials as functions of the AR and MA polynomials, after cancellation of roots, the estimator of \\(s_{t}\\) can be expressed as:\n\\[\n\\widehat{s}_{t} =\nk_{s}\\frac{\\theta_{s}(B)\\theta_{s}(F)\\varphi_{n}(B)\\delta_{n}(B)\\varphi_{n}(F)\\delta_{n}(F)}\n{\\theta(B)\\theta(F)}x_{t}\n\\tag{23}\\]\nwhere:\n\\[\n\\nu_{s}(B,F) = k_{s}\\frac{\\theta_{s}(B)\\theta_{s}(F)\\varphi_{n}(B)\\delta_{n}(B)\\varphi_{n}(F)\\delta_{n}(F)}{\\theta(B)\\theta(F)}\n\\tag{24}\\]\nis a WK filter.\nEquation 24 shows that the WK filter is two-sided (uses observations both from the past and from the future), centred (the number of points in the past is the same as in the future) and symmetric (for any \\(k\\) the weight applied to \\(x_{t-k}\\) and \\(x_{t+k}\\) is the same), which allows the phase effect to be avoided. Due to invertibility of \\(\\theta(B)\\) (and \\(\\theta(F)\\)) the filter is convergent in the past and in the future.\nThe estimator can be presented as\n\\[\n\\widehat{s}_{t} = \\nu_{i}(B,F)x_{t}\n\\tag{25}\\]\nwhere \\(\\nu_{i}(B,F)=\\nu_{0}+ \\sum_{j = 1}^{\\infty}\\nu_{ij}(B^{j}+F^{j})\\) is the WK filter.\nThe example of the WK filters obtained for the pseudo-spectra of the series illustrated above is shown on the figure below: WK filters for components.\n\n\n\nWK filters for components\n\n\nThe WK filter from Equation 24 can also be expressed as a ratio of two pseudo-autocovariance generating functions (p-ACGF). The p-ACGF function summarizes the sequence of absolutely summable autocovariances of a stationary process \\(x_{t}\\) (see Spectral Analysis).\nThe ACGF function of an ARIMA process is expressed as:\n\\[\nacgf(B) = \\frac{\\theta(B)\\theta(F)}{\\phi(B)\\delta(B)\\phi(F)\\delta(F)}V(a)\n\\tag{26}\\]\nAnd, the WK filter can be rewritten as:\n\\[\n\\nu_{s}(B,F) = \\frac{\\gamma_{s}(B,F)}{\\gamma(B,F)}\n\\tag{27}\\]\nwhere:\n\n\\(\\gamma_{s}(B,F) = \\frac{\\theta_{s}(B)\\theta_{s}(F)}{\\phi_{s}(B)\\delta_{s}(B)\\phi_{s}(F)\\delta_{s}(F)}V(a_{s})\\) is the p-ACGF of \\(s_{t}\\);\n\\(\\gamma(B,F) = \\frac{\\theta(B)\\theta(F)}{\\phi(B)\\delta(B)\\phi(F)\\delta(F)}V(a)\\) is the p-ACGF of \\(x_{t}\\).\n\nFrom Equation 24 it can be seen that the WK filter depends on both the component and the series models. Consequently, the estimator of the component and the WK filter reflect the characteristic of data and by construction, the WK filter adapts itself to the series under consideration. Therefore, the ARIMA model is of particular importance for the SEATS method. Its misspecification results in an incorrect decomposition.\nThis adaptability, if the model has been correctly determined, avoids the dangers of under and overestimation with an ad-hoc filtering. For example, for the series with a highly stochastic seasonal component the filter adapts to the width of the seasonal peaks and the seasonally adjusted series does not display any spurious seasonality. Examples of WK filters for stochastic and stable seasonal components are presented on the figure below. (MARAVALL, A. (1995)).\n\n\n\nWK filters for stable and stochastic seasonal components\n\n\nThe derivation of the components requires an infinite realization of \\(x_{t}\\) in the direction of the past and of the future. However, the convergence of the WK filter guarantees that, in practice, it could be approximated by a truncated (finite) filter and, in most applications, for large \\(k\\) the estimator for the central periods of the series can be safely seen as generated by the WK filter (MARAVALL, A., and PLANAS, C. (1999)).\n\\[\n\\widehat{s}_{t}=\\nu_{k}x_{t-k} + \\ldots + \\nu_{0}x_{t} + \\ldots + \\nu_{k}x_{t+k}\n\\tag{28}\\]\nWhen \\(T &gt; 2L + 1\\), where \\(T\\) is the last observed period, and \\(L\\) is an a priori number that typically expands between 3 and 5 years, the estimator expressed by Equation 23 can be assumed as the final (historical) estimator for the central observations of the series1. In practice, the Wiener-Kolmogorov filter is applied to \\(x_{t}\\) extended with forecasts and backcasts from the ARIMA model. The final or historical estimator of \\(\\widehat{s}_{t}\\), is obtained with a doubly infinite filter, and therefore contains an error \\(e_{st}\\) called final estimation error, which is equal \\(e_{st}=s_{t}\\) associated with the regular and the seasonal differences have roots in \\(\\varphi(B)\\) with modulus \\(r = 1\\). They are called non-stationary roots and can be represented on the unit circle. Let us consider the seasonal differencing operator applied to a quarterly time series \\((1-B^{4})\\). Its characteristic equation is \\({(z}^{4}-1) = 0\\) with solutions given by \\(z=\\sqrt[4]{1}\\), i.e. \\(z_{1,2} = \\pm 1\\) and \\(z_{3,4} = \\pm i1\\). The first two solutions are real and the last two are complex conjugates. They are represented by the black points on the unit circle on the figure below.\n\n\n\nUnit roots on the unit circle\n\n\nIn the frequency domain, the Wiener-Kolmogorov filter\\(\\ \\nu(B,F)\\) that provides the final estimator of \\(s_{t}\\) is expressed as the ratio of the \\(s_{t}\\) and \\(x_{t}\\) pseudo-spectra:\n\\[\n\\widetilde{\\nu}(\\omega) = \\frac{g_{s}(\\omega)}{g_{x}(\\omega)}\n\\tag{29}\\]\nThe function \\(\\widetilde{\\nu}(\\omega)\\) is also referred as the gain of the filter. GÓMEZ, V., and MARAVALL, A. (2001a) show that when for some frequency the signal (the seasonally adjusted series) dominates the noise (seasonal fluctuations) the gain \\(\\widetilde{\\nu}(\\omega)\\) approaches 1. On the contrary, when for some frequency the noise dominates the gain \\(\\widetilde{\\nu}(\\omega)\\) approaches 0.\nThe spectrum of the estimator of the seasonal component is expressed as:\n\\[\ng_{\\widehat{s}}(\\omega) = \\lbrack \\frac{g_{s}(\\omega)}{g_{x}(\\omega)}\\rbrack^{2}g_{x}(\\omega)\n\\tag{30}\\]\nwhere\n\n\\(\\ \\lbrack \\widetilde{\\nu}(\\omega)\\rbrack^{2} = \\lbrack \\frac{g_{s}(\\omega)}{g_{x}(\\omega)}\\rbrack^{2} = \\lbrack \\frac{g_{s}(\\omega)}{g_{s}(\\omega) + g_{n}(\\omega)}\\rbrack^{2} = \\lbrack \\frac{1}{1+\\frac{1}{r(\\omega)}}\\rbrack^{2}\\) is the squared gain of the filter ;\n\\(r(\\omega) = \\frac{g_{s}(\\omega)}{g_{n}(\\omega)}\\) represents the signal-to-noise ratio.\n\nFor each \\(\\omega\\), the MMSE estimation gives the signal-to-noise ratio. If this ratio is high, then the contribution of that frequency to the estimation of the signal will be also high. Assume that the trend is a signal that needs to be extracted from a seasonal time series. Then \\(R(0) = 1\\) and the frequency \\(\\omega = 0\\) will only be used for trend estimations. For seasonal frequencies \\(R(\\omega) = 0\\), so that these frequencies are ignored in computing the trend resulting in spectral zeros in \\(g_{\\widehat{s}}(\\omega)\\). For this reason, unlike the spectrum of the component, the component spectrum contains dips as it can be seen on the figure below: Component spectrum and estimator spectrum for trend.\n\n\n\nComponent spectrum and estimator spectrum for trend\n\n\nFrom the Equation 29 it is clear that the squared gain of the filter determines how the variance of the series contributes to the variance of the seasonal component for the different frequencies. When \\(\\widetilde{\\nu}(\\omega) = 1\\), the full variation of \\(x_{t}\\) for that frequency is passed to \\(\\widehat{s}_{t}\\), while if \\(\\widetilde{\\nu}(\\omega) = 0\\) the variation of \\(x_{t}\\) for that frequency is fully ignored in the computation of \\(\\widehat{s}_{t}\\). These two cases are well illustrated by the figure below that shows the square gain of the WK filter for two series already analysed in the figure above (Figure: WK filters for stable and stochastic seasonal components).\n\n\n\nThe squared gain of the WK filter for stable and stochastic seasonal components.\n\n\nSince \\(r(\\omega) \\geq 0\\), then \\(\\widetilde{\\nu}(\\omega) \\leq 1\\) and from Equation 29 it can be derived that \\(g_{\\widehat{s}}(\\omega) = \\widetilde{\\nu}(\\omega)g_{s}(\\omega)\\). As a result, the estimator will always underestimate the component, i.e. it will be always more stable that the component.\nSince \\(g_{\\widehat{n}}(\\omega) &lt; g_{n}(\\omega)\\) and \\(g_{\\widehat{s}}(\\omega) &lt; g_{s}(\\omega)\\) the expression: \\(g_{x}(\\omega) - \\lbrack g_{\\widehat{n}}(\\omega) + g_{\\widehat{s}}(\\omega)\\rbrack \\geq 0\\) is the cross-spectrum. As it is positive, the MMSE yields correlated estimators. This effect emerges since variance of estimator is smaller than the variance of component. Nevertheless, if at least one non-stationary component exists, cross-correlations estimated by TRAMO-SEATS will tend to zero as cross-covariances between estimators of the components are finite. In practice, the inconvenience caused by this property will likely be of little relevance.\nPreliminary estimators for the components\nGÓMEZ, V., and MARAVALL, A. (2001a) point out that the properties of the estimators have been derived for the final (or historical) estimators. For a finite (long enough) realization, they can be assumed to characterize the estimators for the central observations of the series, but for periods close to the beginning of the end the filter cannot be completed and some preliminary estimator has to be used. Indeed, the historical estimator shown in Equation 28 is obtained for the central periods of the series. However, when \\(t\\) approaches \\(T\\) (last observation), the WK filter requires observations, which are not available yet. For this reason a preliminary estimator needs to be used.\nTo introduce preliminary estimators let us consider a semi-finite realization \\([x_{- \\infty}\\),…$ x_{T}]$, where \\(T\\) is the last observed period. The preliminary estimator of \\(x_{\\text{it}}\\) obtained at \\(T\\), \\((T - t = k \\geq 0)\\) can be expressed as\n\\[\n\\widehat{x}_{it|t + k}=\\nu_{i}(B,F)x_{t|T}^{e}\n\\tag{31}\\]\nwhere\n\n\\(\\nu_{i}(B,F)\\) is the WK filter ;\n\\(x_{t|T}^{e}\\) is the extended series, such that \\(x_{t|T}^{e} = x_{t}\\) for \\(t \\leq T\\) and \\(x_{t|T}^{e}=\\widehat{x}_{t|T}\\) for \\(t&gt;T\\), where \\(\\widehat{x}_{t|T}\\) denotes the forecast of \\(x_{t}\\) obtained at period \\(T\\).\n\nThe future \\(k\\) values necessary to apply the filter are not yet available and are replaced by their optimal forecasts from the ARIMA model on \\(x_{t}\\). When \\(k=0\\) the preliminary estimator becomes the concurrent estimator. As the forecasts are linear functions of present and past observations of \\(x_{t}\\), the preliminary estimator \\(\\widehat{x}_{it}\\) will be a truncated asymmetric filter applied to \\(x_{t}\\) that generates a phase effect (KAISER, R., and MARAVALL, A. (2000)).\nWhen a new observation \\(x_{T + 1}\\) becomes available the forecast \\(\\widehat{x}_{T + 1|T}\\) is replaced by the observation and the forecast \\(\\widehat{x}_{iT + j|T}\\), \\(j &gt; 1\\) are updated to \\(x_{T + j|T + 1}\\) resulting in the revision error (MARAVALL, A. (1995)). The total error in the preliminary estimator \\(d_{it|t + k}\\) is expressed as a sum of the final estimation error (\\(e_{it}\\)) and the revision error (\\(r_{it|t + k}\\)), i.e.:\n\\[\nd_{it|t + k} = x_{it}-\\widehat{x}_{it|t + k} = (x_{it} - \\widehat{x}_{it}) + (         \\widehat{x}_{it} - \\widehat{x}_{it|t + k}) = e_{it} + r_{it|t + k}\n\\tag{32}\\]\nwhere:\n\n\\(x_{it}-i^{th}\\) component;\n\\(\\widehat{x}_{it|t + k}\\)- the estimator of \\(x_{it}\\) when the last observation is \\(x_{t+k}\\).\n\nTherefore the preliminary estimator is subject not only to the final error but also to a revision error, which are orthogonal to each other (MARAVALL, A. (2009)). The revision error decreases as \\(k\\) increases, until it can be assumed equal to 0 for large enough \\(k\\).\nIt’s worth remembering that SEATS estimates the unobservable components of the time series so the “true” components are never observed. Therefore, MARAVALL, A. (2009) stresses that the error in the historical estimator is more of academic rather than practical interest. In practice, interest centres on revisions. (…) the revision standard deviation will be an indicator of how far we can expect to be from the optimal estimator that will be eventually attained, and the speed of convergence of \\(\\theta(B)^{- 1}\\) will dictate the speed of convergence of the preliminary estimator to the historical one. The analysis of an error is therefore useful for making decision concerning the revision policy, including the policy for revisions and horizon of revisions.\n\n\nPsiE-weights\nThe estimator of the component is calculated as \\(\\widehat{x}_{it} = \\nu_{s}(B,F)x_{t}\\). By replacing \\(x_{it}=\\frac{\\theta(B)}{\\gamma(B)\\delta(B)}a_{t}\\), the component estimator can be expressed as (KAISER, R., and MARAVALL, A. (2000)):\n\\[\n\\widehat{x}_{it} = \\xi_{s}(B,F)a_{t}\n\\tag{33}\\]\nwhere \\(\\xi_{s}(B,F) = \\ldots + \\xi_{j}B^{j} + \\ldots + \\xi_{1}B + \\xi_{0} + \\xi_{- 1}F\\ldots\\xi_{- j}F^{j} + \\ldots\\).\nThis representation shows the estimator as a filter applied to the innovation \\(a_{t}\\), rather than on the series \\(x_{t}\\). Hence, the filter from Equation 32 can be divided into two components: the first one, i.e. \\(\\ldots + \\xi_{j}B^{j}+ \\ldots+ \\xi_{1}B + \\xi_{0}\\), applies to prior and concurrent innovations, the second one, i.e. \\(\\xi_{- 1}F + \\ldots + \\xi_{- j}F^{j}\\) applies to future (i.e. posterior to \\(t\\)) innovations. Consequently, \\(\\xi_{j}\\) determines the contribution of \\(a_{t - j}\\) to \\(\\widehat{s}_{t}\\) while \\(\\xi_{- j}\\) determines the contribution of \\(a_{t + j}\\) to \\(\\widehat{s}_{t}\\). Finally, the estimator of the component can be expressed as:\n\\[\n\\widehat{x}_{it} =\\xi_{i}(B)^{-}a_{t} + \\xi_{i}(F)^{+}a_{t + 1}\n\\tag{34}\\]\nwhere:\n\n\\(\\xi_{i}{(B)}^{-}a_{t}\\) is an effect of starting conditions, present and past innovations in series;\n\\(\\xi_{i}{(F)}^{+}a_{t + 1}\\) is an effect of future innovations.\n\nFor the two cases already presented in figure WK filters for stable and stochastic seasonal components and figure The squared gain of the WK filter for stable and stochastic seasonal components above, the psi-weights are shown in the figure below.\n\n\n\nWK filters and squared gain of the WK filter\n\n\nIt can be shown that \\({\\xi}_{- 1},\\ldots,\\xi_{- j}\\) are convergent and \\(\\xi_{j},\\ldots, {\\xi}_{1},\\xi_{0}\\) are divergent. From Equation 33, the concurrent estimator is equal to:\n\\[\n\\widehat{x}_{it|t} = E_{t}x_{it}=E_{t}\\widehat{x}_{it} = {\\xi}_{i}(B)^{-}a_{t}\n\\tag{35}\\]\nso that the revision\n\\[\nr_{it} = \\widehat{x}_{it} - \\widehat{x}_{it|t} = \\xi_{i}(F)^{+}a_{t + 1}\n\\tag{36}\\]\nis a zero-mean stationary MA process. As a result, historical and preliminary estimators are co-integrated. From Equation 25 the relative size of the full revision and the speed of convergence can be obtained."
  },
  {
    "objectID": "M-SEATS-decomposition.html#footnotes",
    "href": "M-SEATS-decomposition.html#footnotes",
    "title": "SEATS decomposition",
    "section": "",
    "text": "MARAVALL, A. (1998).↩︎"
  },
  {
    "objectID": "M-Trend-Estimation-Local-Polynomials.html",
    "href": "M-Trend-Estimation-Local-Polynomials.html",
    "title": "Trend Estimation",
    "section": "",
    "text": "Up-coming content."
  },
  {
    "objectID": "M-tests.html#in-this-chapter",
    "href": "M-tests.html#in-this-chapter",
    "title": "Tests",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter describes all the tests available in JDemetra+, via Graphical User Interface and R packages. Here the underlying theoretical principles of each test are provided.\nto be added: which test are done when SEATS decomposition vs X-13-Arima."
  },
  {
    "objectID": "M-tests.html#tests-on-residuals",
    "href": "M-tests.html#tests-on-residuals",
    "title": "Tests",
    "section": "Tests on residuals",
    "text": "Tests on residuals\n\n\n\nTest\nPurpose\nGUI\nR package\n\n\n\n\nLjung-Box\nautocorrelation\n✔️\n\n\n\nBox-Pierce\nautocorrelation\n✔️\n\n\n\nDoornik-Hansen\nnormality\n✔️\nrjd3tookit\n\n\n\n\nLjung-Box\nThe Ljung-Box Q-statistics are given by:\n\\[\n\\text{LB}(k)=n \\times (n+2) \\times \\sum_{k=1}^{K}\\frac{\\rho_{a,k}^{2}}{n-k}\n\\]\nwhere \\(\\rho_{a,k}^{2}\\) is the autocorrelation coefficient at lag \\(k\\) of the residuals \\(\\widehat{a}_{t}\\), \\(n\\) is the number of terms in the differenced series, \\(K\\), the maximum lag being considered, is set in JDemetra+ to \\(24\\) (monthly series) or \\(8\\) (quarterly series).\nIf the residuals are random (which is the case for residuals from a well specified model), they will be distributed as \\(\\chi_{(K-m)}^{2}\\), where \\(m\\) is the number of parameters in the model which has been fitted to the data. (edit: not the residuals, but \\(\\widehat{\\rho}\\))\n\n\nBox-Pierce\nThe Box-Pierce Q-statistics are given by:\n\\[\n\\text{BP}(k)=n\\sum_{k=1}^{K}\\rho_{a,k}^{2}\n\\]\nwhere:\n\n\\(\\rho_{a,k}^{2}\\) is the autocorrelation coefficient at lag \\(k\\) of the residuals \\(\\widehat{a}_{t}\\).\n\\(n\\) is the number of terms in differenced series;\n\\(K\\) is the maximum lag being considered, set in JDemetra+ to \\(24\\) (monthly series) or \\(8\\) (quarterly series).\n\nIf the residuals are random (which is the case for residuals from a well specified model), they will be distributed as \\(\\chi_{(K-m)}^{2}\\) degrees of freedom, where \\(m\\) is the number of parameters in the model which has been fitted to the data.\n\n\nDornik-Hansen\nThe Doornik-Hansen test for multivariate normality (DOORNIK, J.A., and HANSEN, H. (2008)) is based on the skewness and kurtosis of multivariate data that is transformed to ensure independence.\nThe skewness and kurtosis are defined, respectively, as: \\(s=\\frac{m_{3}}{\\sqrt{m_{2}}^{3}}\\) and \\(k=\\frac{m_{4}}{m_{2}^{2}}\\),\nwhere:\n\n\\(m_{i}=\\frac{1}{n}\\sum_{i=1}^{n}{(x_{i}}{-\\overline{x})}^{i}\\) ;\n\\(\\overline{x}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}\\) ;\n\\(n\\) number of (non-missing) residuals.\n\nThe Doornik-Hansen test statistic derives from SHENTON, L.R., and BOWMAN, K.O. (1977) and uses transformed versions of skewness and kurtosis.\nThe transformation for the skewness \\(s\\) into \\(\\text{z}_{1}\\) is as in D’AGOSTINO, R.B. (1970):\n\\[\n\\beta=\\frac{3(n^{2}+27n-70)(n+1)(n+3)}{(n-2)(n+5)(n+7)(n+9)}\n\\]\n\\[\n\\omega^{2}=- 1+\\sqrt{2(\\beta-1)}\n\\]\n\\[\n\\delta=\\frac{1}{\\sqrt{\\log{(\\omega}^{2})}}\n\\]\n\\[\ny=s\\sqrt{\\frac{(\\omega^{2}-1)(n+1)(n+3)}{12(n-2)}}\n\\]\n\\[\nz_{1}=\\delta log(y+\\sqrt{y^{2}-1})\n\\]\nThe kurtosis \\(k\\) is transformed from a gamma distribution to \\(\\chi^{2}\\), which is then transformed into standard normal \\(z_{2}\\) using the Wilson-Hilferty cubed root transformation:\n\\[\n\\delta=(n-3)(n+1)(n^{2}+15n-4)\n\\]\n\\[\na=\\frac{(n-2)(n+5)(n+7)(n^{2}+27n-70)}{6\\delta}\n\\]\n\\[\nc=\\frac{(n-7)(n+5)(n+7)(n^{2}+2n-5)}{6\\delta}\n\\]\n\\[\nl= \\frac{(n+5)(n+7)({n^{3}+37n}^{2}+11n-313)}{12\\delta}\n\\]\n\\[\n\\alpha=a+c \\times s^{2}\n\\]\n\\[\n\\chi=2l(k-1-s^{2})\n\\]\n\\[\nz_{2}=\\sqrt{9\\alpha}(\\frac{1}{9\\alpha}-1+\\sqrt[3]{\\frac{\\chi}{2\\alpha}})\n\\]\nFinally, the Doornik-Hansen test statistic is defined as the sum of squared transformations of the skewness and kurtosis. Approximately, the test statistic follows a \\(\\chi^{2}\\) distribution, i.e.:\n\\[\nDH=z_{1}^{2}+z_{2}^{2}\\sim\\chi^{2}(2)\n\\]"
  },
  {
    "objectID": "M-tests.html#seasonality-tests",
    "href": "M-tests.html#seasonality-tests",
    "title": "Tests",
    "section": "Seasonality tests",
    "text": "Seasonality tests\ntable with all tests by purpose and accessibility\n\n\n\n\n\n\n\n\n\nTest\nPurpose\nGUI\nR package\n\n\n\n\nQS test\nAutocorrelation at seasonal lags\n✔️\n\n\n\nF-test with seasonal dummies\nStable seasonality\n✔️\nrjd3toolkit\n\n\nCanova-Hansen\nSeasonal frequencies\n✖\nrjd3toolkit\n\n\nIdentification of spectral peaks\nSeasonal frequencies\n✔️\nrjd3toolkit\n\n\nFriedman test\nStable seasonality\n✔️\nrjd3toolkit\n\n\nTwo-way variance analysis\nMoving seasonality\n✔️\n\n\n\n\n\nQS Test on autocorrelation at seasonal lags\nThe QS test is a variant of the Ljung-Box test computed on seasonal lags, where we only consider positive auto-correlations\nMore exactly,\n\\[\nQS=n(n+2)\\sum_{i=1}^k\\frac{[\\max(0, \\hat\\gamma_{i \\cdot l})]^2}{n-i \\cdot l}\n\\]\nwhere \\(k=2\\), so only the first and second seasonal lags are considered. Thus, the test would check the correlation between the actual observation and the observations lagged by one and two years. Note that \\(l=12\\) when dealing with monthly observations, so we consider the autocovariances \\(\\hat\\gamma_{12}\\) and \\(\\hat\\gamma_{24}\\) alone. In turn, \\(k=4\\) in the case of quarterly data.\nUnder H0, which states that the data are independently distributed, the statistics follows a \\(\\chi(k)\\) distribution. However, the elimination of negative correlations makes it a bad approximation. The p-values would be given by \\(P(\\chi^{2}(k) &gt; Q)\\) for \\(k=2\\). As \\({P(\\chi}^{2}(2)) &gt; 0.05=5.99146\\) and \\({P(\\chi}^{2}(2)) &gt; 0.01=9.21034\\), \\(QS &gt; 5.99146\\) and \\(QS &gt; 9.21034\\) would suggest rejecting the null hypothesis at \\(95\\%\\) and \\(99\\%\\) significance levels, respectively.\nMaravall (2012) proposes approximate the correct distribution (p-values) of the QS statistic using simulation techniques. Using 1000K replications of sample size 240, the correct critical values would be 3.83 and 7.09 with confidence levels of \\(95\\%\\) and \\(99\\%\\), respectively (lower than the 5.99146 and 9.21034 shown above). For each of the simulated series, he obtains the distribution by assuming \\(QS=0\\) when \\(\\hat\\gamma_{12}\\), so in practice this test will detect seasonality only when any of these conditions hold:\n\nStatistically significant positive autocorrelation at lag 12\nNon-negative sample autocorrelation at lag 12 and statistically significant positive autocorrelation at lag 24\n\n\n\nF-test on seasonal dummies\nThe F-test on seasonal dummies checks for the presence of deterministic seasonality. The model used here uses seasonal dummies (mean effect and 11 seasonal dummies for monthly data, mean effect and 3 for quarterly data) to describe the (possibly transformed) time series behaviour. The test statistic checks if the seasonal dummies are jointly statistically not significant. When this hypothesis is rejected, it is assumed that the deterministic seasonality is present and the test results are displayed in green.\nThis test refers to Model-Based $^{2}$ and F-tests for Fixed Seasonal Effects proposed by LYTRAS, D.P., FELDPAUSCH, R.M., and BELL, W.R. (2007) that is based on the estimates of the regression dummy variables and the corresponding t-statistics of the Reg-Arima model, in which the ARIMA part of the model has a form (0,1,1)(0,0,0). The consequences of a misspecification of a model are discussed in LYTRAS, D.P., FELDPAUSCH, R.M., and BELL, W.R. (2007).\nFor a monthly time series the Reg-Arima model structure is as follows:\n\\[\n(1-B)(y_{t}-\\beta_{1}M_{1,t}-\\ldots-\\beta_{11}M_{11,t}-\\gamma X_{t})=\\mu+(1-B)a_{t}\n\\tag{1}\\]\nwhere:\n\n\\(M_{j,t} =\\begin{cases}1 & \\text{in month } j=1, \\ldots, 11 \\\\- 1 & \\text{in December}\\\\0 & \\text{otherwise}\\end{cases} \\text{-dummy variables;}\\)\n\\(y_{t}\\) – the original time series;\n\\(B\\) – backshift operator;\n\\(X_{t}\\) – other regression variables used in the model (e.g. outliers, calendar effects, user-defined regression variables, intervention variables);\n\\(\\mu\\) – mean effect;\n\\(a_{t}\\) – white-noise variable with mean zero and a constant variance.\n\nIn the case of a quarterly series the estimated model has this form:\n\\[\n(1-B)(y_{t}-\\beta_{1}M_{1,t}-\\ldots-\\beta_{3}M_{3,t}-\\gamma X_{t})=\\mu+(1-B)a_{t}\n\\tag{2}\\]\nwhere:\n\\[\nM_{j,t} =\n\\begin{cases}\n1 & \\text{in quarter} j=1, \\ldots, 3 \\\\\n- 1 & \\text{in the fourth quarter}\\\\\n0 & \\text{otherwise}\n\\end{cases} \\text{-dummy variables;}\n\\]\nOne can use the individual t-statistics to assess whether seasonality for a given month is significant, or a chi-squared test statistic if the null hypothesis is that the parameters are collectively all zero. The chi-squared test statistic is \\({\\widehat{\\chi}}^{2}={\\widehat{\\beta}}^{'}{[ Var(\\widehat{\\beta})}^{\\ })^{- 1}]{\\widehat{\\beta}}^{\\ }\\) in this case compared to critical values from a \\(\\chi^{2}(\\text{df})\\)-distribution, with degrees of freedom \\(df=11\\) (monthly series) or \\(df=3\\) (quarterly series). Since the \\(Var(\\widehat{\\beta})\\) computed using the estimated variance of \\(\\alpha_{t}\\) may be very different from the actual variance in small samples, this test is corrected using the proposed \\(\\text{F}\\) statistic:\n\\[\nF=\\frac{{\\widehat{\\chi}}^{2}}{s-1} \\times \\frac{n-d-k}{n-d}\n\\]\nwhere \\(n\\) is the sample size, \\(d\\) is the degree of differencing, s is time series frequency (12 for a monthly series, 4 for a quarterly series) and \\(k\\) is the total number of regressors in the Reg-Arima model (including the seasonal dummies \\(\\text{M}_{j,t}\\) and the intercept).\nThis statistic follows a \\(F_{s-1,n-d-k}\\) distribution under the null hypothesis.\n\n\nFriedman test for stable seasonality\nThe Friedman test is a non-parametric method for testing that samples are drawn from the same population or from populations with equal medians. The significance of the month (or quarter) effect is tested. The Friedman test requires no distributional assumptions. It uses the rankings of the observations. If the null hypothesis of no stable seasonality is rejected at the 0.10% significance level then the series is considered to be seasonal and the test’s outcome is displayed in green.\nThe test statistic is constructed as follows. Consider first the matrix of data \\(\\{x_{ij}\\}_{n \\times k}\\) with \\(n\\) rows (the blocks, i.e. number of years in the sample), \\(k\\) columns (the treatments, i.e. either 12 months or 4 quarters, depending on the frequency of the data).\nThe data matrix needs to be replaced by a new matrix \\(\\{r_{ij}\\}_{n \\times k}\\), where the entry \\(r_{ij}\\) is the rank of \\(x_{ij}\\) within block \\(i\\) .\nThe test statistic is given by\n\\[\nQ=\\frac{SS_t}{SS_e}\n\\]\nwhere \\(SS_t=n \\sum_{j=1}^{k}(\\overline{r}_{.j}-\\overline{r})^2\\) and \\(SS_e=\\frac{1}{n(k-1)} \\sum_{i=1}^{n}\\sum_{j=1}^{k}(r_{ij}-\\overline{r})^2\\). It represents the variance of the average ranking across treatments j relative to the total.\nUnder the hypothesis of no seasonality, all months can be equally treated. For the sake of completeness:-\\(\\overline{r}*{.j}\\) is the average ranks of each treatment (month) j within each block (year)-The average rank is given by \\(\\overline{r}=\\frac{1}{nk}\\sum_{i=1}^{n}\\sum_{j=1}^{k}r_{ij}\\)\nFor large \\(n\\) or \\(k\\) , i.e. \\(n &gt; 15\\) or \\(k &gt; 4\\), the probability distribution of \\(Q\\) can be approximated by that of a chi-squared distribution. Thus, the p-value is given by \\(P(\\chi^2_{k-1}&gt;Q)\\).\n\n\nMoving seasonality test\nThe evolutive seasonality test is based on a two-way analysis of variance model. The model uses the values from complete years only. Depending on the decomposition type for the Seasonal/Irregular component it uses Equation 1 (in the case of a multiplicative model) or Equation 2 (in the case of an additive model):\n\\[\n|\\text{SI}_{\\text{ij}}-1|=X_{\\text{ij}}=b_{i}+m_{j}+e_{\\text{ij}}\n\\]\n\\[\n|\\text{SI}_{\\text{ij}}|=X_{\\text{ij}}=b_{i}+m_{j}+e_{\\text{ij}}\n\\]\nwhere:\n\n\\(m_{j}\\) – monthly or quarterly effect for \\(j\\)-th period, \\(j=(1,\\ldots,k)\\), where \\(k=12\\) for a monthly series and \\(k=4\\) for a quarterly series;\n\\(b_{j}\\) – annual effect \\(i\\), \\((i=1,\\ldots,N)\\) where \\(N\\) is the number of complete years;\n\\(e_{\\text{ij}}\\) – residual effect.\n\nThe test is based on the following decomposition:\n\\[\nS^{2}=S_{A}^{2}+S_{B}^{2}+S_{R}^{2},\n\\tag{3}\\]\nwhere:\n\n\\(S^{2}=\\sum_{j=1}^{k}{\\sum_{i=1}^{N}({\\overline{X}}_{\\text{ij}}-{\\overline{X}}_{\\bullet \\bullet})^{2}}\\) –the total sum of squares;\n\\(S_{A}^{2}=N\\sum_{j=1}^{k}({\\overline{X}}_{\\bullet j}-{\\overline{X}}_{\\bullet \\bullet})^{2}\\) – the inter-month (inter-quarter, respectively) sum of squares, which mainly measures the magnitude of the seasonality;\n\\(S_{B}^{2}=k\\sum_{i=1}^{N}({\\overline{X}}_{i \\bullet}-{\\overline{X}}_{\\bullet \\bullet})^{2}\\) – the inter-year sum of squares, which mainly measures the year-to-year movement of seasonality;\n\\(S_{R}^{2}=\\sum_{i=1}^{N}{\\sum_{j=1}^{k}({\\overline{X}}_{\\text{ij}}-{\\overline{X}}_{i \\bullet}-{\\overline{X}}_{\\bullet j}-{\\overline{X}}_{\\bullet \\bullet})^{2}}\\) – the residual sum of squares.\n\nThe null hypothesis \\(H_{0}\\) is that \\(b_{1}=b_{2}=...=b_{N}\\) which means that there is no change in seasonality over the years. This hypothesis is verified by the following test statistic:\n\\[\nF_{M}=\\frac{\\frac{S_{B}^{2}}{(n-1)}}{\\frac{S_{R}^{2}}{(n-1)(k-1)}}\n\\]\nwhich follows an \\(F\\)-distribution with \\(k-1\\) and \\(n-k\\) degrees of freedom.\n\n\nCombined seasonality test\nThis test combines the Kruskal-Wallis test along with test for the presence of seasonality assuming stability (\\(F_{S}\\)), and evaluative seasonality test for detecting the presence of identifiable seasonality (\\(F_{M}\\)). Those three tests are calculated using the final unmodified SI component. The main purpose of the combined seasonality test is to check whether the seasonality of the series is identifiable. For example, the identification of the seasonal pattern is problematic if the process is dominated by highly moving seasonality (DAGUM, E.B. (1987)). The testing procedure is shown in the figure below.\n\n\n\nCombined seasonality test, source: LADIRAY, D., QUENNEVILLE, B. (2001)\n\n\n\n\nIdentification of spectral peaks\nTests related to identification of spectral peaks in a periodogram, autoregressive spectrum or Tuckey spectrum are detailed here in the chapter dedicated to spectral analysis."
  },
  {
    "objectID": "M-STL-decomposition.html",
    "href": "M-STL-decomposition.html",
    "title": "STL: Local regression decomposition",
    "section": "",
    "text": "Up coming content."
  },
  {
    "objectID": "M-state-space-framework.html",
    "href": "M-state-space-framework.html",
    "title": "State space framework",
    "section": "",
    "text": "Up coming content."
  },
  {
    "objectID": "M-Temp-Disagg-Bench.html#benchmarking-underlying-theory",
    "href": "M-Temp-Disagg-Bench.html#benchmarking-underlying-theory",
    "title": "Temporal disaggregation and benchmarking",
    "section": "Benchmarking Underlying Theory",
    "text": "Benchmarking Underlying Theory\nBenchmarking1 is a procedure widely used when for the same target variable the two or more sources of data with different frequency are available. Generally, the two sources of data rarely agree, as an aggregate of higher-frequency measurements is not necessarily equal to the less-aggregated measurement. Moreover, the sources of data may have different reliability. Usually it is thought that less frequent data are more trustworthy as they are based on larger samples and compiled more precisely. The more reliable measurement is considered as a benchmark.\nBenchmarking also occurs in the context of seasonal adjustment. Seasonal adjustment causes discrepancies between the annual totals of the seasonally unadjusted (raw) and the corresponding annual totals of the seasonally adjusted series. Therefore, seasonally adjusted series are benchmarked to the annual totals of the raw time series[^m-temp-disagg-bench-2]. Therefore, in such a case benchmarking means the procedure that ensures the consistency over the year between adjusted and non-seasonally adjusted data. It should be noted that the ‘ESS Guidelines on Seasonal Adjustment’ (2015) do not recommend benchmarking as it introduces a bias in the seasonally adjusted data. Also the U.S. Census Bureau points out that: Forcing the seasonal adjustment totals to be the same as the original series annual totals can degrade the quality of the seasonal adjustment, especially when the seasonal pattern is undergoing change. It is not natural if trading day adjustment is performed because the aggregate trading day effect over a year is variable and moderately different from zero.[^m-temp-disagg-bench-3] Nevertheless, some users may prefer the annual totals for the seasonally adjusted series to match the annual totals for the original, non-seasonally adjusted series[^m-temp-disagg-bench-4]. According to the ‘ESS Guidelines on Seasonal Adjustment’ (2015), the only benefit of this approach is that there is consistency over the year between adjusted and non-seasonally adjusted data; this can be of particular interest when low-frequency (e.g. annual) benchmarking figures officially exist (e.g. National Accounts, Balance of Payments, External Trade, etc.) where user needs for time consistency are stronger.\nThe benchmarking procedure in JDemetra+ is available for a single seasonally adjusted series and for an indirect seasonal adjustment of an aggregated series. In the first case, univariate benchmarking ensures consistency between the raw and seasonally adjusted series. In the second case, the multivariate benchmarking aims for consistency between the seasonally adjusted aggregate and its seasonally adjusted components.\nGiven a set of initial time series \\[\\left\\{ z_{i,t} \\right\\}_{i \\in I}\\], the aim of the benchmarking procedure is to find the corresponding\n\\[\n\\left\\{ x_{i,t} \\right\\}_{i \\in I}\n\\]\nthat respect temporal aggregation constraints, represented by \\(X_{i,T} = \\sum_{t \\in T}^{}x_{i,t}\\) and contemporaneous constraints given by\n\\[\nq_{k,t} = \\sum_{j \\in J_{k}}^{}{w_{\\text{kj}}x_{j,t}}\n\\]\nor, in matrix form:\n\\[\nq_{k,t} = w_{k}x_{t}\n\\] .\nThe underlying benchmarking method implemented in JDemetra+ is an extension of Cholette’s2 method, which generalises, amongst others, the additive and the multiplicative Denton procedure as well as simple proportional benchmarking.\nThe JDemetra+ solution uses the following routines that are described in DURBIN, J., and KOOPMAN, S.J. (2001):\n\nThe multivariate model is handled through its univariate transformation,\nThe smoothed states are computed by means of the disturbance smoother.\n\nThe performance of the resulting algorithm is highly dependent on the number of variables involved in the model (\\(\\propto \\ n^{3}\\)). The other components of the problem (number of constraints, frequency of the series, and length of the series) are much less important (\\(\\propto \\ n\\)).\nFrom a theoretical point of view, it should be noted that this approach may handle any set of linear restrictions (equalities), endogenous (between variables) or exogenous (related to external values), provided that they don’t contain incompatible equations. The restrictions can also be relaxed for any period by considering their “observation” as missing. However, in practice, it appears that several kinds of contemporaneous constraints yield unstable results. This is more especially true for constraints that contain differences (which is the case for non-binding constraints). The use of a special square root initializer improves in a significant way the stability of the algorithm."
  },
  {
    "objectID": "M-Temp-Disagg-Bench.html#footnotes",
    "href": "M-Temp-Disagg-Bench.html#footnotes",
    "title": "Temporal disaggregation and benchmarking",
    "section": "",
    "text": "Description of the idea of benchmarking is based on DAGUM, B.E., and CHOLETTE, P.A. (1994) and QUENNEVILLE, B. et all (2003). Detailed information can be found in: DAGUM, B.E., and CHOLETTE, P.A. (2006).↩︎\nCHOLETTE, P.A. (1979).↩︎"
  }
]